{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc8ca69-0fed-4b55-b3c4-fc864a47c5a9",
   "metadata": {},
   "source": [
    "# Lesson #: Difference-in-Differences\n",
    "\n",
    "This notebook will cover:\n",
    "\n",
    "1. Difference-in-Differences and when it is appropriate.\n",
    "2. Consequences of misspecification.\n",
    "3. The Event Study estimator.\n",
    "4. The Triple Difference estimator.\n",
    "5. Using Repeated Cross-Section data.\n",
    "6. Failure of Parallel Trends.\n",
    "\n",
    "This notebook assumes you are familiar with and draws on concepts covered in:\n",
    "\n",
    "1. Introduction to Jupyter.\n",
    "2. Introduction to R.\n",
    "3. Introduction to Data.\n",
    "4. Expectations and Summary Statistics.\n",
    "4. Conditional Expectations and the $t$-Test.\n",
    "5. Regression Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e80eb05f-8d89-4c61-9ed3-44e30707b828",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.9\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 4.1.3”\n",
      "Warning message:\n",
      "“package ‘tidyr’ was built under R version 4.1.2”\n",
      "Warning message:\n",
      "“package ‘readr’ was built under R version 4.1.2”\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 4.1.3”\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Warning message:\n",
      "“package ‘stargazer’ was built under R version 4.1.2”\n",
      "\n",
      "Please cite as: \n",
      "\n",
      "\n",
      " Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n",
      "\n",
      " R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n",
      "\n",
      "\n",
      "Warning message:\n",
      "“package ‘broom’ was built under R version 4.1.3”\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(stargazer)\n",
    "library(broom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183b2cf-f17c-4735-bf1c-1e8323529f57",
   "metadata": {},
   "source": [
    "## Difference-in-Differences\n",
    "\n",
    "To demonstrate how DID works and the consequences of misspecification, I require data where I know the true parameter values. Therefore this again necessitates using simulated data rather than real-life data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8896b7b-8317-4153-ae70-1e576faf5cfc",
   "metadata": {},
   "source": [
    "### Generating Panel-Structured Data\n",
    "\n",
    "Panel-Structured data have both an unit and a time index. The features that matter are that there should be a common time trend component and an additional time trend component specific only to the \"treated\" group. For our purposes, it can be more helpful to think of the \"treated\" group as simply the \"group of interest\" who may have been differentially affected by something that changed between the \"before\" and the \"after\" period(s). The minimum number of time periods you require to run a DID estimator is $2$, but the definition of a \"period\" is not constrained to \"usual\" time units like months and years. For example, if you have the privilege of working with linked census data, then your period may be decadal or quinquennial, while if you work with stock market data your period may be as fine as minutes or seconds.\n",
    "\n",
    "Note also that panel-structured data is not restricted to a unit-by-time structure. It is also possible to have a group-by-unit panel structured data. Examples include twins in a family unit, students in a class, patients and their primary physicians, _et cetera_. In this case, `i` below indexes the group instead of the unit and `T` indexes the unit within the group instead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e798f1-5a5e-4e12-a1ff-9f5d51873e93",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(998)\n",
    "sim.data <- tibble(i = c(1:10000), hgt = rnorm(10000, 1.68, 0.09), u = rnorm(10000, 0, 1))\n",
    "sim.data <- sim.data %>% mutate(diet = if_else(rnorm(10000, 0, 1) + u < 0, 0, 1))\n",
    "sim.data <- rbind(\n",
    "    sim.data %>% mutate(Treatment = 0, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = 28 * hgt ^ 2 + e),\n",
    "    sim.data %>% mutate(Treatment = 1, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = 2 + 28 * hgt ^ 2 - 3 * diet + e)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04291028-a774-45a7-9891-a562544028e8",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "\n",
    "A quick overview of the synthetic data. To an approximation, this data set tries to simulate a height and weight data set. `hgt` is short for height (measured in meters; m), `wgt` for weight (measured in kilograms; kg), `diet` implies we are considering the effect of a diet. As is intuitive, evaluating the effect of a diet is an appropriate case for DID because diets take time to show their effects. We also clearly need height as a control because all else equal, a healthy but taller person should weigh more than a healthy but shorter person. `i` and `T` are our person and time indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046b3f50-c6bd-423f-9ea2-85cf738fc3fa",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       i              hgt              u                 diet       \n",
       " Min.   :    1   Min.   :1.348   Min.   :-4.25151   Min.   :0.0000  \n",
       " 1st Qu.: 2501   1st Qu.:1.619   1st Qu.:-0.67718   1st Qu.:0.0000  \n",
       " Median : 5000   Median :1.681   Median : 0.01236   Median :0.0000  \n",
       " Mean   : 5000   Mean   :1.680   Mean   :-0.00241   Mean   :0.4946  \n",
       " 3rd Qu.: 7500   3rd Qu.:1.741   3rd Qu.: 0.67019   3rd Qu.:1.0000  \n",
       " Max.   :10000   Max.   :2.011   Max.   : 4.07305   Max.   :1.0000  \n",
       "       T             e                  wgt        \n",
       " Min.   :0.0   Min.   :-6.319845   Min.   : 49.41  \n",
       " 1st Qu.:0.0   1st Qu.:-0.955488   1st Qu.: 73.48  \n",
       " Median :0.5   Median :-0.009791   Median : 79.38  \n",
       " Mean   :0.5   Mean   :-0.011837   Mean   : 79.48  \n",
       " 3rd Qu.:1.0   3rd Qu.: 0.940875   3rd Qu.: 85.19  \n",
       " Max.   :1.0   Max.   : 7.251245   Max.   :116.57  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(sim.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407602bf-cd01-47b6-abed-ecb5a4a8e342",
   "metadata": {},
   "source": [
    "## Difference-in-Differences Estimator\n",
    "\n",
    "Recap that DID is the following model. We estimate\n",
    "\n",
    "$$\n",
    "    \\theta = \\mathbb{E}[Y_{i} \\mid \\underbrace{G_{i} = 1, T_{i} = 1}_{D_{i} = 1}] - \\mathbb{E}[Y_{i} \\mid \\underbrace{G_{i} = 1, T_{i} = 0}_{D_{i} = 0}].\n",
    "$$\n",
    "\n",
    "This is a model for when we have a treatment implemented in between two periods where we observe the units. However as before there will be bias without further adjustments to the method. The main bias with estimators that make use of the temporal dimension of the data is that na&iuml;ve estimators conflate the true effect with time trends.\n",
    "\n",
    "To give an intuition, suppose we want to measure the effect of drinking milk daily on height growth in young children. The problem is that young children are developing and naturally grow taller regardless of their diet (unless they are severely malnourished). Therefore a na&iuml;ve estimator conflates this natural time trend with the real effect of the target diet and can spuriously estimate a positive effect of drinking milk when it could very well be the case that the true effect is zero or even negative.\n",
    "\n",
    "Mathematically, we see the bias in the PO model by\n",
    "\n",
    "$$\n",
    "    \\theta = \\underbrace{\\mathbb{E}[Y_{1,i}(1) \\mid T_{i} = 1] - \\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 1]}_{ATET} + \\underbrace{\\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 1] - \\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 0]}_{Bias}.\n",
    "$$\n",
    "\n",
    "The bias is clearly coming from the unobserved time trend. How do we deal with it given that the comparison estimator already implicitly makes use of a time period indicator? The answer is we postulate the existence of a counterfactual group for which we do indeed observe them being untreated in both periods, but their time trend is identical to the group of interest:\n",
    "\n",
    "$$\n",
    "    \\mathbb{E}[Y_{0,i}(0) \\mid T_{i} = 1] - \\mathbb{E}[Y_{0,i}(0) \\mid T_{i} = 0] = \\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 1] - \\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 0]\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "    \\mathbb{E}[Y_{0,i}(0) \\mid T_{i} = 1] - \\mathbb{E}[Y_{0,i}(0) \\mid T_{i} = 0] = \\mathbb{E}[Y_{i} \\mid \\underbrace{G_{i} = 0, T_{i} = 1}_{D_{i} = 0}] - \\mathbb{E}[Y_{i} \\mid \\underbrace{G_{i} = 0, T_{i} = 0}_{D_{i} = 0}].\n",
    "$$\n",
    "\n",
    "With this observed control group we can now estimate:\n",
    "\n",
    "$$\n",
    "    ATET = \\left( \\mathbb{E}[Y_{i} \\mid G_{i} = 1, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid G_{i} = 1, T_{i} = 0] \\right) - \\left( \\mathbb{E}[Y_{i} \\mid G_{i} = 0, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid G_{i} = 0, T_{i} = 0] \\right).\n",
    "$$\n",
    "\n",
    "This is estimatable because all this data is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd29938-c7fc-4e9c-98b8-6fbc5d547cb3",
   "metadata": {},
   "source": [
    "### Difference-in-Differences with $t$-Tests\n",
    "\n",
    "Before we talk about the regression method of estimating DID models, let's talk about the much simpler method of doing a plain comparison estimate. Recall that the model is\n",
    "\n",
    "$$\n",
    "    ATET = \\left( \\mathbb{E}[Y_{i} \\mid G_{i} = 1, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid G_{i} = 1, T_{i} = 0] \\right) - \\left( \\mathbb{E}[Y_{i} \\mid G_{i} = 0, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid G_{i} = 0, T_{i} = 0] \\right)\n",
    "$$\n",
    "\n",
    "which we can rewrite as\n",
    "\n",
    "$$\n",
    "    ATET = \\mathbb{E}[Y_{i,1} - Y_{i,0} \\mid G_{i} = 1] - \\mathbb{E}[Y_{i,1} - Y_{i,0} \\mid G_{i} = 0].\n",
    "$$\n",
    "\n",
    "This tells us precisely how to estimate the ATET using the DID estimator using a simple $t$-test:\n",
    "\n",
    "1. Generate $\\Delta Y_{i} = Y_{i,1} - Y_{i,0}$.\n",
    "2. Test $\\overline{\\Delta Y_{i}} \\mid_{G_{i} = 1}$ versus $\\overline{\\Delta Y_{i}} \\mid_{G_{i} = 0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1bf7a5-ce37-4786-9f68-3eb19a31bdf4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "diff.data <- sim.data %>% filter(Treatment == 1) - sim.data %>% filter(Treatment == 0) %>% mutate(diet = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59459e30-8e2f-4142-8f75-d66ed8b058dd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 1 × 10\u001b[39m\n",
      "  estim…¹ estim…² estim…³ stati…⁴ p.value param…⁵ conf.…⁶ conf.…⁷ method alter…⁸\n",
      "    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \n",
      "\u001b[90m1\u001b[39m   -\u001b[31m2\u001b[39m\u001b[31m.\u001b[39m\u001b[31m97\u001b[39m  -\u001b[31m0\u001b[39m\u001b[31m.\u001b[39m\u001b[31m973\u001b[39m    1.99   -\u001b[31m106\u001b[39m\u001b[31m.\u001b[39m       0    \u001b[4m9\u001b[24m998   -\u001b[31m3\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m2\u001b[39m   -\u001b[31m2\u001b[39m\u001b[31m.\u001b[39m\u001b[31m91\u001b[39m Two S… two.si…\n",
      "\u001b[90m# … with abbreviated variable names ¹​estimate, ²​estimate1, ³​estimate2,\u001b[39m\n",
      "\u001b[90m#   ⁴​statistic, ⁵​parameter, ⁶​conf.low, ⁷​conf.high, ⁸​alternative\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "list(\n",
    "    t.test(\n",
    "        diff.data %>% filter(diet == 1) %>% select(wgt),\n",
    "        diff.data %>% filter(diet == 0) %>% select(wgt),\n",
    "        var.equal = TRUE\n",
    "    )\n",
    ") %>% \n",
    "    map_df(tidy) %>%\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3cbdec-0134-4a51-9e92-cfc49105fca6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Interpreting the Results\n",
    "\n",
    "Recall that the simple $t$-test method does not use controls, so this level of accuracy is unexpected. Note, in general the DID estimator without controls does not yield the same results as the DID estimator with controls when applied to real-world data.\n",
    "\n",
    "The estimate is simply interpreted as the estimated ATET. The diet decreases the weight of the group undertaking the diet by $2.97$ kg. In your own cases, what the treatment, outcome, treated group, and units are depends on your question and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedbc6ff-7958-4227-b2a0-2078777307f7",
   "metadata": {},
   "source": [
    "### Na&iuml;ve Comparison Measure Estimator\n",
    "\n",
    "I will first present several wrong ways to use panel data and show empirically why you should not be doing these things if your interest is in the ATET. One way is to estimate a comparison measure for the \"after\" period only:\n",
    "\n",
    "$$\n",
    "    \\theta_{after} = \\mathbb{E}[Y_{i} \\mid \\underbrace{G_{i} = 1, T_{i} = 1}_{D_{i} = 1}] - \\mathbb{E}[Y_{i} \\mid \\underbrace{G_{i} = 0, T_{i} = 1}_{D_{i} = 0}].\n",
    "$$\n",
    "\n",
    "This is of course going to be biased because you can see that in the PO model this corresponds to\n",
    "\n",
    "$$\n",
    "    \\theta_{after} = \\underbrace{\\mathbb{E}[Y_{1,i}(1) \\mid T_{i} = 1] - \\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 1]}_{ATET} + \\underbrace{\\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 1] - \\mathbb{E}[Y_{0,i}(0) \\mid T_{i} = 1]}_{Bias}.\n",
    "$$\n",
    "\n",
    "This corresponds to the selection bias as we have been studying it for much of this course. However, if we assume that the size of this bias remains constant throughout time---which intuitively is exactly what the parallel trends assumption says---then we get rid of the selection bias precisely by further subtracting the \"before\" period comparison measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2529ba05-1c31-4432-9e24-7626b647eb38",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wgt ~ hgt + diet, data = filter(sim.data, T == 1))\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-4.6139 -0.8926  0.0041  0.8866  7.4931 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -77.09513    0.24757 -311.40   <2e-16 ***\n",
       "hgt          93.92216    0.14688  639.46   <2e-16 ***\n",
       "diet         -1.87458    0.02665  -70.34   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.332 on 9997 degrees of freedom\n",
       "Multiple R-squared:  0.9765,\tAdjusted R-squared:  0.9765 \n",
       "F-statistic: 2.075e+05 on 2 and 9997 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(\n",
    "    lm(\n",
    "        wgt ~ hgt + diet,\n",
    "        data = filter(sim.data, Treatment == 1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5daef4-f09a-4cbc-a971-2e1fe389b9ed",
   "metadata": {},
   "source": [
    "### Na&iuml;ve Before-After Estimator\n",
    "\n",
    "The second wrong way is to do exactly what was described at the start of this section,\n",
    "\n",
    "$$\n",
    "    \\theta = \\mathbb{E}[Y_{i} \\mid \\underbrace{G_{i} = 1, T_{i} = 1}_{D_{i} = 1}] - \\mathbb{E}[Y_{i} \\mid \\underbrace{G_{i} = 1, T_{i} = 0}_{D_{i} = 0}].\n",
    "$$\n",
    "\n",
    "Of course, by now you know where the problem with this estimator lies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13e6acb-4c65-403b-9868-f4940ad8f783",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wgt ~ hgt + T, data = filter(sim.data, diet == 1))\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-4.6795 -0.8937 -0.0087  0.8962  7.5164 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -78.19937    0.24766 -315.75   <2e-16 ***\n",
       "hgt          94.04261    0.14711  639.28   <2e-16 ***\n",
       "T            -0.97253    0.02654  -36.64   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.32 on 9889 degrees of freedom\n",
       "Multiple R-squared:  0.9764,\tAdjusted R-squared:  0.9764 \n",
       "F-statistic: 2.05e+05 on 2 and 9889 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(\n",
    "    lm(\n",
    "        wgt ~ hgt + Treatment,\n",
    "        data = filter(sim.data, diet == 1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d692ac-6f01-42fa-9cf7-2f58e99bd6c7",
   "metadata": {},
   "source": [
    "### Na&iuml;ve Linear Estimator Without Interaction Terms\n",
    "\n",
    "A third way to estimate the ATET wrongly is to do a na&iuml;ve linear estimator of the form\n",
    "\n",
    "$$\n",
    "    Y_{i} = b_{0} + b_{1} T_{i} + b_{2} D_{i} + e_{i}.\n",
    "$$\n",
    "\n",
    "Why would this be biased? One way to think about this is that this regression implies\n",
    "\n",
    "\\begin{align*}\n",
    "    b_{2} & = \\mathbb{E}[Y_{i} \\mid D_{i} = 1, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid D_{i} = 0, T_{i} = 1] \\\\\n",
    "    & = \\mathbb{E}[Y_{i} \\mid D_{i} = 1, T_{i} = 0] - \\mathbb{E}[Y_{i} \\mid D_{i} = 0, T_{i} = 0] \\\\\n",
    "    & = \\mathbb{E}[Y_{i} \\mid D_{i} = 1] - \\mathbb{E}[Y_{i} \\mid D_{i} = 0] \\\\\n",
    "    & = \\mathbb{E}[Y_{1,i}(1)] - \\mathbb{E}[Y_{0,i}(0)] \\\\\n",
    "    & = \\underbrace{\\mathbb{E}[Y_{1,i}(1)] - \\mathbb{E}[Y_{1,i}(0)]}_{ATET} + \\underbrace{\\mathbb{E}[Y_{1,i}(0)] - \\mathbb{E}[Y_{0,i}(0)]}_{Bias}.\n",
    "\\end{align*}\n",
    "\n",
    "This points to a selection bias intuition. If you believe there is no unobserved selection into treatment, then this model is correct. In most cases this is not true.\n",
    "\n",
    "This may then prompt the question: intuitively the saturated model solves this problem and you have learnt in lectures that it does. Why? The idea again goes back to the parallel trends assumption. We assume that the selection bias is constant over time. As such, the \"before\" period observation where both groups are untreated provides an estimate of the selection bias, which we can then remove from this biased estimator to obtain the unbiased estimate of the ATET.\n",
    "\n",
    "This intuition should not also reveal something very interesting to those paying attention: the DID estimator circumvents selection bias entirely. You do not need an experimental set-up without selection bias to use DID!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "710b67cd-592f-4970-9a2a-39ee6b96f601",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wgt ~ hgt + T + diet, data = sim.data)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.7042 -1.0528 -0.0032  1.0504  6.7400 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -78.32235    0.20121 -389.25   <2e-16 ***\n",
       "hgt          93.90292    0.11920  787.76   <2e-16 ***\n",
       "T             0.52621    0.02163   24.33   <2e-16 ***\n",
       "diet         -0.39189    0.02163  -18.12   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.529 on 19996 degrees of freedom\n",
       "Multiple R-squared:  0.9688,\tAdjusted R-squared:  0.9688 \n",
       "F-statistic: 2.073e+05 on 3 and 19996 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(\n",
    "    lm(\n",
    "        wgt ~ hgt + Treatment + diet,\n",
    "        data = sim.data\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053e3a1-7966-4fb5-bbc6-5235f90e8a49",
   "metadata": {},
   "source": [
    "### Difference-in-Differences using Linear Regression\n",
    "\n",
    "The linear regression model of DID is how most DID models are estimated in the academic literature. We estimate a model that is saturated in the time and group variables,\n",
    "\n",
    "$$\n",
    "    Y_{i} = \\alpha + \\gamma T_{i} + \\beta G_{i} + \\delta T_{i} \\times G_{i} + \\epsilon_{i}.\n",
    "$$\n",
    "\n",
    "This gives us\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}[Y_{i} \\mid T_{i} = 1, G_{i} = 1] & = \\alpha + \\gamma + \\beta + \\delta \\\\\n",
    "    \\mathbb{E}[Y_{i} \\mid T_{i} = 1, G_{i} = 0] & = \\alpha + \\gamma \\\\\n",
    "    \\mathbb{E}[Y_{i} \\mid T_{i} = 0, G_{i} = 1] & = \\alpha + \\beta \\\\\n",
    "    \\mathbb{E}[Y_{i} \\mid T_{i} = 0, G_{i} = 0] & = \\alpha.\n",
    "\\end{align*}\n",
    "\n",
    "This yields the time trend as $\\gamma$ and the time-invariant selection bias as $\\beta$. $\\delta$ is the unbiased estimator of the ATET and our parameter of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbdc5642-2291-4f8d-a58a-4573fa3bffc4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wgt ~ hgt + T * diet, data = sim.data)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-5.9709 -0.9063  0.0025  0.8985  7.4894 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -79.05570    0.17623 -448.58   <2e-16 ***\n",
       "hgt          93.90292    0.10426  900.69   <2e-16 ***\n",
       "T             1.99292    0.02660   74.91   <2e-16 ***\n",
       "diet          1.09083    0.02675   40.78   <2e-16 ***\n",
       "T:diet       -2.96545    0.03783  -78.39   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.337 on 19995 degrees of freedom\n",
       "Multiple R-squared:  0.9762,\tAdjusted R-squared:  0.9762 \n",
       "F-statistic: 2.048e+05 on 4 and 19995 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(\n",
    "    lm(\n",
    "        wgt ~ hgt + Treatment * diet,\n",
    "        data = sim.data\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71bfc21-19a8-430d-b989-b4341290a884",
   "metadata": {},
   "source": [
    "### Comparing Estimators\n",
    "\n",
    "The following table shows all the misspecified models and the correct specification. (1) is the na&iuml;ve comparison estimator, (2) is the before-after estimator, (3) is the linear model estimator without the interaction term, (4) is the fully specified model, and (5) is what the $t$-test implicitly estimates.\n",
    "\n",
    "Again, note that (4) and (5) will in general not produce the same ATET estimate in most real-world data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9690e133-0e22-419b-bd57-7b4c881453d8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================\n",
      "                                     Dependent variable:                 \n",
      "                    -----------------------------------------------------\n",
      "                                             wgt                         \n",
      "                       (1)        (2)        (3)        (4)        (5)   \n",
      "-------------------------------------------------------------------------\n",
      "hgt                 93.922***  94.043***  93.903***  93.903***           \n",
      "                     (0.147)    (0.147)    (0.119)    (0.104)            \n",
      "                                                                         \n",
      "diet                -1.875***             -0.392***   1.091***  0.900*** \n",
      "                     (0.027)               (0.022)    (0.027)    (0.172) \n",
      "                                                                         \n",
      "T:diet                                               -2.965***  -2.965***\n",
      "                                                      (0.038)    (0.244) \n",
      "                                                                         \n",
      "T                              -0.973***   0.526***   1.993***  1.993*** \n",
      "                                (0.027)    (0.022)    (0.027)    (0.172) \n",
      "                                                                         \n",
      "Constant            -77.095*** -78.199*** -78.322*** -79.056*** 78.770***\n",
      "                     (0.248)    (0.248)    (0.201)    (0.176)    (0.121) \n",
      "                                                                         \n",
      "-------------------------------------------------------------------------\n",
      "Observations          10,000     9,892      20,000     20,000    20,000  \n",
      "R2                    0.976      0.976      0.969      0.976      0.009  \n",
      "Adjusted R2           0.976      0.976      0.969      0.976      0.009  \n",
      "Residual Std. Error   1.332      1.320      1.529      1.337      8.623  \n",
      "=========================================================================\n",
      "Note:                                         *p<0.1; **p<0.05; ***p<0.01\n"
     ]
    }
   ],
   "source": [
    "model1 <- lm(wgt ~ hgt + diet, data = filter(sim.data, Treatment == 1))\n",
    "model2 <- lm(wgt ~ hgt + Treatment, data = filter(sim.data, diet == 1))\n",
    "model3 <- lm(wgt ~ hgt + Treatment + diet, data = sim.data)\n",
    "model4 <- lm(wgt ~ hgt + Treatment * diet, data = sim.data)\n",
    "model5 <- lm(wgt ~ Treatment * diet, data = sim.data)\n",
    "\n",
    "stargazer(model1, \n",
    "          model2, \n",
    "          model3, \n",
    "          model4, \n",
    "          model5, \n",
    "          type = 'text',\n",
    "          df = FALSE,\n",
    "          omit.stat = c('F'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c69c3f-7294-4569-be5f-36620489d254",
   "metadata": {},
   "source": [
    "## Heterogeneity Over Time: the Event Study Estimator\n",
    "\n",
    "The logic of DID can be extended to the case where we observe multiple post-treatment periods. If we think that the ATET is heterogeneous over time, we can estimate an ATET for each period observed. This gives rise to the Event Study estimator. It is so named because this is often used to study the effect of a specific event---usually policy changes and natural disasters---and trace out its effects over many periods. While there is currently an active literature looking at problems with this estimator, we concern ourselves primarily with the simplest case where the treatment occurs only once and we observe the treated group and a counterfactual never-treated group for several periods before and after the event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f93b7-9595-4687-a56d-f6034db84154",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "By convention, for a panel-structured data with more than two periods, period $0$ is when the treatment is implemented and all other period numbers refer to the number of periods after (before if negative) treatment implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac3a7e23-160b-4e78-8324-6125766becad",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(999)\n",
    "sim.data <- tibble(i = c(1:10000), hgt = rnorm(10000, 1.68, 0.09), u = rnorm(10000, 0, 1))\n",
    "sim.data <- sim.data %>% mutate(diet = if_else(rnorm(10000, 0, 1) + u < 0, 0, 1))\n",
    "sim.data <- rbind(\n",
    "    sim.data %>% mutate(Treatment = -3, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = - 1.2 + 28 * hgt ^ 2 + e),\n",
    "    sim.data %>% mutate(Treatment = -2, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = - .5 + 28 * hgt ^ 2 + e),\n",
    "    sim.data %>% mutate(Treatment = -1, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = 28 * hgt ^ 2 + e),\n",
    "    sim.data %>% mutate(Treatment = 0, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = .3 + 28 * hgt ^ 2 + 1.2 * diet + e),\n",
    "    sim.data %>% mutate(Treatment = 1, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = .5 + 28 * hgt ^ 2 + .8 * diet + e),\n",
    "    sim.data %>% mutate(Treatment = 2, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = .9 + 28 * hgt ^ 2 + .1 * diet + e),\n",
    "    sim.data %>% mutate(Treatment = 3, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = 1.1 + 28 * hgt ^ 2 - .5 * diet + e),\n",
    "    sim.data %>% mutate(Treatment = 4, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = 1.4 + 28 * hgt ^ 2 - 1.5 * diet + e)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b68b30-9d20-4fc4-8674-498398414196",
   "metadata": {},
   "source": [
    "### Wrongly Using the Difference-in-Differences Estimator\n",
    "\n",
    "Intuitively, of course the plain DID estimator is a misspecification if we believe that the ATET is heterogeneous over time. We know what the wrongly estimated ATET will be using the Law of Iterated Expectations:\n",
    "\n",
    "$$\n",
    "    \\mathbb{E}[\\Delta_{i} \\mid G_{i} = 1] = \\mathbb{E}_{T}[\\mathbb{E}[\\Delta_{i} \\mid G_{i} = 1, T] \\mid G_{i} = 1].\n",
    "$$\n",
    "\n",
    "Hence, as in this simulated data set, if the time trend of the treatment effect is not monotonic, we can have unexpected results by misspecifying a case of truly heterogeneous treatment effects using the homogeneous treatment effect estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9b86bc6-7dd5-498a-a891-d1438817cd0a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wgt ~ hgt + T * diet, data = .)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.4001 -0.9648 -0.0045  0.9593  6.5022 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error  t value Pr(>|t|)    \n",
       "(Intercept) -80.030035   0.095009 -842.338   <2e-16 ***\n",
       "hgt          94.134484   0.056145 1676.617   <2e-16 ***\n",
       "T             1.417592   0.014639   96.836   <2e-16 ***\n",
       "diet          1.155211   0.016458   70.192   <2e-16 ***\n",
       "T:diet       -0.007523   0.020818   -0.361    0.718    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.425 on 79995 degrees of freedom\n",
       "Multiple R-squared:  0.9726,\tAdjusted R-squared:  0.9726 \n",
       "F-statistic: 7.1e+05 on 4 and 79995 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim.data %>%\n",
    "    mutate(T = if_else(Treatment > -1, 1, 0)) %>%\n",
    "    lm(wgt ~ hgt + Treatment * diet, data = .) %>%\n",
    "    summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70e048-729e-42a7-bd52-b795e3c6c386",
   "metadata": {},
   "source": [
    "### Event Study with $t$-Tests\n",
    "\n",
    "The $t$-Test version of the Event Study estimator is straightforward. Because what we are essentially interested in is\n",
    "\n",
    "$$\n",
    "    ATET(t) = \\left( \\mathbb{E}[Y_{i} \\mid G_{i} = 1, T_{i} = t] - \\mathbb{E}[Y_{i} \\mid G_{i} = 1, T_{i} = -1] \\right) - \\left( \\mathbb{E}[Y_{i} \\mid G_{i} = 0, T_{i} = t] - \\mathbb{E}[Y_{i} \\mid G_{i} = 0, T_{i} = -1] \\right)\n",
    "$$\n",
    "\n",
    "which we can rewrite as\n",
    "\n",
    "$$\n",
    "    ATET(t) = \\mathbb{E}[Y_{i,t} - Y_{i,-1} \\mid G_{i} = 1] - \\mathbb{E}[Y_{i,t} - Y_{i,-1} \\mid G_{i} = 0],\n",
    "$$\n",
    "\n",
    "it implies that what we want to do is simply to first restrict our data set to the periods $t$ and $-1$, then use the regular DID estimator on this subset, and repeat this exercise for all periods before and after $-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1c3a1c3-b9d6-44c9-bb6d-9927d4d75ee8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 5 × 10\u001b[39m\n",
      "  estimate estimate1 estimate2 statis…¹   p.value param…² conf.…³ conf.…⁴ method\n",
      "     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \n",
      "\u001b[90m1\u001b[39m   1.12       1.45      0.332    39.6  8.61\u001b[90me\u001b[39m\u001b[31m-319\u001b[39m    \u001b[4m9\u001b[24m998  1.06     1.17  Two S…\n",
      "\u001b[90m2\u001b[39m   0.748      1.27      0.524    26.4  8.13\u001b[90me\u001b[39m\u001b[31m-149\u001b[39m    \u001b[4m9\u001b[24m998  0.692    0.803 Two S…\n",
      "\u001b[90m3\u001b[39m   0.066\u001b[4m8\u001b[24m     0.986     0.919     2.40 1.66\u001b[90me\u001b[39m\u001b[31m-  2\u001b[39m    \u001b[4m9\u001b[24m998  0.012\u001b[4m1\u001b[24m   0.121 Two S…\n",
      "\u001b[90m4\u001b[39m  -\u001b[31m0\u001b[39m\u001b[31m.\u001b[39m\u001b[31m571\u001b[39m      0.581     1.15    -\u001b[31m20\u001b[39m\u001b[31m.\u001b[39m\u001b[31m2\u001b[39m  1.31\u001b[90me\u001b[39m\u001b[31m- 88\u001b[39m    \u001b[4m9\u001b[24m998 -\u001b[31m0\u001b[39m\u001b[31m.\u001b[39m\u001b[31m627\u001b[39m   -\u001b[31m0\u001b[39m\u001b[31m.\u001b[39m\u001b[31m516\u001b[39m Two S…\n",
      "\u001b[90m5\u001b[39m  -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m55\u001b[39m      -\u001b[31m0\u001b[39m\u001b[31m.\u001b[39m\u001b[31m122\u001b[39m     1.43    -\u001b[31m55\u001b[39m\u001b[31m.\u001b[39m\u001b[31m2\u001b[39m  0   \u001b[90m \u001b[39m        \u001b[4m9\u001b[24m998 -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m61\u001b[39m    -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m50\u001b[39m  Two S…\n",
      "\u001b[90m# … with 1 more variable: alternative <chr>, and abbreviated variable names\u001b[39m\n",
      "\u001b[90m#   ¹​statistic, ²​parameter, ³​conf.low, ⁴​conf.high\u001b[39m\n",
      "\u001b[90m# ℹ Use `colnames()` to see all variable names\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "c(0:4) %>% \n",
    "    lapply(\n",
    "        function (t) t.test(\n",
    "            sim.data %>% filter(Treatment == t & diet == 1) %>% select(wgt) - sim.data %>% filter(Treatment == -1 & diet == 1) %>% select(wgt), \n",
    "            sim.data %>% filter(Treatment == t & diet == 0) %>% select(wgt) - sim.data %>% filter(Treatment == -1 & diet == 0) %>% select(wgt), \n",
    "            var.equal = TRUE\n",
    "        )\n",
    "    ) %>%\n",
    "    map_df(tidy) %>%\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040799e-8b4d-4265-8c64-da1580687d51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Interpreting the Results\n",
    "\n",
    "The $t$-test analogue of the Event Study estimator also highlights intuitively how we need to think about and interpret the estimator. The ATET estimate for each period is interpreted with respect to the base period, which in this case is the period just before the treatment is implemented. In this case,\n",
    "\n",
    "1. The diet actually increases the weight of those on the diet by $1.12$ kg on average in the period they start the diet.\n",
    "2. The diet still increases the weight of those on the diet by $0.748$ kg on average relative to before starting the diet after $1$ period (let's say, months).\n",
    "3. The effect of the diet $2$ months after starting the diet is approximately zero relative to before the diet.\n",
    "4. The effect of the diet turns negative after $3$ months relative to before the diet, with those on diet losing $0.571$ kg on average.\n",
    "5. Those on the diet lose $1.55$ kg on average after $4$ months on the diet relative to before starting the diet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba368f-39d0-4eeb-8473-d5c7167aeebb",
   "metadata": {},
   "source": [
    "### Event Study with Linear Regression\n",
    "\n",
    "With linear regression, the Event Study method is even simpler. Factorise your time variable and set $-1$ as the base level using `relevel`, then estimate the model. `R` takes care of all the necessary interactions for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07d74946-e0d2-49b0-ace6-efbf776eb0fd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wgt ~ hgt + T * diet, data = .)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.1449 -0.9069 -0.0105  0.8969  6.4436 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error  t value Pr(>|t|)    \n",
       "(Intercept) -79.48427    0.09059 -877.440   <2e-16 ***\n",
       "hgt          94.13448    0.05275 1784.377   <2e-16 ***\n",
       "T-3          -1.18358    0.02664  -44.435   <2e-16 ***\n",
       "T-2          -0.45371    0.02664  -17.033   <2e-16 ***\n",
       "T0            0.33232    0.02664   12.476   <2e-16 ***\n",
       "T1            0.52417    0.02664   19.679   <2e-16 ***\n",
       "T2            0.91899    0.02664   34.501   <2e-16 ***\n",
       "T3            1.15252    0.02664   43.268   <2e-16 ***\n",
       "T4            1.43113    0.02664   53.728   <2e-16 ***\n",
       "diet          1.18592    0.02678   44.277   <2e-16 ***\n",
       "T-3:diet     -0.01854    0.03788   -0.489   0.6246    \n",
       "T-2:diet     -0.07358    0.03788   -1.942   0.0521 .  \n",
       "T0:diet       1.11920    0.03788   29.547   <2e-16 ***\n",
       "T1:diet       0.74760    0.03788   19.737   <2e-16 ***\n",
       "T2:diet       0.06681    0.03788    1.764   0.0778 .  \n",
       "T3:diet      -0.57137    0.03788  -15.084   <2e-16 ***\n",
       "T4:diet      -1.55337    0.03788  -41.009   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.339 on 79983 degrees of freedom\n",
       "Multiple R-squared:  0.9758,\tAdjusted R-squared:  0.9758 \n",
       "F-statistic: 2.017e+05 on 16 and 79983 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim.data %>%\n",
    "    mutate(Treatment = relevel(factor(Treatment, levels = c(-3, -2, -1, 0, 1, 2, 3, 4)), ref = 3)) %>%\n",
    "    lm(wgt ~ hgt + Treatment * diet, data = .) %>%\n",
    "    summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c6324-6ee9-4faa-af8a-8db16c04f3e3",
   "metadata": {},
   "source": [
    "## Heterogeneity Over Groups: the Triple Difference Estimator\n",
    "\n",
    "You have seen one way to discuss the Triple Differences estimator. Here I present another.\n",
    "\n",
    "Suppose we are interested in not only the ATET, but also how the ATET differs across certain groups of interest. An example is whether certain policies help to close the gender wage gap: what this implicitly asks is whether\n",
    "\n",
    "$$\n",
    "    ATET(female) > ATET(male).\n",
    "$$\n",
    "\n",
    "Provided that we have panel data, again there is a method that helps to illuminate this kind of heterogeneity: the Triple Difference estimator. What the Triple Difference estimator is interested in is implicitly\n",
    "\n",
    "$$\n",
    "    ATET(k) = \\left( \\mathbb{E}[Y_{i} \\mid G_{i} = 1, K = k, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid G_{i} = 1, K = k, T_{i} = 0] \\right) - \\left( \\mathbb{E}[Y_{i} \\mid G_{i} = 0, K = k, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid G_{i} = 0, K = k, T_{i} = 0] \\right),\n",
    "$$\n",
    "\n",
    "where $k$ is a group of interest that is not the basis for selection into treatment for which we think $ATET(k) \\ne ATET$ and we would like to estimate $ATET(k)$ specifically. As in the lecture notes, while we can in principle estimate heterogeneous treatment effects by simply estimating a DID model for each sub-group, this assumes a fully heterogeneous model where it may not actually be warranted, is inefficient as you are not using the full sample, and it is difficult---though not impossible, but the methods are beyond this level of study---to test if the differences are actually statistically significant.\n",
    "\n",
    "Hence, taking the usual route of adding yet another interaction term to the model to obtain the heterogeneous treatment effects of interest yields the Triple Differences estimator. This gives an intuition as to what Triple Differences are good for:\n",
    "\n",
    "1. Triple Differences tells you if a treatment has additional effects on specific sub-groups.\n",
    "2. Triple Differences is also useful if what you are interested in is the pure effect of the treatment and would like to partial out all other confounding effects of time and group using an argument similar to the parallel trends assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce633fd-c00a-4d05-9279-f0e32c36bf69",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "The data requirements for Triple Differences is similar to that of DID, except you also require another grouping axis that exhibits variation over the treatment assignment indicator. In other words, it cannot be the case that that grouping variable is collinear with the treatment assignment indicator---then how exactly are you supposed to separate the effect of the group from the effect of the treatment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "468faf9e-1e1f-4239-a520-253051dd862c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(999)\n",
    "sim.data <- tibble(i = c(1:10000), u = rnorm(10000, 0, 1))\n",
    "sim.data <- sim.data %>% mutate(sex = rnorm(10000, 0, 1) + u, diet = rnorm(10000, 0, 1))\n",
    "sim.data <- sim.data %>% mutate(diet = if_else(diet < 0, 0, 1), sex = factor(if_else(sex < 0, 'male', 'female'), levels = c('male', 'female')))\n",
    "sim.data <- sim.data %>% mutate(hgt = rnorm(10000, 1.69, .1))\n",
    "sim.data <- rbind(sim.data %>% mutate(Treatment = 0), sim.data %>% mutate(Treatment = 1)) \n",
    "sim.data <- sim.data %>% mutate(e = rnorm(20000, 0, 1) + u)\n",
    "sim.data <- sim.data %>% mutate(wgt = 26.4 * hgt * hgt + 1.7 * Treatment - 2.55 * (sex == 'female') - 1.3 * Treatment * (sex == 'female') - 2 * Treatment * diet - 1.2 * Treatment * diet * (sex == 'female') + e) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97ab10-857e-42c7-b61a-415561e50641",
   "metadata": {},
   "source": [
    "### Wrongly Using the Difference-in-Differences Estimator\n",
    "\n",
    "The Law of Iterated Expectations can again be used to tell us that if the treatment effect is really heterogeneous, then ignoring that heterogeneity is going to yield a biased estimator that is the weighted mean of all the treatment effects,\n",
    "\n",
    "$$\n",
    "    \\mathbb{E}[\\Delta_{i} \\mid G_{i} = 1] = \\mathbb{E}_{K}[\\mathbb{E}[\\Delta_{i} \\mid G_{i} = 1, K] \\mid G_{i} = 1].\n",
    "$$\n",
    "\n",
    "In this case, it may look like there was a mistake because $-2.5$ is less than either $-2$ or $-1.2$, but recall from the Regressions notebook that the proper way to interpret coefficients under interaction terms tells us that in fact the effect of the diet on the two sexes are $-2$ and $-3.2$ respectively. Therefore the biased estimate of $-2.5$ adheres to the Law of Iterated Expectations well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4f7702a-bdfb-4208-8070-a0cf953761a9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wgt ~ hgt + T * diet, data = .)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6.5577 -1.3393  0.0034  1.3350  6.6981 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error  t value Pr(>|t|)    \n",
       "(Intercept) -76.323064   0.225496 -338.468   <2e-16 ***\n",
       "hgt          89.190338   0.132452  673.377   <2e-16 ***\n",
       "T             1.022790   0.037333   27.396   <2e-16 ***\n",
       "diet          0.003336   0.037609    0.089    0.929    \n",
       "T:diet       -2.528769   0.053187  -47.545   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.88 on 19995 degrees of freedom\n",
       "Multiple R-squared:  0.9582,\tAdjusted R-squared:  0.9582 \n",
       "F-statistic: 1.145e+05 on 4 and 19995 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim.data %>%\n",
    "    lm(wgt ~ hgt + Treatment * diet, data = .) %>%\n",
    "    summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a03cac-4e70-4abe-91bc-7b9fe07f15ee",
   "metadata": {},
   "source": [
    "### Triple Difference Intuition with $t$-Tests\n",
    "\n",
    "Before we move into regression analysis, which can be harder to interpret, look at some $t$-test results to get a bearing on your intuitions. Each row corresponds to one of the sexes. The first column of the table is the heterogeneous weight loss estimate of each sex. Then, the Triple Difference estimator is simply the difference in the two weight loss estimates. The estimate corresponds to the coefficient on the triple interaction term in our data simulation code, as expected, and can be interpreted in one of two ways. The first is outlined in the notes, corresponding to the true treatment effect after partialling out group effects as well. The second is outlined here, corresponding to the additional weight loss due to the diet on females compared to males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ecb6b4-c7e4-42b5-ad97-afb58f409b80",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 2 × 10\u001b[39m\n",
      "  estim…¹ estim…² estim…³ stati…⁴ p.value param…⁵ conf.…⁶ conf.…⁷ method alter…⁸\n",
      "    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \n",
      "\u001b[90m1\u001b[39m   -\u001b[31m3\u001b[39m\u001b[31m.\u001b[39m\u001b[31m15\u001b[39m  -\u001b[31m2\u001b[39m\u001b[31m.\u001b[39m\u001b[31m76\u001b[39m    0.386   -\u001b[31m79\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m       0    \u001b[4m4\u001b[24m917   -\u001b[31m3\u001b[39m\u001b[31m.\u001b[39m\u001b[31m22\u001b[39m   -\u001b[31m3\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m7\u001b[39m Two S… two.si…\n",
      "\u001b[90m2\u001b[39m   -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m96\u001b[39m  -\u001b[31m0\u001b[39m\u001b[31m.\u001b[39m\u001b[31m311\u001b[39m   1.65    -\u001b[31m49\u001b[39m\u001b[31m.\u001b[39m\u001b[31m6\u001b[39m       0    \u001b[4m5\u001b[24m079   -\u001b[31m2\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m4\u001b[39m   -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m88\u001b[39m Two S… two.si…\n",
      "\u001b[90m# … with abbreviated variable names ¹​estimate, ²​estimate1, ³​estimate2,\u001b[39m\n",
      "\u001b[90m#   ⁴​statistic, ⁵​parameter, ⁶​conf.low, ⁷​conf.high, ⁸​alternative\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "list(\n",
    "    t.test(\n",
    "        sim.data %>% filter(sex == 'female' & Treatment == 1 & diet == 1) %>% select(wgt) - sim.data %>% filter(sex == 'female' & Treatment == 0 & diet == 1) %>% select(wgt), \n",
    "        sim.data %>% filter(sex == 'female' & Treatment == 1 & diet == 0) %>% select(wgt) - sim.data %>% filter(sex == 'female' & Treatment == 0 & diet == 0) %>% select(wgt), \n",
    "        var.equal = TRUE\n",
    "    ),\n",
    "    t.test(\n",
    "        sim.data %>% filter(sex == 'male' & Treatment == 1 & diet == 1) %>% select(wgt) - sim.data %>% filter(sex == 'male' & Treatment == 0 & diet == 1) %>% select(wgt), \n",
    "        sim.data %>% filter(sex == 'male' & Treatment == 1 & diet == 0) %>% select(wgt) - sim.data %>% filter(sex == 'male' & Treatment == 0 & diet == 0) %>% select(wgt), \n",
    "        var.equal = TRUE\n",
    "    )\n",
    ") %>%\n",
    "    map_df(tidy) %>%\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0775779-0632-4ac4-930e-e35f8d796e62",
   "metadata": {},
   "source": [
    "### Triple Difference with Linear Regression\n",
    "\n",
    "This shows the Triple Difference estimator as discussed in the note. In `R`, the interaction operator `*` can be chained and therefore it is relatively simple to set up the Triple Difference estimator. `R` takes care of populating all the interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5421ead8-18e9-4c5f-9417-2463992e157f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wgt ~ hgt + sex * T * diet, data = .)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-5.2075 -0.9236 -0.0131  0.8979  5.7873 \n",
       "\n",
       "Coefficients:\n",
       "                   Estimate Std. Error  t value Pr(>|t|)    \n",
       "(Intercept)      -75.691458   0.163032 -464.272   <2e-16 ***\n",
       "hgt               89.247438   0.095169  937.778   <2e-16 ***\n",
       "sexfemale         -1.468163   0.037936  -38.701   <2e-16 ***\n",
       "T                  1.649296   0.037783   43.652   <2e-16 ***\n",
       "diet               0.008188   0.037906    0.216    0.829    \n",
       "sexfemale:T       -1.263220   0.053650  -23.546   <2e-16 ***\n",
       "sexfemale:diet    -0.034714   0.054053   -0.642    0.521    \n",
       "T:diet            -1.960662   0.053607  -36.575   <2e-16 ***\n",
       "sexfemale:T:diet  -1.186159   0.076443  -15.517   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.351 on 19991 degrees of freedom\n",
       "Multiple R-squared:  0.9784,\tAdjusted R-squared:  0.9784 \n",
       "F-statistic: 1.133e+05 on 8 and 19991 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim.data %>%\n",
    "    lm(wgt ~ hgt + sex * Treatment * diet, data = .) %>%\n",
    "    summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f069ea8-7acc-4b7c-adec-612ab3da0f53",
   "metadata": {},
   "source": [
    "### Comparing Misspecified Estimators under Triple Differences\n",
    "\n",
    "The following two tables shows how various ways of misspecifying the model when the true CEF corresponds to the heterogeneous ATET/Triple Difference case results in biased estimates. You are encouraged to figure out if you can compute the biased estimates theoretically yourself to check your understanding of how the DID model works in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e337308a-8deb-4bda-bb06-a66ae36d0a73",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================\n",
      "                                Dependent variable:            \n",
      "                    -------------------------------------------\n",
      "                                        wgt                    \n",
      "                       (1)        (2)        (3)        (4)    \n",
      "---------------------------------------------------------------\n",
      "hgt                 89.190***  89.499***  89.019***  89.247*** \n",
      "                     (0.132)    (0.138)    (0.132)    (0.095)  \n",
      "                                                               \n",
      "T                    1.023***   0.386***   1.649***   1.649*** \n",
      "                     (0.037)    (0.038)    (0.038)    (0.038)  \n",
      "                                                               \n",
      "diet                  0.003      -0.026     0.008      0.008   \n",
      "                     (0.038)    (0.038)    (0.038)    (0.038)  \n",
      "                                                               \n",
      "sexfemale                                            -1.468*** \n",
      "                                                      (0.038)  \n",
      "                                                               \n",
      "T:diet              -2.529***  -3.147***  -1.961***  -1.961*** \n",
      "                     (0.053)    (0.054)    (0.054)    (0.054)  \n",
      "                                                               \n",
      "T:sexfemale                                          -1.263*** \n",
      "                                                      (0.054)  \n",
      "                                                               \n",
      "diet:sexfemale                                         -0.035  \n",
      "                                                      (0.054)  \n",
      "                                                               \n",
      "T:diet:sexfemale                                     -1.186*** \n",
      "                                                      (0.076)  \n",
      "                                                               \n",
      "Constant            -76.323*** -77.584*** -75.306*** -75.691***\n",
      "                     (0.225)    (0.234)    (0.224)    (0.163)  \n",
      "                                                               \n",
      "---------------------------------------------------------------\n",
      "Observations          20,000     9,838      10,162     20,000  \n",
      "R2                    0.958      0.978      0.978      0.978   \n",
      "Adjusted R2           0.958      0.978      0.978      0.978   \n",
      "Residual Std. Error   1.880      1.348      1.354      1.351   \n",
      "===============================================================\n",
      "Note:                               *p<0.1; **p<0.05; ***p<0.01\n"
     ]
    }
   ],
   "source": [
    "model1 <- lm(wgt ~ hgt + Treatment * diet, data = sim.data)\n",
    "model2 <- lm(wgt ~ hgt + Treatment * diet, data = sim.data %>% filter(sex == 'female'))\n",
    "model3 <- lm(wgt ~ hgt + Treatment * diet, data = sim.data %>% filter(sex == 'male'))\n",
    "model4 <- lm(wgt ~ hgt + Treatment * diet * sex, data = sim.data)\n",
    "\n",
    "stargazer(model1, \n",
    "          model2, \n",
    "          model3, \n",
    "          model4, \n",
    "          type = 'text',\n",
    "          df = FALSE,\n",
    "          omit.stat = c('F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "916f6580-95b6-48e3-ad84-770dc7b55cf8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================================\n",
      "                                                Dependent variable:                             \n",
      "                    ----------------------------------------------------------------------------\n",
      "                                                        wgt                                     \n",
      "                       (1)        (2)        (3)        (4)        (5)        (6)        (7)    \n",
      "------------------------------------------------------------------------------------------------\n",
      "hgt                 89.261***  89.157***  89.338***  89.247***  89.329***  89.165***  89.247*** \n",
      "                     (0.115)    (0.135)    (0.134)    (0.111)    (0.134)    (0.135)    (0.095)  \n",
      "                                                                                                \n",
      "T                    0.675***  -0.311***   1.649***                                    1.649*** \n",
      "                     (0.033)    (0.038)    (0.038)                                     (0.038)  \n",
      "                                                                                                \n",
      "diet                                                 -0.972***  -1.953***    0.008      0.008   \n",
      "                                                      (0.031)    (0.038)    (0.038)    (0.038)  \n",
      "                                                                                                \n",
      "sexfemale           -1.485***  -1.503***  -1.468***  -2.100***  -2.732***  -1.468***  -1.468*** \n",
      "                     (0.033)    (0.039)    (0.038)    (0.031)    (0.038)    (0.038)    (0.038)  \n",
      "                                                                                                \n",
      "T:diet                                                                                -1.961*** \n",
      "                                                                                       (0.054)  \n",
      "                                                                                                \n",
      "T:sexfemale         -1.827***  -2.449***  -1.263***                                   -1.263*** \n",
      "                     (0.046)    (0.055)    (0.053)                                     (0.054)  \n",
      "                                                                                                \n",
      "diet:sexfemale                                       -0.628***  -1.221***    -0.035     -0.035  \n",
      "                                                      (0.044)    (0.054)    (0.054)    (0.054)  \n",
      "                                                                                                \n",
      "T:diet:sexfemale                                                                      -1.186*** \n",
      "                                                                                       (0.076)  \n",
      "                                                                                                \n",
      "Constant            -75.711*** -75.531*** -75.844*** -74.867*** -74.181*** -75.553*** -75.691***\n",
      "                     (0.196)    (0.230)    (0.228)    (0.188)    (0.228)    (0.230)    (0.163)  \n",
      "                                                                                                \n",
      "------------------------------------------------------------------------------------------------\n",
      "Observations          20,000     9,854      10,146     20,000     10,000     10,000     20,000  \n",
      "R2                    0.968      0.979      0.978      0.971      0.979      0.978      0.978   \n",
      "Adjusted R2           0.968      0.979      0.978      0.971      0.979      0.978      0.978   \n",
      "Residual Std. Error   1.639      1.357      1.345      1.572      1.348      1.354      1.351   \n",
      "================================================================================================\n",
      "Note:                                                                *p<0.1; **p<0.05; ***p<0.01\n"
     ]
    }
   ],
   "source": [
    "model1 <- lm(wgt ~ hgt + Treatment * sex, data = sim.data)\n",
    "model2 <- lm(wgt ~ hgt + Treatment * sex, data = sim.data %>% filter(diet == 1))\n",
    "model3 <- lm(wgt ~ hgt + Treatment * sex, data = sim.data %>% filter(diet == 0))\n",
    "model4 <- lm(wgt ~ hgt + diet * sex, data = sim.data)\n",
    "model5 <- lm(wgt ~ hgt + diet * sex, data = sim.data %>% filter(Treatment == 1))\n",
    "model6 <- lm(wgt ~ hgt + diet * sex, data = sim.data %>% filter(Treatment == 0))\n",
    "model7 <- lm(wgt ~ hgt + Treatment * diet * sex, data = sim.data)\n",
    "\n",
    "\n",
    "stargazer(model1, \n",
    "          model2, \n",
    "          model3, \n",
    "          model4, \n",
    "          model5, \n",
    "          model6, \n",
    "          model7, \n",
    "          type = 'text',\n",
    "          df = FALSE,\n",
    "          omit.stat = c('F'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c2b7e5-4b52-4556-9edc-44ae9bdf8057",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using Repeated Cross-Section Data\n",
    "\n",
    "Return to the DID model for a bit,\n",
    "\n",
    "$$\n",
    "    ATET = \\left( \\mathbb{E}[Y_{i} \\mid G_{i} = 1, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid G_{i} = 1, T_{i} = 0] \\right) - \\left( \\mathbb{E}[Y_{i} \\mid G_{i} = 0, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid G_{i} = 0, T_{i} = 0] \\right).\n",
    "$$\n",
    "\n",
    "Nothing in this equation indicates that the individuals at $T = 1$ has to be the same as the individuals at $T = 0$. The implication is that it is possible to do DID with repeated cross-section data. Recap, repeated cross-section data is simply data where you have collected data from samples in multiple periods, but the sample in each period is a different sample. Unlike panel data, while you have a time index in the data there are no longitudinal observations at the unit level.\n",
    "\n",
    "The model in theory suggests two ways to run DID. I will discuss each in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab18f093-ebd6-4070-a863-1cf1f3c2a5e2",
   "metadata": {},
   "source": [
    "### Generating Repeated Cross-Section Data\n",
    "\n",
    "Data for repeated cross-section data is similar to panel data, except that instead of generating the unit first and then reusing the units over time you simply generate a new set of units in each time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5933623c-db80-4991-ae93-088b0daa385e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(1000)\n",
    "sim.data <- rbind(\n",
    "    tibble(i = c(1:10000), Treatment = 0, hgt = rnorm(10000, 1.68, 0.09), u = rnorm(10000, 0, 1)),\n",
    "    tibble(i = c(1:10000), Treatment = 1, hgt = rnorm(10000, 1.68, 0.09), u = rnorm(10000, 0, 1))\n",
    ")\n",
    "sim.data <- sim.data %>% mutate(diet = if_else(rnorm(20000, 0, 1) + u < 0, 0, 1), e = rnorm(20000, 0, 1) + u)\n",
    "sim.data <- sim.data %>% mutate(wgt = 2 * T + 28 * hgt ^ 2 - 3 * T * diet + e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f732941a-ca3f-4710-a3bf-5f90bcbe18d2",
   "metadata": {},
   "source": [
    "### DID on Repeated Cross-Section using OLS\n",
    "\n",
    "This is straightforward. As long as the sample in each period are independent, representative samples and you know which group in the \"before\" period would be given the treatment if you could observe them in the \"after\" period, then DID using OLS works the same way as in the panel data case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25133898-e0fb-4c36-bda9-f0d73e43580f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wgt ~ hgt + T * diet, data = .)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-5.1114 -0.8986 -0.0203  0.8910  5.9010 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) -79.52065    0.17772 -447.44   <2e-16 ***\n",
       "hgt          94.18162    0.10511  895.99   <2e-16 ***\n",
       "T             1.98072    0.02662   74.42   <2e-16 ***\n",
       "diet          1.09574    0.02670   41.05   <2e-16 ***\n",
       "T:diet       -2.96648    0.03775  -78.57   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 1.335 on 19995 degrees of freedom\n",
       "Multiple R-squared:  0.9759,\tAdjusted R-squared:  0.9759 \n",
       "F-statistic: 2.026e+05 on 4 and 19995 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim.data %>%\n",
    "    lm(wgt ~ hgt + Treatment * diet, data = .) %>%\n",
    "    summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8802e-e0eb-4bdf-9942-2d362feeef15",
   "metadata": {},
   "source": [
    "### DID using a $2 \\times 2$ Table\n",
    "\n",
    "What I refer to as the $2 \\times 2$ table is:\n",
    "\n",
    "| | $G = 0$ | $G = 1$ | |\n",
    "| ---: | :---: | :---: | :---: |\n",
    "| $T = 0$ | $\\mu_{Y}(0,0)$ | $\\mu_{Y}(1,0)$ | $\\mu_{Y}(1,0) - \\mu_{Y}(0,0)$ |\n",
    "| $T = 1$ | $\\mu_{Y}(0,1)$ | $\\mu_{Y}(1,1)$ | $\\mu_{Y}(1,1) - \\mu_{Y}(0,1)$ |\n",
    "| | $\\mu_{Y}(0,1) - \\mu_{Y}(0,0)$ | $\\mu_{Y}(1,1) - \\mu_{Y}(1,0)$ | $ATET$ |\n",
    "\n",
    "The principal problem is not in the point estimates. These are straightforward. The estimates for the central four cells are simply the four conditional means of the outcome variable. Then the estimates for the marginal cells are simply either row-wise or column-wise differences between the conditional means and the estimate of the ATET is the DID estimator using the conditional mean estimates in place of the true conditional expectations.\n",
    "\n",
    "The main problem is the question: How do you know that the ATET estimate is statistically significant? In other words, you want to test\n",
    "\n",
    "\\begin{align*}\n",
    "    H_{0} & : \\left( \\mu_{Y}(1,1) - \\mu_{Y}(1,0) \\right) - \\left( \\mu_{Y}(0,1) - \\mu_{Y}(0,0) \\right) = 0 \\\\\n",
    "    H_{1} & : \\left( \\mu_{Y}(1,1) - \\mu_{Y}(1,0) \\right) - \\left( \\mu_{Y}(0,1) - \\mu_{Y}(0,0) \\right) \\ne 0.\n",
    "\\end{align*}\n",
    "\n",
    "Recall the following:\n",
    "\n",
    "$$\n",
    "    Var(\\overline{X} + \\overline{Y}) = Var(\\overline{X}) + Var(\\overline{Y}) + 2 Cov(\\overline{X},\\overline{Y}).\n",
    "$$\n",
    "\n",
    "Note that this switching of notation from $\\mu$ (representing the true population-level conditional expectation) to $\\overline{X}$ (representing our sample analogue estimator of the population-level expectations) is not a mistake. $\\mu$ has a variance of zero because it is the true population parameter. On the other hand $\\overline{X}$ has a variance because it is a function of a random sample. A function of random variables is itself a random variable (think about adding two random variables---is it now non-random?), therefore it makes sense to talk about its distributional properties. Now, if the data for $X$ and $Y$ are independent, then\n",
    "\n",
    "$$\n",
    "    Var(\\overline{X} + \\overline{Y}) = Var(\\overline{X}) + Var(\\overline{Y}).\n",
    "$$\n",
    "\n",
    "If the data was collected well, in many cases we can assume that $\\overline{Y}\\mid_{G=0,T=0}$, $\\overline{Y}\\mid_{G=0,T=1}$, $\\overline{Y}\\mid_{G=1,T=0}$, and $\\overline{Y}\\mid_{G=1,T=1}$, are indeed independent. Which then implies that the SE of the estimator should just be\n",
    "\n",
    "$$\n",
    "    SE\\left( \\left( \\overline{Y}\\mid_{G=1,T=1} - \\overline{Y}\\mid_{G=1,T=0} \\right) - \\left( \\overline{Y}\\mid_{G=0,T=1} - \\overline{Y}\\mid_{G=0,T=0} \\right) \\right) = \\sqrt{ Var\\left(\\overline{Y}\\mid_{G=0,T=0}\\right) + Var\\left(\\overline{Y}\\mid_{G=0,T=1}\\right) + Var\\left(\\overline{Y}\\mid_{G=1,T=0}\\right) + Var\\left(\\overline{Y}\\mid_{G=1,T=1}\\right) }.\n",
    "$$\n",
    "\n",
    "We can compute the second term. Each variance term is effectively just the squared SE of a conditional mean. Recall from the conditional expectations notebook that this is computed simply as `varmean = var(X[G = g & T = t], na.rm = TRUE) / sum(G = g & T = t & !is.na(X))`.\n",
    "\n",
    "Finally, we need a distribution. If you remember what you should have learnt about the $t$-test before, you would know that in only one case is the degrees of freedom the straightforward $df_{1} + df_{2} - 2$. In all other cases there is a specific formula that does not necessarily yield an integer DF. What do we then do here? You have two main options without going too deeply into theory unrelated to this course:\n",
    "\n",
    "1. Assume that something analogous works for your situation as well, so that you compute your DF as\n",
    "$$\n",
    "    df_{0,0} + df_{0,1} + df_{1,0} + df_{1,1} - 4.\n",
    "$$\n",
    "2. Ignore the DF and assume that you have sufficient variables (as a rule-of-thumb, do you have at least $50$ observations in each of the four groups?) so that you can assume that some Law of Large Numbers holds and therefore the distribution of the test statistic is approximately Normal.\n",
    "\n",
    "These give rise to the following procedure that should be roughly appropriate for this level:\n",
    "\n",
    "0. Compute $\\overline{Y}\\mid_{G=1,T=1}$, $\\overline{Y}\\mid_{G=1,T=0}$, $\\overline{Y}\\mid_{G=0,T=1}$, $\\overline{Y}\\mid_{G=0,T=0}$, $Var\\left(\\overline{Y}\\mid_{G=0,T=0}\\right)$, $Var\\left(\\overline{Y}\\mid_{G=0,T=1}\\right)$, $Var\\left(\\overline{Y}\\mid_{G=1,T=0}\\right)$, and $Var\\left(\\overline{Y}\\mid_{G=1,T=1}\\right)$.\n",
    "1. Compute $\\theta = \\left( \\overline{Y}\\mid_{G=1,T=1} - \\overline{Y}\\mid_{G=1,T=0} \\right) - \\left( \\overline{Y}\\mid_{G=0,T=1} - \\overline{Y}\\mid_{G=0,T=0} \\right)$.\n",
    "2. Compute $s^{2} = \\sqrt{ Var\\left(\\overline{Y}\\mid_{G=0,T=0}\\right) + Var\\left(\\overline{Y}\\mid_{G=0,T=1}\\right) + Var\\left(\\overline{Y}\\mid_{G=1,T=0}\\right) + Var\\left(\\overline{Y}\\mid_{G=1,T=1}\\right) }$.\n",
    "3. Compute $\\frac{\\theta}{s}$ and label it either $t$ or $z$.\n",
    "4. If you used the $t$ label, compute $N\\mid_{G=0,T=0} + N\\mid_{G=0,T=1} + N\\mid_{G=1,T=0} + N\\mid_{G=1,T=1} - 4$ where $N$ means number of non-missing observations.\n",
    "5. Compute the $p$ value for your test using either the $t$-distribution or the Standard Normal distribution, depending on whether you used the $t$ or $z$ label respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532243b1-b37a-4034-805d-4d5b031584de",
   "metadata": {},
   "source": [
    "### Compute the $2 \\times 2$ Table of Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "587ca6da-4e87-4374-8825-5139857cf88d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            no diet      diet diff diet\n",
      "before    78.816257 79.707727  0.891470\n",
      "after     80.911836 79.043610 -1.868226\n",
      "diff time  2.095579 -0.664117 -2.759696\n"
     ]
    }
   ],
   "source": [
    "sim.res.mat <- matrix(\n",
    "    c(sim.data %>% filter(Treatment == 0 & diet == 0 & !is.na(wgt)) %>% .$wgt %>% mean, sim.data %>% filter(Treatment == 0 & diet == 1 & !is.na(wgt)) %>% .$wgt %>% mean, 0,\n",
    "      sim.data %>% filter(Treatment == 1 & diet == 0 & !is.na(wgt)) %>% .$wgt %>% mean, sim.data %>% filter(Treatment == 1 & diet == 1 & !is.na(wgt)) %>% .$wgt %>% mean, 0,\n",
    "      0, 0, 0),\n",
    "    nrow = 3,\n",
    "    ncol = 3,\n",
    "    byrow = TRUE\n",
    ")\n",
    "sim.res.mat[1,3] <- sim.res.mat[1,2] - sim.res.mat[1,1]\n",
    "sim.res.mat[2,3] <- sim.res.mat[2,2] - sim.res.mat[2,1]\n",
    "sim.res.mat[3,1] <- sim.res.mat[2,1] - sim.res.mat[1,1]\n",
    "sim.res.mat[3,2] <- sim.res.mat[2,2] - sim.res.mat[1,2]\n",
    "sim.res.mat[3,3] <- sim.res.mat[3,2] - sim.res.mat[3,1]\n",
    "rownames(sim.res.mat) <- c('before', 'after', 'diff time')\n",
    "colnames(sim.res.mat) <- c('no diet', 'diet', 'diff diet')\n",
    "print(sim.res.mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20370d78-5aaa-42fe-a119-b620abee52fb",
   "metadata": {},
   "source": [
    "### Compute the Variances Associated with each Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39ef3aef-840e-4fd2-8ba2-5d01d195952e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        no diet     diet\n",
      "before 72.81513 73.37404\n",
      "after  75.41587 71.59111\n"
     ]
    }
   ],
   "source": [
    "sim.var.mat <- matrix(\n",
    "    c(sim.data %>% filter(Treatment == 0 & diet == 0 & !is.na(wgt)) %>% .$wgt %>% var, sim.data %>% filter(Treatment == 0 & diet == 1 & !is.na(wgt)) %>% .$wgt %>% var,\n",
    "     sim.data %>% filter(Treatment == 1 & diet == 0 & !is.na(wgt)) %>% .$wgt %>% var, sim.data %>% filter(Treatment == 1 & diet == 1 & !is.na(wgt)) %>% .$wgt %>% var),\n",
    "    nrow = 2,\n",
    "    ncol = 2,\n",
    "    byrow = TRUE\n",
    ")\n",
    "rownames(sim.var.mat) <- c('before', 'after')\n",
    "colnames(sim.var.mat) <- c('no diet', 'diet')\n",
    "print(sim.var.mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08f345-5c0a-4685-b6f0-b852136127e3",
   "metadata": {},
   "source": [
    "### Compute the Counts in each Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82cac71e-c201-4bd5-b7ab-256d78483281",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       no diet diet\n",
      "before    5006 4994\n",
      "after     5054 4946\n"
     ]
    }
   ],
   "source": [
    "sim.n.mat <- matrix(\n",
    "    c(sim.data %>% filter(Treatment == 0 & diet == 0 & !is.na(wgt)) %>% .$wgt %>% length, sim.data %>% filter(Treatment == 0 & diet == 1 & !is.na(wgt)) %>% .$wgt %>% length,\n",
    "     sim.data %>% filter(Treatment == 1 & diet == 0 & !is.na(wgt)) %>% .$wgt %>% length, sim.data %>% filter(Treatment == 1 & diet == 1 & !is.na(wgt)) %>% .$wgt %>% length),\n",
    "    nrow = 2,\n",
    "    ncol = 2,\n",
    "    byrow = TRUE\n",
    ")\n",
    "rownames(sim.n.mat) <- c('before', 'after')\n",
    "colnames(sim.n.mat) <- c('no diet', 'diet')\n",
    "print(sim.n.mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8055287-b31f-4e88-bf88-98eaeb7fc429",
   "metadata": {},
   "source": [
    "### Compute the Test Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3976e0c6-3091-4fd6-82e6-0a1a83d8eb13",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -11.39684\n"
     ]
    }
   ],
   "source": [
    "sim.theta <- sim.res.mat[3,3] / sqrt(sum(sim.var.mat / sim.n.mat))\n",
    "print(sim.theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a429006-839c-4b63-baa7-215f2b7cf026",
   "metadata": {},
   "source": [
    "### Compute the $p$-Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e10f6420-4348-4de5-9675-d49ac1ad89b5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$`z-test`\n",
      "[1] 4.335754e-30\n",
      "\n",
      "$`t-test`\n",
      "[1] 5.366081e-30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    list(\n",
    "        'z-test' = 2 * pnorm(abs(sim.theta), 0, 1, lower.tail = FALSE),\n",
    "        't-test' = 2 * pt(abs(sim.theta), sum(sim.n.mat), lower.tail = FALSE)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a18ad1-8553-4a46-ba06-0b7e2a56e3f5",
   "metadata": {},
   "source": [
    "### Comparison Against Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2288345e-dba5-4879-a795-83d08bfa08a2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = wgt ~ T * diet, data = .)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-30.974  -5.901  -0.248   5.593  38.872 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  78.8163     0.1210 651.301  < 2e-16 ***\n",
       "T             2.0956     0.1707  12.274  < 2e-16 ***\n",
       "diet          0.8915     0.1712   5.206 1.95e-07 ***\n",
       "T:diet       -2.7597     0.2422 -11.395  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 8.562 on 19996 degrees of freedom\n",
       "Multiple R-squared:  0.009025,\tAdjusted R-squared:  0.008876 \n",
       "F-statistic:  60.7 on 3 and 19996 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim.data %>%\n",
    "    lm(wgt ~ Treatment * diet, data = .) %>%\n",
    "    summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94446956-0419-4e0b-a768-1593da76010a",
   "metadata": {},
   "source": [
    "### Summary for Repeated Cross-Section\n",
    "\n",
    "Clearly, you can compute the DID estimator manually with repeated cross-section data and it yields estimates of similar quality to what OLS provides. If doing it manually is your preference, go ahead. Otherwise, you should also take away from this section that OLS works just as well for repeated cross-section data. The presentation of the manual method is really just to show you in detail how the underlying statistics of this estimator works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4d3ce-55a3-42d2-a6e7-748908654fbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## When Parallel Trends Fails\n",
    "\n",
    "The key and only assumption for DID is parallel trends,\n",
    "\n",
    "$$\n",
    "    \\mathbb{E}[Y_{0,i}(0) \\mid T_{i} = 1] - \\mathbb{E}[Y_{0,i}(0) \\mid T_{i} = 0] = \\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 1] - \\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 0].\n",
    "$$\n",
    "\n",
    "What happens if this fails? Notice what happens to the bias when you compute the DID estimator,\n",
    "\n",
    "$$\n",
    "    \\theta - ATET = \\underbrace{\\left( \\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 1] - \\mathbb{E}[Y_{1,i}(0) \\mid T_{i} = 0] \\right)}_{\\text{Time Trend for $G_{i} = 1$}} - \\underbrace{\\left( \\mathbb{E}[Y_{0,i}(0) \\mid T_{i} = 1] - \\mathbb{E}[Y_{0,i}(0) \\mid T_{i} = 0] \\right)}_{\\text{Time Trend for $G_{i} = 0$}}.\n",
    "$$\n",
    "\n",
    "When parallel trends is not satisfied, there is no longer any guarantee that the trends for the two groups are in the same direction, such that DID reduces the bias in the estimator. In fact, if the two groups intuitively trend in opposite directions, DID exacerbates the bias. Can you think of situations where your treated and never-treated groups naturally trend in different directions over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39595806-3b11-4d90-b559-8f9b32711ec9",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "I will now simulate some data to simulate the case where parallel trends fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a23bb44f-7de0-4b8f-b7c0-095b8281e966",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       i              hgt              u                 diet       \n",
       " Min.   :    1   Min.   :1.278   Min.   :-4.25151   Min.   :0.0000  \n",
       " 1st Qu.: 2501   1st Qu.:1.556   1st Qu.:-0.67718   1st Qu.:0.0000  \n",
       " Median : 5000   Median :1.631   Median : 0.01236   Median :0.0000  \n",
       " Mean   : 5000   Mean   :1.630   Mean   :-0.00241   Mean   :0.4946  \n",
       " 3rd Qu.: 7500   3rd Qu.:1.704   3rd Qu.: 0.67019   3rd Qu.:1.0000  \n",
       " Max.   :10000   Max.   :2.017   Max.   : 4.07305   Max.   :1.0000  \n",
       "       T             e                  wgt        \n",
       " Min.   :0.0   Min.   :-6.319845   Min.   : 42.55  \n",
       " 1st Qu.:0.0   1st Qu.:-0.955488   1st Qu.: 67.61  \n",
       " Median :0.5   Median :-0.009791   Median : 74.62  \n",
       " Mean   :0.5   Mean   :-0.011837   Mean   : 74.99  \n",
       " 3rd Qu.:1.0   3rd Qu.: 0.940875   3rd Qu.: 81.91  \n",
       " Max.   :1.0   Max.   : 7.251245   Max.   :118.16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(998)\n",
    "sim.data <- tibble(i = c(1:10000), hgt = rnorm(10000, 1.63, 0.08), u = rnorm(10000, 0, 1))\n",
    "sim.data <- sim.data %>% mutate(diet = if_else(rnorm(10000, 0, 1) + u < 0, 0, 1))\n",
    "sim.data <- rbind(\n",
    "    sim.data %>% mutate(Treatment = 0, e = rnorm(10000, 0, 1) + u) %>% mutate(wgt = 28 * hgt ^ 2 + e),\n",
    "    sim.data %>% mutate(Treatment = 1, e = rnorm(10000, 0, 1) + u, hgt = if_else(diet == 1, hgt - .1, hgt + .1)) %>% mutate(wgt = 2 + 28 * hgt ^ 2 - 3 * diet + e)\n",
    ")\n",
    "summary(sim.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7960147-28f6-48bc-8e8c-dcaf93695596",
   "metadata": {},
   "source": [
    "### The $t$-Test Fails\n",
    "\n",
    "Intuitively, because the divergence in time trends is due to unaccounted for changes in other covariates, the $t$-test will be badly biased because it is not considering the possibility that other confounding factors may change differently between the groups over time. This again reflects the core intuition of the parallel trends assumption: the selection bias in treatment assignment has to be constant over time.\n",
    "\n",
    "In this case, because the time trends of the diet and non-diet group move in opposite directions, the simple DID (first row) is more biased than either the na&iuml;ve comparison measure (second row) or the before-after estimator (third row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7371f0d9-23fd-4654-a475-b225d858059f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "diff.data <- sim.data %>% filter(Treatment == 1) - sim.data %>% filter(Treatment == 0) %>% mutate(diet = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "040126b5-4ac6-4018-bd50-f01713019643",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 3 × 10\u001b[39m\n",
      "  estim…¹ estim…² estim…³ stati…⁴ p.value param…⁵ conf.…⁶ conf.…⁷ method alter…⁸\n",
      "    \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m  \n",
      "\u001b[90m1\u001b[39m  -\u001b[31m21\u001b[39m\u001b[31m.\u001b[39m\u001b[31m2\u001b[39m    -\u001b[31m9\u001b[39m\u001b[31m.\u001b[39m\u001b[31m81\u001b[39m    11.4  -\u001b[31m719\u001b[39m\u001b[31m.\u001b[39m        0    \u001b[4m9\u001b[24m998   -\u001b[31m21\u001b[39m\u001b[31m.\u001b[39m\u001b[31m3\u001b[39m  -\u001b[31m21\u001b[39m\u001b[31m.\u001b[39m\u001b[31m2\u001b[39m  Two S… two.si…\n",
      "\u001b[90m2\u001b[39m  -\u001b[31m20\u001b[39m\u001b[31m.\u001b[39m\u001b[31m3\u001b[39m    65.2     85.5  -\u001b[31m136\u001b[39m\u001b[31m.\u001b[39m        0    \u001b[4m9\u001b[24m998   -\u001b[31m20\u001b[39m\u001b[31m.\u001b[39m\u001b[31m6\u001b[39m  -\u001b[31m20\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m  Two S… two.si…\n",
      "\u001b[90m3\u001b[39m   -\u001b[31m9\u001b[39m\u001b[31m.\u001b[39m\u001b[31m81\u001b[39m   65.2     75.0   -\u001b[31m67\u001b[39m\u001b[31m.\u001b[39m\u001b[31m6\u001b[39m       0    \u001b[4m9\u001b[24m890   -\u001b[31m10\u001b[39m\u001b[31m.\u001b[39m\u001b[31m1\u001b[39m   -\u001b[31m9\u001b[39m\u001b[31m.\u001b[39m\u001b[31m53\u001b[39m Two S… two.si…\n",
      "\u001b[90m# … with abbreviated variable names ¹​estimate, ²​estimate1, ³​estimate2,\u001b[39m\n",
      "\u001b[90m#   ⁴​statistic, ⁵​parameter, ⁶​conf.low, ⁷​conf.high, ⁸​alternative\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "list(\n",
    "    t.test(\n",
    "        diff.data %>% filter(diet == 1) %>% select(wgt),\n",
    "        diff.data %>% filter(diet == 0) %>% select(wgt),\n",
    "        var.equal = TRUE\n",
    "    ),\n",
    "    t.test(\n",
    "        sim.data %>% filter(Treatment == 1, diet == 1) %>% select(wgt),\n",
    "        sim.data %>% filter(Treatment == 1, diet == 0) %>% select(wgt),\n",
    "        var.equal = TRUE\n",
    "    ),\n",
    "    t.test(\n",
    "        sim.data %>% filter(Treatment == 1, diet == 1) %>% select(wgt),\n",
    "        sim.data %>% filter(Treatment == 0, diet == 1) %>% select(wgt),\n",
    "        var.equal = TRUE\n",
    "    )\n",
    ") %>% \n",
    "    map_df(tidy) %>%\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e8a24-d319-4fcd-ac46-4d9397059777",
   "metadata": {},
   "source": [
    "### The Regression Method Still Works\n",
    "\n",
    "As you will see below, the regression method with controls still obtains the desired estimate. In fact, if you are paying attention, the OLS estimator gets the correct estimate despite misspecifying the form which height enters the model. This really gets to the heart of how closely linked regression methods (not just linear regression) and the CEF are. Notice that the regression model with controls is really estimating this:\n",
    "\n",
    "$$\n",
    "    ATET = \\left( \\mathbb{E}[Y_{i} \\mid X_{i}, G_{i} = 1, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid X_{i}, G_{i} = 1, T_{i} = 0] \\right) - \\left( \\mathbb{E}[Y_{i} \\mid X_{i}, G_{i} = 0, T_{i} = 1] - \\mathbb{E}[Y_{i} \\mid X_{i}, G_{i} = 0, T_{i} = 0] \\right).\n",
    "$$\n",
    "\n",
    "If controls $X_{i}$ are good enough proxies for the true reasons (or are the true reasons themselves) for divergence in time trends between the treated and never-treated groups, then the conditional version of the parallel trends assumption will be satisfied:\n",
    "\n",
    "$$\n",
    "    \\mathbb{E}[Y_{0,i}(0) \\mid X_{i}, T_{i} = 1] - \\mathbb{E}[Y_{0,i}(0) \\mid X_{i}, T_{i} = 0] = \\mathbb{E}[Y_{1,i}(0) \\mid X_{i}, T_{i} = 1] - \\mathbb{E}[Y_{1,i}(0) \\mid X_{i}, T_{i} = 0].\n",
    "$$\n",
    "\n",
    "This brings out the intuition for doing DID estimation with regression models. What you seek to control for is not selection bias---remember that DID has no problem with time-invariant selection bias. Instead, controls in the DID model should remove differences in the time trends of the treated and never-treated groups. This is what you need discuss when setting up your DID model and justifying the controls used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2da12aaa-8994-486c-b59b-d8f465df7e67",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================\n",
      "                                     Dependent variable:                  \n",
      "                    ------------------------------------------------------\n",
      "                                             wgt                          \n",
      "                       (1)        (2)        (3)        (4)        (5)    \n",
      "--------------------------------------------------------------------------\n",
      "hgt                 91.230***  88.464***  95.298***  91.147***            \n",
      "                     (0.172)    (0.166)    (0.112)    (0.119)             \n",
      "                                                                          \n",
      "diet                -1.881***               0.020     1.092***   0.927*** \n",
      "                     (0.044)               (0.024)    (0.027)    (0.149)  \n",
      "                                                                          \n",
      "T:diet                                               -2.989***  -21.219***\n",
      "                                                      (0.045)    (0.211)  \n",
      "                                                                          \n",
      "T                              -0.968***   0.807***   2.290***  11.405*** \n",
      "                                (0.031)    (0.021)    (0.030)    (0.149)  \n",
      "                                                                          \n",
      "Constant            -72.404*** -69.089*** -80.787*** -74.552*** 74.078*** \n",
      "                     (0.299)    (0.272)    (0.189)    (0.195)    (0.105)  \n",
      "                                                                          \n",
      "--------------------------------------------------------------------------\n",
      "Observations          10,000     9,892      20,000     20,000     20,000  \n",
      "R2                    0.988      0.977      0.979      0.983      0.481   \n",
      "Adjusted R2           0.988      0.977      0.979      0.983      0.481   \n",
      "Residual Std. Error   1.388      1.327      1.499      1.358      7.474   \n",
      "==========================================================================\n",
      "Note:                                          *p<0.1; **p<0.05; ***p<0.01\n"
     ]
    }
   ],
   "source": [
    "model1 <- lm(wgt ~ hgt + diet, data = filter(sim.data, Treatment == 1))\n",
    "model2 <- lm(wgt ~ hgt + Treatment, data = filter(sim.data, diet == 1))\n",
    "model3 <- lm(wgt ~ hgt + Treatment + diet, data = sim.data)\n",
    "model4 <- lm(wgt ~ hgt + Treatment * diet, data = sim.data)\n",
    "model5 <- lm(wgt ~ Treatment * diet, data = sim.data)\n",
    "\n",
    "stargazer(model1, \n",
    "          model2, \n",
    "          model3, \n",
    "          model4, \n",
    "          model5, \n",
    "          type = 'text',\n",
    "          df = FALSE,\n",
    "          omit.stat = c('F'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55120a48-62cf-45ed-b97c-28c5d39e91b5",
   "metadata": {},
   "source": [
    "## Exercise #: Difference-in-Differences in your Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71055f-4e51-49d3-ab77-f881deb89c58",
   "metadata": {},
   "source": [
    "### Load Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b230932d-cdf7-4b27-ac62-8fbbcf1dc3bc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘haven’ was built under R version 4.1.3”\n"
     ]
    }
   ],
   "source": [
    "library(haven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4ba2c96-ecda-46d1-8637-b668fa479e25",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "my.data <- 'load your data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a979c05-adc1-4ba7-9ebc-877d2bc93345",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "my.data <- 'clean your data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7500cea-81ca-441b-9bcc-53ce4d40aeae",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "Statistic N Mean St. Dev. Min Max\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "my.data %>% data.frame %>% stargazer(type = 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c0b0b-1a11-4d6e-b25a-c82b33720730",
   "metadata": {},
   "source": [
    "### Plan and Run some DD Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f158bc67-2829-4d7d-bc66-2360894b1ab6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in str2lang(x): <text>:1:7: unexpected symbol\n1: write your\n          ^\n",
     "output_type": "error",
     "traceback": [
      "Error in str2lang(x): <text>:1:7: unexpected symbol\n1: write your\n          ^\nTraceback:\n",
      "1. \"write your model\" %>% lm(, data = my.data)",
      "2. lm(., , data = my.data)",
      "3. eval(mf, parent.frame())",
      "4. eval(mf, parent.frame())",
      "5. stats::model.frame(formula = ., data = my.data, drop.unused.levels = TRUE)",
      "6. model.frame.default(formula = ., data = my.data, drop.unused.levels = TRUE)",
      "7. as.formula(formula)",
      "8. formula(object, env = baseenv())",
      "9. formula.character(object, env = baseenv())",
      "10. str2lang(x)"
     ]
    }
   ],
   "source": [
    "my.model.1 <- 'write your model' %>% lm(, data = my.data)\n",
    "my.model.1 %>% summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b36e77-dff3-44d3-a06b-3d86fabf005f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "my.model.2 <- 'write another model' %>% lm(, data = my.data)\n",
    "my.model.2 %>% summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75afc9de-6638-4446-bd56-b46f20a7c5ed",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "my.model.3 <- 'write as many models as you would like to estimate' %>% lm(, data = my.data)\n",
    "my.model.3 %>% summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52ca95-b26d-4efa-aec0-0f65b106d9ff",
   "metadata": {},
   "source": [
    "### Tabulate All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3ac75-bb58-48fb-9d77-143ff1ebafec",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "stargazer(\n",
    "    my.model.1,\n",
    "    my.model.2,\n",
    "    my.model.3,\n",
    "    type = 'html',\n",
    "    out = 'prj_dd_out.html',\n",
    "    out.header = TRUE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
