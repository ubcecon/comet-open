{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82f9cc8-86ab-4034-81e5-6a550681d3c0",
   "metadata": {},
   "source": [
    "# Introduction to Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cbeb30-2370-42fe-814f-e85a71504eb6",
   "metadata": {},
   "source": [
    "_R Version_\n",
    "<br>\n",
    "Authors: Anneke Dresselhuis,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db6c315-2ab3-4fa4-bf1b-f388128f6617",
   "metadata": {},
   "source": [
    "![Cover Art Image](media/sentiment_analysis_cover_art.png \"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea0809-c842-4e21-b651-f182fde7fd43",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prerequisites\n",
    "1. Introduction to Jupyter\n",
    "2. Introduction to R\n",
    "\n",
    "### Learning outcomes\n",
    "After completing this notebook, you will be able to: <br>\n",
    "1. Understand and apply the principles of ‚Äútidy text‚Äù data to clean a textual dataset\n",
    "2. Perform basic sentiment analysis using ...\n",
    "\n",
    "### Outline\n",
    "_To be finalized when notebook is complete_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7db7f-f42a-4fbb-8ef6-eeea79e33f45",
   "metadata": {},
   "source": [
    "## What is Sentiment Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa9eb4-2ff7-4d66-a8ef-e49204f93d31",
   "metadata": {},
   "source": [
    "‚ÄúSentiment analysis is the practice of applying natural language processing and text analysis techniques to identify and extract subjective information from text‚Äù (Hussein, 2018). As this definition alludes, sentiment analysis is a part of natural language processing (NLP) which is a field that exists at the intersection of human language and computation. Because humans are complex, emotional beings, the language we use is often shaped by our affective (emotional) dispositions. Sentiment analysis, sometimes referred to as ‚Äúopinion mining‚Äù is one way that researchers can methodologically understand the emotional intentions that lie in a textual dataset.\n",
    "\n",
    "> **üîé **Let‚Äôs think critically****\n",
    ">\n",
    ">  üü† At the heart of sentiment analysis is the assumption that language reveals interior, affective states, and that these states can be codified and generalized to broader populations. In her book, [Atlas of AI](https://katecrawford.net/atlas) the artificial intelligence scholar Kate Crawford explores how many assumptions found in contemporary sentiment research (ie, that there are 7 universal emotions, etc) are largely unsubstantiated notions that emerged from mid 20th century research funded by US Department of Defense. Rather than maintaining that emotions can be universally categorized, her work invites researchers to think about how emotional expression is highly contextualized by social and cultural factors and the distinct subject positions of content makers.\n",
    ">\n",
    "> üü† Consider the research question for your sentiment analysis project. How might the text you are working with be shaped by the distinct communities that have generated it?\n",
    ">\n",
    "> üü† Are there steps you can take to educate yourself around the unique language uses of your dataset (for example, directly speaking with someone from that group or learning from a qualified expert on the subject)?\n",
    ">\n",
    "> üü† If you‚Äôre interested, you can learn more about data justice in community research in a [guide](https://genderplusresearchcollective.sites.olt.ubc.ca/files/2022/09/2022-Gender-Guide-1.pdf) created by UBC‚Äôs Office for Regional and International Community Engagement. \n",
    "\n",
    "The rise of [web 2.0](https://en.wikipedia.org/wiki/Web_2.0) has produced prolific volumes of user-generated content (UGC) on the internet, particularly as people engage in a variety of social platforms and forums to share opinions, ideas and express themselves. Maybe you are interested in understanding how people feel about a particular political candidate by examining tweets around election time, or you wonder what people think about a particular bus route on reddit. UGC is often unstructured data, meaning that it isn‚Äôt organized in a recognizable way.\n",
    "<br>\n",
    "\n",
    "**Structured data** for a microwave product review might look something like this:\n",
    "\n",
    "|<span style=\"color: #CC7A00\">Pro</span> | <span style=\"color: #CC7A00\">Con</span> | <span style=\"color: #CC7A00\">Neutral</span>\n",
    "| :---| :----------- | :-- |\n",
    "| <span style=\"color: #CC7A00\">Interface is visually appealing</span> | <span style=\"color: #CC7A00\">Hard to change the time</span> | <span style=\"color: #CC7A00\">Purchased from store #553</span> |\n",
    "| <span style=\"color: #CC7A00\">Heats up food perfectly</span> | <span style=\"color: #CC7A00\">Plug cord length is too short</span> | <span style=\"color: #CC7A00\">Product weighed 23lbs</span> |\n",
    "\n",
    "**Unstructured data** for a microwave product review might look something like this:\n",
    "\n",
    "> <span style=\"color: #CC7A00\">I bought the WAV0 X5K microwave last week. When i got home I was tryign to set it up and needed to go out and buy an extension cord because the one on the thing was too short. Took me 20 mins to figure out how to change the time, but teh interface was visually appealing. When I finally got working, it heated up my leftover take-out dinner perfectly.<span style=\"color: #CC7A00\">\n",
    "<br>\n",
    "    \n",
    "In the structured data example above, the reviewer defines which parts of the feedback are positive, negative or neutral. In the unstructured example on the other hand, there are many typos and a given sentence might include a positive and a negative review as well as more nuanced contextual information (ie, that the person had to buy an additional product to make the microwave work). While messy, this contextual information often carries valuable insights that can be very useful for researchers.\n",
    "<br>\n",
    "The task of sentiment analysis is to make sense of these kinds of nuanced textual data - often for the purpose of understanding people, predicting human behaviour, or even in some cases, manipulating human behaviour.\n",
    "<br>\n",
    "    \n",
    "**Language is complex and always changing.**\n",
    "<br>\n",
    "    \n",
    "In the English language, for example, the word ‚Äúpresent‚Äù has multiple meanings which could have positive, negative or neutral connotations. Further, a contemporary sentiment lexicon might code the word ‚Äúmiss‚Äù as being associated with negative or sad emotional experiences such as longing; if such a lexicon were applied to a 19th century novel which uses the word ‚Äúmiss‚Äù to describe single women, then, it might incorrectly associate negative sentiment where it shouldn‚Äôt be. While sentiment analysis can be a useful tool, it demands ongoing criticality and reflexivity from a researcher (you!). Throughout your analysis, be sure to continually ask yourself whether a particular sentiment lexicon is appropriate for your project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a289f-97a1-4690-818b-63721fb498c7",
   "metadata": {},
   "source": [
    "## Working with Textual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e897d1d-8e85-458d-86eb-c279b5fc5e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce66337e-a064-4cb6-9d43-5b59a16d8ca2",
   "metadata": {},
   "source": [
    "### Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a06ce-2bf8-425c-805a-15665806fb7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# these may take a while to load (it might be worth moving this cell to the top)\n",
    "#install.packages(\"quanteda\")\n",
    "#install.packages(\"tidytext\")\n",
    "#install.packages(\"SentimentAnalysis\")\n",
    "#install.packages(\"textdata\")\n",
    "library(tidytext)\n",
    "library(readr)\n",
    "library(tidyverse)\n",
    "library(quanteda)\n",
    "library(janeaustenr)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(stringr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab94c9-c4ee-43f9-8276-c46598bee04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct dataframe\n",
    "username <- c(\"@potus\", \"@abject.ron\", \"@tess888\", \"@ayden99\", \"@curious_reggie\", \n",
    "                    \"@peter.the.third\", \"@xavier_w\", \"@humble.pacifist\", \n",
    "                    \"@krz4377\", \"@not.nat\")\n",
    "policy_text <- c(\"Today we changed prehistoric policies held our great country back from progress.\", \n",
    "            \"@potus this policy change is an abomination of everything America stands for\", \n",
    "            \"I have completely lost trust in the government\", \n",
    "            \"I am hopeful things will get better after this valuable change\", \n",
    "            \"Navigating the past is always a challenge, but one that can be overcome through hard work.\",\n",
    "            \"Can our country recover from this?\",\n",
    "            \"@ayden99 - Progress wins. A victory for America today.\",\n",
    "            \"Poor call @potus - old rules kept us from making the mistakes of the past...\",\n",
    "            \"I'm sick of aristocracy stamping out the people's power\",\n",
    "            \"Definitely some mixed feelings about today's decision. Some wins, some losses, but hey - that's democracy.\")\n",
    "\n",
    "policy_df <- tibble(username = username, text=policy_text) %>%\n",
    "group_by(username)\n",
    "\n",
    "policy_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb78ff-8f43-4728-86fd-28a1307934e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "policy_token <- policy_df  %>%\n",
    "    unnest_tokens(output = word, \n",
    "                  input = text,\n",
    "                  token = \"words\", # this specifies that we want a token to be 1 word\n",
    "                  to_lower = TRUE) # converts all text to uniform lowercase\n",
    "            \n",
    "head(policy_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25aaad-4e74-4346-b925-8af255830d39",
   "metadata": {},
   "source": [
    "In the above code, try changing the argument `token = \"words\"` to `token = \"characters\"` or `token = \"sentences\"` <br>\n",
    "<br>\n",
    "What do you see? <br>\n",
    "<br>\n",
    "If we were interested in running our sentiment analysis at a higher level, for example, by considering sentences as tokens, we could also do that. If you are interested, you can read more about documentation for the `unnest_tokens` function [here](https://www.rdocumentation.org/packages/tidytext/versions/0.4.2/topics/unnest_tokens) or by typing \n",
    "`?unnest_tokens` into a code cell. For the purpose of this analysis, we will be working at the word level; be sure to return the above argument to `token = \"words\"` when you are ready to continue the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893ca3e-3290-45b7-985c-3bed9568a7a7",
   "metadata": {},
   "source": [
    "#### Negative Sentiment\n",
    "If we are only interested in identifying the words in our corpus of tweets that contain negative (as opposed to positive) sentiment, we can use the `bing` library, created by [Bing and collaborators](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef670442-3613-4fda-b55b-ae811dc8324d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head(get_sentiments(\"bing\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752e4e3-5c04-4c18-85cb-b93c1cbe7da1",
   "metadata": {},
   "source": [
    "This library contains a list of 6,786 words that have been pre-classified as being associated with negative or positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497b0d1-cd5c-472f-abf4-84e0ab52cbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_sentiments <- get_sentiments(\"bing\") %>% \n",
    "    filter(sentiment == \"negative\") # select only the negative words\n",
    "\n",
    "negative_policy <- policy_token %>%\n",
    "    inner_join(negative_sentiments) %>% \n",
    "    count(word, sort = TRUE) # count the number of negative words\n",
    "\n",
    "head(negative_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532944c-0b88-4694-8854-87128958585b",
   "metadata": {},
   "source": [
    "#### Negative and Positive Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb748d0-19dc-4bf6-9fe2-60ab26d92c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_policy <- policy_token %>%\n",
    "    inner_join(get_sentiments(\"bing\")) %>% # adds column with binary sentiment library\n",
    "    count(word, sentiment) %>%\n",
    "    pivot_wider(names_from = sentiment, values_from = n, values_fill = 0)\n",
    "head(sentiment_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a00086-22e1-4d1a-962c-ef84279d043a",
   "metadata": {},
   "source": [
    "#### summarizing sentence level sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a121133b-736e-4f01-a82b-d7a8a5e19f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_policy2 <- policy_token %>%\n",
    "    inner_join(get_sentiments(\"bing\")) %>% # adds column with binary sentiment library\n",
    "    count(username, word, sentiment) %>%\n",
    "    pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%\n",
    "    mutate(sentiment = positive - negative)\n",
    "sentiment_policy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6150686-3de2-4b70-a7e8-8d3bf281baaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "policy_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df4815-dc5e-422a-96aa-92be68cc5ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bing_word_counts <- policy_token %>%\n",
    "  inner_join(get_sentiments(\"bing\")) %>%\n",
    "  count(word, sentiment, sort = TRUE) %>%\n",
    "  ungroup()\n",
    "\n",
    "bing_word_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c6da9-313a-4627-b77c-173c72890dff",
   "metadata": {},
   "source": [
    "We can further look at the summed score for a given user's tweet beyond the individual words. <br>\n",
    "For example, if we ran the code, `with(sentiment_policy2, sum(sentiment[username == \"@curious_reggie\"]))` we would get a value of `-1` because `(-1) + (-1) + (+1) = -1`\n",
    "<br>\n",
    "Try out a few different usernames in the blank `...` code below: \n",
    "* \"@potus\"\n",
    "* \"@abject.ron\" \n",
    "* \"@tess888\" \n",
    "* \"@ayden99\" \n",
    "* \"@curious_reggie\" \n",
    "* \"@peter.the.third\"\n",
    "* \"@xavier_w\"\n",
    "* \"@humble.pacifist\"\n",
    "* \"@krz4377\"\n",
    "* \"@not.nat\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3883a0-7cc1-47af-b105-4024af9a752d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with(sentiment_policy2, sum(sentiment[username == \"@curious_reggie\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e9ddd-0705-4297-b3bc-b7c7449891f5",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51e517-4e5b-450d-b89e-49ea2f035991",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b76ec-f9a6-45d3-8cc1-50f2ec449d20",
   "metadata": {},
   "source": [
    "* Air Force Institute of Technology. (n.d.). Text Mining: Sentiment Analysis ¬∑ AFIT Data Science Lab R Programming Guide. Retrieved May 31, 2024, from https://afit-r.github.io/sentiment_analysis\n",
    "* Benoit, K., Watanabe, K., Wang, H., Nulty, P., Obeng, A., M√ºller, S., & Matsuo, A. (2018). quanteda: An R package for the quantitative analysis of textual data. Journal of Open Source Software, 3(30), 774. https://doi.org/10.21105/joss.00774\n",
    "* Hicks, S. (2022, October 13). Tidytext and sentiment analysis: Introduction to tidytext and sentiment analysis. https://www.stephaniehicks.com/jhustatcomputing2022/posts/2022-10-13-working-with-text-sentiment-analysis/\n",
    "* Hussein, D. M. E.-D. M. (2018). A survey on sentiment analysis challenges. Journal of King Saud University - Engineering Sciences, 30(4), 330‚Äì338. https://doi.org/10.1016/j.jksues.2016.04.002\n",
    "* Liu, B. (2011). Sentiment Analysis and Opinion Mining. Department of Computer Science University Of Illinois at Chicago. https://www.cs.uic.edu/~liub/FBS/Sentiment-Analysis-tutorial-AAAI-2011.pdf\n",
    "* Robinson, D. (2016, July 21). Does sentiment analysis work? A tidy analysis of Yelp reviews. Variance Explained. http://varianceexplained.org/r/yelp-sentiment/\n",
    "* Silge, J., & Hvitfeldt, E. (2022). Supervised Machine Learning for Text Analysis in R. https://smltar.com/\n",
    "* Silge, J., & Robinson, D. (2017). Welcome to Text Mining with R | Text Mining with R. https://www.tidytextmining.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca2f6cb-f13b-41ad-a1e5-f44f37a76356",
   "metadata": {},
   "source": [
    "# Seeing the stop words in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a62685-a2e6-4213-aba3-29a76dc3019c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "policy_df %>%\n",
    "unnest_tokens(output = word, input = text) %>%\n",
    "count(word, sort = TRUE) %>%\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820daa97-3e0c-45ed-8d3a-edb88f7bc3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e19fc043-4036-4f97-93ff-5fb03ca9836f",
   "metadata": {},
   "source": [
    "# Playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f66100-9e96-4f2a-8caa-67329a08f883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d03b2f-f2fb-41e5-9066-c284b2f0d44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data <- corpus_subset(data_corpus_inaugural, Year > 1939 & Year < 1945)\n",
    "\n",
    "# make a dfm\n",
    "data_dfm <- data %>%\n",
    "    tokens() %>%\n",
    "    dfm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fea595-d568-4a1d-8664-57d0da53c9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data <- corpus_subset(data_corpus_amicus)\n",
    "\n",
    "# make a dfm\n",
    "data_dfm <- data %>%\n",
    "    tokens() %>%\n",
    "    dfm()\n",
    "print(data_dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb3b6e-ec24-4cee-99c7-35fa2c1e8227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
