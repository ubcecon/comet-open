---
jupyter: python3
---

```{python}
##Make sure you have OpenAI library installed
##pip install openai
```

```{python}
from openai import OpenAI
import os

##Import the OpenAI library in Python
```

```{python}
# Program to read the entire file using read() function
file = open("api_key.txt", "r")
content = file.read()
file.close()
```

```{python}
client = OpenAI(api_key=content)

##Set the API Key. Replace "api_key" to your own API key.
```

```{python}
##This code defines a function send_request that sends a request to OpenAI's GPT-3.5 model with 
##specified hyperparameters and returns the generated text.

def send_request(messages, temperature=0.7, presence_penalty=0.0, top_p=0.9, frequency_penalty=0.0):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "system", "content": f"{messages}"}],
        max_tokens=200,
        temperature=temperature,
        presence_penalty=presence_penalty,
        top_p=top_p,
        frequency_penalty=frequency_penalty  # Add the frequency_penalty parameter
    )
    generated_comment = str(response.choices[0].message)
    return generated_comment
```

```{python}
##Generate Text based on Prompt
```

```{python}
question = "tell me a story about an econ PhD student"  # Define the question Variable.
print('ask:', question)  # Print the Input Question.

# Generate Text with different hyperparameters
response_low_temp = send_request(question, temperature=0.3, presence_penalty=0.5, top_p=0.7, frequency_penalty=0.5)
response_med_temp = send_request(question, temperature=0.7, presence_penalty=0.0, top_p=0.8, frequency_penalty=0.3)
response_high_temp = send_request(question, temperature=1.0, presence_penalty=0.9, top_p=0.9, frequency_penalty=0.1)

print('GPT (Low Temp):', response_low_temp)  # Print Low Temperature Output
print('GPT (Med Temp):', response_med_temp)  # Print Medium Temperature Output
print('GPT (High Temp):', response_high_temp)  # Print High Temperature Output
```

