{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c48b76",
   "metadata": {},
   "source": [
    "# ECON 490: Instrumental Variables (19)\n",
    "\n",
    "## Prerequisites:\n",
    "---\n",
    "1. Run OLS regressions.\n",
    "\n",
    "## Learning objectives:\n",
    "---\n",
    "\n",
    "1. Understand what an instrumental variable is and the conditions it must satisfy to address the endogeneity problem.\n",
    "2. Implement a Two Stage Least Squares (2SLS) regression-based approach using an instrument. \n",
    "3. Describe what the weak instrument problem is.\n",
    "4. Interpret the first stage test of whether the instrument is weak or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4973e0",
   "metadata": {},
   "source": [
    "## 19.1 What problem are we trying to fix to begin with?\n",
    "\n",
    "Consider a case where we want to know the Average Treatment Effects (ATE), defined as \n",
    "$$E[ Y_i(1) - Y_i(0) ] $$\n",
    "\n",
    "where $Y_i(1)$ is the outcome had the individual been treated and $Y_i(0)$ had she not been treated. The problem of causal inference is that we cannot observe both potential outcomes at the same time, i.e. a unit was either treated or not treated. When we have treatment $D_i$ that is good as random, these potential outcomes do not depend on $D_i$ (otherwise $D_i$ would have been correlated with these $Y$s). Formally,\n",
    "\n",
    "$$\\begin{align} \n",
    "E[Y_i(0) \\mid D_i=1] &= E[Y_i(0) \\mid D_i=0] = E[Y_i(0)], \\quad \\text{    and } \\\\\n",
    "E[Y_i(1) \\mid D_i=1] &= E[Y_i(1) \\mid D_i=0] = E[Y_i(1)].\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Notice that the previous set of equations say that we can condition on any value of $D_i$ and it would be the same as if we didn't condition. When this holds, we can infer the average treatment effects \n",
    "\n",
    "$$\\begin{align} \n",
    "E[ Y_i(1) - Y_i(0) ] &= E[ Y_i(1)] - E[ Y_i(0)] \\\\\n",
    "&= E[ Y_i(1) \\mid D_i=1] - E[ Y_i(0) \\mid D_i=0], \\quad \\text{by independence of $D_i$.}\\\\\n",
    "&= E[ Y_i \\mid D_i=1] - E[ Y_i \\mid D_i=0], \\quad \\text{because those are the outcomes that are observed for those groups.}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "A regression-based approach to that same issue can be formulated with the following model, \n",
    "\n",
    "$$Y_{i} = \\alpha + \\beta D_i + \\epsilon_i$$\n",
    "\n",
    "where we assume $E[\\epsilon_i \\mid D_i] =0$. This condition is equivalent to the potential outcome model, it states that there are no unobserved differences across treated and untreated units. In other words, treatment is (mean) independent to whatever explains the outcome.  \n",
    "\n",
    "\n",
    "The punchline is that randomization is a great way to tackle the fundamental problem of causal inference: observing averages of counterfactuals. However, in *most* economic applications this will not be the case. The instrumental variables approach relies on finding something that is as good as random that affects the treatment and thus indirectly affect the outcome. The trick is to split the treatment into two pieces: one that is as-good-as-random part and one that is non-random. We then use the former to estimate causal effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b22be",
   "metadata": {},
   "source": [
    "## 19.2 The Linear IV Model\n",
    "\n",
    "Consider the following model \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Y_i &= \\alpha_1 + \\beta D_i + \\gamma_1 X_i + u_i  \\quad \\text{(Structural Equation)}\\\\\n",
    "D_i &= \\alpha_2 + \\gamma_2 Z_i + \\gamma_3 X_i + e_i  \\quad \\text{(First Stage Equation)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $Z_i$ is called an instrumental variable. An instrumental variable must satisfy two conditions:\n",
    "- It must affect treatment assignment ($\\gamma_2 \\neq 0$).\n",
    "- It must be uncorrelated with $u_i$, i.e. it should not be part of the Structural Equation. \n",
    "\n",
    "These two conditions imply that the instrument must affect the outcome $Y$ *only through* its effect on treatment $D$. A well-known example of this model is studied by Angrist and Krueger (1991). It is the case where $Y$ are earnings, $D$ is years of schooling and $Z$ is the quarter of birth. The idea is that students are required to enter school in the year where they turn 6, creating this relationship between quarter of birth and schooling. At the same time, the time of the year you are born shouldn't really affect your earnings aside from it's effect on schooling.\n",
    "\n",
    "\n",
    "### 19.2.1 Two-Stage Least Squares (2SLS) \n",
    "\n",
    "The 2SLS approach is simple at heart. The two steps are the following.\n",
    "\n",
    "1. Estimate the First Stage Equation by OLS, and obtain the predicted value of $D_i$. That is $\\hat{D_i} \\equiv \\hat{\\alpha_2} + \\hat{\\gamma_2} Z_i + \\hat{\\gamma_3} X_i $.\n",
    "\n",
    "2. Plug $\\hat{D_i}$ instead of $D_i$ in the Structural Equation, and estimate via OLS. We are then using the \"as-good-as-random\" part of $D_i$ to capture $\\beta$. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Caution**: We can run 2SLS following the steps above, but when we want to do inference we need to be sure we're using the true residuals in the Structural equation $\\hat{u}_i$. When we do the manual approach, Stata will report the standard errors based on  $\\hat{u}_i +  $\\hat{e}_i$$, which would be wrong. The solution is to use the built-in command `ivregress` or `ivreg2`!\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stata",
   "language": "stata",
   "name": "stata"
  },
  "language_info": {
   "codemirror_mode": "stata",
   "file_extension": ".do",
   "mimetype": "text/x-stata",
   "name": "stata",
   "version": "15.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
