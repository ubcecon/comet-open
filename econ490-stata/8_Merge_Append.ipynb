{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1c10ba",
   "metadata": {},
   "source": [
    "# ECON 490: Merge and Append (8)\n",
    "\n",
    "## Prerequisites \n",
    "---\n",
    "1. Effectively use Stata do-files and generate log-files.\n",
    "2. Be able to change your directory so that Stata can find your files.\n",
    "3. Import datasets in csv and dta format. \n",
    "4. Save data files. \n",
    "5. Create new variables using the command `egen` and pre-commands`by` and `bysort`.\n",
    "\n",
    "## Learning Outcomes\n",
    "---\n",
    "1. Adding new variables to an existing dataset (merge).\n",
    "2. Adding new observations to already existing variables (append).\n",
    "\n",
    "## 8.1 Introduction to Merge and Append\n",
    "\n",
    "Often when we are working with data sets it will be necessary to merge or append this data with other data sets. For example, imagine that you want to do one of the following:\n",
    "\n",
    "- You want to run a regression that has national fertility rate the main dependent variable and GDP/capita as an explanitory variable. You have one macro data set that has three variables - country, year, and fertility rate - and a second macro data set also with three variables - country, year, and GDP/capita. To do your research you would need to merge these two data sets to create a final data set. That final data set would have the same number of observations as the intital data set(s), but now with four variables: country, year, fertility rate and GDP/capita. \n",
    "\n",
    "- You want to run a regression that has number of births as the main dependent variable and education level of the mother as an explanitory variable. You have two such micro data sets, one from Canada and one from the US, and you want to combine them into one data set that includes observations from both countries. To do your reseaarch you would need to take one data set (say, the Canadian data) and append the second data set (here, the US data). This final data set would have same number of variables as the intial data set(s) but the number of observations would be the number of observations of the Canadian data set plus the number of observations of the US data set.\n",
    "\n",
    "Here you will be learning how to undertake these two approaches to combining data sets: merge and append. \n",
    "\n",
    "We'll continue working with the fake data dataset introduced in the previous lecture. Recall that this dataset is simulating information of workers in the years 1982-2012 in a fake country where a training program was introduced in 2003 to boost their earnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c10420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "/Users/marinaadshade/Documents/TELF Project/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clear*\n",
    "\n",
    "cd \"/Users/marinaadshade/Documents/TELF Project/raw\"\n",
    "use fake_data, clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e4b1d2-c3d1-4f94-b776-db96a4bba980",
   "metadata": {},
   "source": [
    "## 8.2 Getting Ready to Merge and Append\n",
    "\n",
    "Before introducing the command `merge`, we need the follow the steps below in order to properly combine datasets.\n",
    "\n",
    "#### 8.2.1 Check the data set's unique identifiers \n",
    "\n",
    "The key to merging data sets is to understand what are the variables that uniquely identify each observation.\n",
    "\n",
    "Let's look at our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c8f989c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workerid</th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>age</th>\n",
       "      <th>start_year</th>\n",
       "      <th>region</th>\n",
       "      <th>treated</th>\n",
       "      <th>earnings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>M</td>\n",
       "      <td>1944</td>\n",
       "      <td>55</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39975.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>M</td>\n",
       "      <td>1944</td>\n",
       "      <td>57</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>278378.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2001</td>\n",
       "      <td>M</td>\n",
       "      <td>1947</td>\n",
       "      <td>54</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18682.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>M</td>\n",
       "      <td>1947</td>\n",
       "      <td>55</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>293336.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>M</td>\n",
       "      <td>1947</td>\n",
       "      <td>56</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>111797.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>M</td>\n",
       "      <td>1951</td>\n",
       "      <td>54</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>88351.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>M</td>\n",
       "      <td>1951</td>\n",
       "      <td>59</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>46229.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>1997</td>\n",
       "      <td>M</td>\n",
       "      <td>1952</td>\n",
       "      <td>45</td>\n",
       "      <td>1997</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>24911.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>2001</td>\n",
       "      <td>M</td>\n",
       "      <td>1952</td>\n",
       "      <td>49</td>\n",
       "      <td>1997</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9908.3623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>M</td>\n",
       "      <td>1954</td>\n",
       "      <td>55</td>\n",
       "      <td>1998</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>137207.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "     +----------------------------------------------------------------------+\n",
       "  1. | workerid | year | sex | birth_~r | age | start_~r | region | treated |\n",
       "     |        1 | 1999 |   M |     1944 |  55 |     1997 |      1 |       0 |\n",
       "     |----------------------------------------------------------------------|\n",
       "     |                               earnings                               |\n",
       "     |                               39975.01                               |\n",
       "     +----------------------------------------------------------------------+\n",
       "\n",
       "     +----------------------------------------------------------------------+\n",
       "  2. | workerid | year | sex | birth_~r | age | start_~r | region | treated |\n",
       "     |        1 | 2001 |   M |     1944 |  57 |     1997 |      1 |       0 |\n",
       "     |----------------------------------------------------------------------|\n",
       "     |                               earnings                               |\n",
       "     |                               278378.1                               |\n",
       "     +----------------------------------------------------------------------+\n",
       "\n",
       "     +----------------------------------------------------------------------+\n",
       "  3. | workerid | year | sex | birth_~r | age | start_~r | region | treated |\n",
       "     |        2 | 2001 |   M |     1947 |  54 |     2001 |      4 |       0 |\n",
       "     |----------------------------------------------------------------------|\n",
       "     |                               earnings                               |\n",
       "     |                                18682.6                               |\n",
       "     +----------------------------------------------------------------------+\n",
       "\n",
       "     +----------------------------------------------------------------------+\n",
       "  4. | workerid | year | sex | birth_~r | age | start_~r | region | treated |\n",
       "     |        2 | 2002 |   M |     1947 |  55 |     2001 |      4 |       0 |\n",
       "     |----------------------------------------------------------------------|\n",
       "     |                               earnings                               |\n",
       "     |                               293336.4                               |\n",
       "     +----------------------------------------------------------------------+\n",
       "\n",
       "     +----------------------------------------------------------------------+\n",
       "  5. | workerid | year | sex | birth_~r | age | start_~r | region | treated |\n",
       "     |        2 | 2003 |   M |     1947 |  56 |     2001 |      4 |       0 |\n",
       "     |----------------------------------------------------------------------|\n",
       "     |                               earnings                               |\n",
       "     |                               111797.3                               |\n",
       "     +----------------------------------------------------------------------+\n",
       "\n",
       "     +----------------------------------------------------------------------+\n",
       "  6. | workerid | year | sex | birth_~r | age | start_~r | region | treated |\n",
       "     |        3 | 2005 |   M |     1951 |  54 |     2005 |      5 |       0 |\n",
       "     |----------------------------------------------------------------------|\n",
       "     |                               earnings                               |\n",
       "     |                               88351.67                               |\n",
       "     +----------------------------------------------------------------------+\n",
       "\n",
       "     +----------------------------------------------------------------------+\n",
       "  7. | workerid | year | sex | birth_~r | age | start_~r | region | treated |\n",
       "     |        3 | 2010 |   M |     1951 |  59 |     2005 |      5 |       0 |\n",
       "     |----------------------------------------------------------------------|\n",
       "     |                               earnings                               |\n",
       "     |                               46229.57                               |\n",
       "     +----------------------------------------------------------------------+\n",
       "\n",
       "     +----------------------------------------------------------------------+\n",
       "  8. | workerid | year | sex | birth_~r | age | start_~r | region | treated |\n",
       "     |        4 | 1997 |   M |     1952 |  45 |     1997 |      5 |       1 |\n",
       "     |----------------------------------------------------------------------|\n",
       "     |                               earnings                               |\n",
       "     |                               24911.03                               |\n",
       "     +----------------------------------------------------------------------+\n",
       "\n",
       "     +----------------------------------------------------------------------+\n",
       "  9. | workerid | year | sex | birth_~r | age | start_~r | region | treated |\n",
       "     |        4 | 2001 |   M |     1952 |  49 |     1997 |      5 |       1 |\n",
       "     |----------------------------------------------------------------------|\n",
       "     |                               earnings                               |\n",
       "     |                               9908.362                               |\n",
       "     +----------------------------------------------------------------------+\n",
       "\n",
       "     +----------------------------------------------------------------------+\n",
       " 10. | workerid | year | sex | birth_~r | age | start_~r | region | treated |\n",
       "     |        5 | 2009 |   M |     1954 |  55 |     1998 |      2 |       1 |\n",
       "     |----------------------------------------------------------------------|\n",
       "     |                               earnings                               |\n",
       "     |                               137207.3                               |\n",
       "     +----------------------------------------------------------------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%browse 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80707f",
   "metadata": {},
   "source": [
    "Here we can see that each observation in the fake_data dataset is identified by the variables *workerid* and *year* (worker-year pairs). \n",
    "\n",
    "We can check to see if this is correct using the command `duplicates report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ef249c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicates in terms of workerid year\n",
      "\n",
      "--------------------------------------\n",
      "   Copies | Observations       Surplus\n",
      "----------+---------------------------\n",
      "        1 |      2861772             0\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "duplicates report workerid year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b0a22",
   "metadata": {},
   "source": [
    "What this table shows is that there are 2,861,772 workerid-year combination (which is exactly equal to all of our observations). This means that every observation we have corresponds to a worker in a particular year. \n",
    "\n",
    "Let's take a look at a different data set now also stored in the folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "537212ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "use region_year_data, clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1b4c0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "      <th>avg_log_earnings</th>\n",
       "      <th>total_employment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>10.506687</td>\n",
       "      <td>30004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>10.513171</td>\n",
       "      <td>31367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.511585</td>\n",
       "      <td>33429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>10.550608</td>\n",
       "      <td>34547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>10.529206</td>\n",
       "      <td>35503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>10.615291</td>\n",
       "      <td>35809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>10.558952</td>\n",
       "      <td>36161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>10.538996</td>\n",
       "      <td>36966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>10.511196</td>\n",
       "      <td>38161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>10.525853</td>\n",
       "      <td>38051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "     +-------------------------------------+\n",
       "     | year   region   avg_lo~s   total_~t |\n",
       "     |-------------------------------------|\n",
       "  1. | 1998        1   10.50669      30004 |\n",
       "  2. | 1999        1   10.51317      31367 |\n",
       "  3. | 2000        1   10.51159      33429 |\n",
       "  4. | 2001        1   10.55061      34547 |\n",
       "  5. | 2002        1   10.52921      35503 |\n",
       "     |-------------------------------------|\n",
       "  6. | 2003        1   10.61529      35809 |\n",
       "  7. | 2004        1   10.55895      36161 |\n",
       "  8. | 2005        1     10.539      36966 |\n",
       "  9. | 2006        1    10.5112      38161 |\n",
       " 10. | 2007        1   10.52585      38051 |\n",
       "     +-------------------------------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%browse 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e201a54",
   "metadata": {},
   "source": [
    "In this case, it seems that every observation corresponds to a region and year combination. Again, we can use `duplicates report` to see if the variables `region` and `year` uniquely identify all observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f56c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicates in terms of region year\n",
      "\n",
      "--------------------------------------\n",
      "   Copies | Observations       Surplus\n",
      "----------+---------------------------\n",
      "        1 |           70             0\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "duplicates report region year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf10fd5f",
   "metadata": {},
   "source": [
    "The table shows that there is not a single case of repeated observations. Hence, we will refer to these variables as the \"unique identifiers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59eb61d",
   "metadata": {},
   "source": [
    "#### 8.2.2 Identify the \"master\" and \"using\" data sets\n",
    "\n",
    "When merging data we need to decide which data set will be the primary data set (Stata refers to this data set as \"master\") and which will be secondary data set (Stata refers to this data set as \"using\"). Most of the time it will not matter which is the master and which is the using data sets. But you will need to know which is which in order to properly interpret the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4637aa1",
   "metadata": {},
   "source": [
    "#### 8.2.3 Identity the matching observations \n",
    "\n",
    "There are three main ways to match observations. The first case is when both observations share the same unique identifiers, so one observation in the master dataset is matched to one observation in the using dataset (reffered as `1:1` merge). The other two cases arise when you match multiple observations in the master dataset to one observation in the using dataset (referred as `m:1` merge). If it is the case that one observation in the master dataset is matched to multiple observations in the using dataset this is known as a `1:m` merge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f51cd",
   "metadata": {},
   "source": [
    "## 8.3 Merging Data Sets\n",
    "\n",
    "Once we know the unique identifiers, the master and using data sets, and what type of match we are doing we are able to merge the data sets. \n",
    "\n",
    "We begin having the master data opened in the current Stata session. For the sake of showing an example, let's suppose we want to set fake_data as the master dataset, and use region-year  as the using dataset. \n",
    "\n",
    "We already know that the fake_data's unique identifiers are *workerid* and *year* while the region-year's unique identifiers are *region* and *year*. The variables we use to link both data sets have to be the unique identifiers that are present in both data sets. Because *workerid* does not exist in the region-level data set, we will use variable *region* and *year* to merge the data sets. \n",
    "\n",
    "This means that for every region in the using data set there will be many observations in the individual level (master) data set to be matched. Therefore, this will be a `m:1` merge.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67674064",
   "metadata": {},
   "outputs": [],
   "source": [
    "use fake_data, clear  // This sets this data set as the master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3c1442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Result                      Number of obs\n",
      "    -----------------------------------------\n",
      "    Not matched                       406,963\n",
      "        from master                   406,963  (_merge==1)\n",
      "        from using                          0  (_merge==2)\n",
      "\n",
      "    Matched                         2,454,809  (_merge==3)\n",
      "    -----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "merge m:1 region year using region_year_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8dcae",
   "metadata": {},
   "source": [
    "Let's analyze the table above. It says that there were 406,963 observations in the master data couldn't be matched to any observation in the using dataset. This is due to the fact that our dataset at the region-year level does not have information for some years. \n",
    "\n",
    "Furthermore, the previous table shows that every observation from the using dataset got matched to some observation in the master dataset. The total number of matched observations is roughly 2.5 million. All of this information gets recorded into a new varible named *_merge*. Because of this, it is good practice to write `cap drop _merge` before running a merge command. \n",
    "\n",
    "Would we get the same results if we switched the master and using datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d911edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    Result                      Number of obs\n",
      "    -----------------------------------------\n",
      "    Not matched                       406,963\n",
      "        from master                         0  (_merge==1)\n",
      "        from using                    406,963  (_merge==2)\n",
      "\n",
      "    Matched                         2,454,809  (_merge==3)\n",
      "    -----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "use region_year_data, clear\n",
    "merge 1:m region year using fake_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53989ea",
   "metadata": {},
   "source": [
    "Indeed, we get the same information. We typically want to restrict to observations that were correctly matched across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b4a3f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406,963 observations deleted)\n"
     ]
    }
   ],
   "source": [
    "keep if _merge==3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40fa5b9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> Before dropping the unmerged observations make sure you spend some time thinking about why they did not merge and correct any errors that you identify. For example, maybe the country names are different in the two data sets (i.e. one data set has \"Barbados\" and another data set has \"The Barbados\"). If this is the case you will want to change the names and attempt your match a second time.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d407219d",
   "metadata": {},
   "source": [
    "## 8.4 Appending Data Sets\n",
    "\n",
    "We have used merge to combine datasets horizontally (we have added columns to the `master` dataset). However, if we want to combine datasets vertically  (add observations to the `master` dataset). Adding new information with `append` is very simple compared to the previous command. When we have a master dataset opened in our session, we can add observations using the syntax:\n",
    "\n",
    "```stata\n",
    "    append using new_dataset\n",
    "```\n",
    "\n",
    "This command will add new observations to the variables that are named *the same* across both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659dde3e-2dad-496c-89f1-35e4538dcb27",
   "metadata": {},
   "source": [
    "8.3 Wrap up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6f3c1-9e7f-43b4-abba-b8f4df719c70",
   "metadata": {},
   "source": [
    "In this module we learned how to combine different datasets. This is an extremely useful skill, especaially when you are undertaking panel data regressions. We will be learning more about these types of regressions in [Module 16]()."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stata",
   "language": "stata",
   "name": "stata"
  },
  "language_info": {
   "codemirror_mode": "stata",
   "file_extension": ".do",
   "mimetype": "text/x-stata",
   "name": "stata",
   "version": "15.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
