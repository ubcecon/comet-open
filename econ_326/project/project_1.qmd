---
title: "11 - ECON 326: An Example of a Final Project"
author: COMET Team <br> __
date: July 2023
description: INSERT DESCRIPTION HERE  
categories: [econ 326, regression, hypothesis testing, project]
format: 
  html: default
  ipynb:
    jupyter:
      kernelspec:
        display_name: R
        language: r
        name: ir
---

## Outline

### Prerequisites

* Introduction to Data in R
* Introduction to Data Visualization - I and II
* Simple Regression
* Multiple Regression
* Issues in Regression using R
* Interactions and Non-Linear Terms in Regressions

### Outcomes

## Introduction: 
Now that you are well armored with a statistical toolkit and experience with R, you are well on your way to embark on your own economic research adventure! This project serves as a sample to give you some intuition into the broad steps to a successful research project. It synthesizes the knowledge you have gained in your study of the ECON325 and ECON326 modules, and allows you to apply it to your own research project. It explains the steps involved in cleaning your data and preparing it for analysis, the actual analysis itself, and the careful interpretation and visualization of that analysis. 

It is important to note that while the more minute tasks in each of these big steps may vary according to the needs of the project, these steps remain mostly the same. Let's get started by importing all of the packages that we will use through out this module!

```{r}

# If any of the packages happened to not be installed for you, use the command install.packages() with the name of the packages, like 'stargazer'

library(ggplot2) 
library(haven)
library(stargazer)
library(tidyverse)
library(car)
library(fastDummies)

```

## Note:
Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.
R package version 5.2.3. https://CRAN.R-project.org/package=stargazer 

## Part 1: Preparing our Data
For the sake of our analysis today, we hope to observe whether factors like Electricity Generation, GDP, and Population, have had any impact on CO2 Emissions across all the Canadian Provinces. 

### Importing Data into R
Once you have gathered data, R has great dependability and dexterity in the viewing and manipulation of that data. To do this, you will want to import your datasets into R, like you have observed in multiple other modules so far. The data that you have gathered could be in a host of different formats like,

- .csv (Comma-Separated Values file), 
- .dta (STATA data file), 
- .xlsx (Excel file),
- .sav (SPSS file) or, 
- .sas (SAS file) 

All of these files correspond to different softwares, like Microsoft Excel, STATA, or SPSS, but can nonetheless be conveniently imported onto R. Fortunately, we will not be needing separate packages to import these files; `haven` is our jack-of-all-trades. We used the command `library(haven)` to load it at beginning of this module. In this case, since all of our data is in the .csv format, we use the function `read_csv`. The corresponding functions for the other formats are, `read_dta`, `read_spss`, and so on.

```{r}

# Loading the Data into R

gdp_data <- read_csv("C:/GitHub/econometrics/econ_326/datasets/gdp_data.csv")
pollution_data <- read_csv("C:/GitHub/econometrics/econ_326/datasets/pollution_data.csv")
elec_data <- read_csv("C:/GitHub/econometrics/econ_326/datasets/elec_data.csv")
pop_data <- read_csv("C:/GitHub/econometrics/econ_326/datasets/pop_data.csv")
```

> NOTE: By default, some functions in the Haven package, like `read_csv()`, assume that the CSV file has a header row with variable names. If your file does not have a header, or you would like different headers for your columns, you can use the argument `col_names` to adjust the column names manually.

### Viewing the Data
Once you have imported your datasets in R, it is worthwhile to get an overview of the data. There are two main reasons for this:

* Not every dataset will come formatted in a way that is suitable for your analysis, and therefore it is important to understand the structure of your dataset and its variables
* An overview allows you to recognize any potential obvious issues that the data may have, like missing values, duplicates, or unnecessary variables, that would pose issues in your analysis at a later stage 

Commands that can be used to view and understand the structure of your data include: `head()`, `str()`, `summary()`, and `view()`. These four functions can be used roughly interchangeably understand the structure of your data

```{r}

# Make sure to run these commands individually!

head(gdp_data)
summary(pollution_data)
str(elec_data)
view(pop_data)
```

An overview of our data reveals a few interesting things. All of data has been collected for the years 2009 - 2020. However, while the GDP and CO2 Emissions data is Annual, the Electricity Generation Data is Monthly, and the Population Data is Quarterly. It is also interesting to note that the some of the values for Electricity Generation are missing for some years for the Provinces of Newfoundland and Labrador, and Prince Edward Island. 

### Cleaning the Data
Having recognized these potential issues, getting rid of them is important, and it deems the name "Cleaning the Data" to this section of the project. An important rough structure to keep in mind while cleaning your data is called "Tidy Data", introduced by the statistician Hadley Wickham, where,

* Each Variable has its own Column
* Each Observation has its own Row, and,
* Each Value has its own Cell

To begin with, we try to keep the column names of our variables such that they are short and easy to manipulate, so let's change some of the column names in our datasets. 
```{r}
# Changing the Names across our Datasets

pollution_data <- pollution_data %>% rename(c(year = REF_DATE, province = GEO, sector = Sector, CO2 = VALUE))

gdp_data <- gdp_data %>% rename(c(year = REF_DATE, province = GEO, NAICS = `North American Industry Classification System (NAICS)`, GDP = VALUE))

elec_data <- elec_data %>% rename(c(year = REF_DATE, province = GEO, type = `Type of electricity generation`, elec = VALUE))

pop_data <- pop_data %>% rename(c(year = REF_DATE, province = GEO, pop = VALUE))
```

Next, note that across our Pollution and Population datasets, there are aggregations to a Canada-wide level, while our analysis is limited to the Provinces. Therefore, an inclusion of the Canada-wide aggregations will lead to a bias in our results. Let's get rid of that by filtering them out.

```{r}
# Filtering to keep every observation for which the GEO isn't equal to Canada

pop_data <- pop_data %>% filter(province != 'Canada')
pollution_data <- pollution_data %>% filter(province != 'Canada')
```

As noted before, there were some missing values in the Electricity Generation dataset. Although there are multiple ways of dealing with missing data, like using averages, or using advanced imputation techniques like multiple imputation, we choose to deal with missing values here by omitting them from our data.
```{r}

elec_data <- elec_data %>% filter(elec != is.na(elec))
```

Similar aggregations also exist in the Pollution dataset for "Total, industries and households", "Total, industries", and "Total, households". They also exist in the Electricity Generation dataset as "Total all types of electricity generation". Let's filter them, only this time, we will keep the aggregates across the categories of electricity generation and pollution, and get rid of the sub-categories. 

```{r}

pollution_data <- pollution_data %>% filter(sector == "Total, industries and households")
elec_data <- elec_data %>% filter(type == 'Total all types of electricity generation')
```

Next, as we previously noted, while the GDP and CO2 Emissions data is Annual, the Electricity Generation Data is Monthly, and the Population Data is Quarterly. Therefore, let's group them both to Yearly levels. Before we do that, note that "REF_DATE" contains the variables **Month** and **Year**. Therefore, satisfying our principles Tidy Data, let's use the Substring function to break it down into Month and Year. 

```{r}
elec_data <- elec_data %>%
  mutate(year = substr(year, 1, 4), month = substr(year, 6, 7))

pop_data <- pop_data %>%
  mutate(year = substr(year, 1, 4), month = substr(year, 6, 7))
```

Now, let's work on making both the Electricity and Population datasets annual. 

```{r}
elec_data_grouped <- elec_data %>%
  group_by(year, province) %>%
  summarise(electricity = sum(elec))

pop_data_grouped <- pop_data %>%
  group_by(year, province) %>%
  summarise(population = sum(pop))
```

Our next step will be to merge our datasets, so that we can smoothly run the analysis from one clean reference.  

```{r}
# Making the Data types compatible for joining
pop_data_grouped <- pop_data_grouped %>% mutate(year = as.double(year))
elec_data_grouped <- elec_data_grouped %>% mutate(year = as.double(year))

# Merging the four datasets into two
merged_data_1 <- left_join(gdp_data, pop_data_grouped, by = c('year', 'province'))
merged_data_2 <- left_join(pollution_data, elec_data_grouped, by = c('year', 'province'))

# Performing the Final Merge
merged_data <- left_join(merged_data_1, merged_data_2, by = c('year', 'province'))
```

```{r}

View(merged_data)

```

```{r}

#renaming some categories
merged_data <- merged_data  %>%
  rename(gdp = GDP)

#Now we need some factors. `Province` should be a factor variable. 

merged_data  <- merged_data_3  %>%
  mutate(province = case_when(
    province == "Newfoundland and Labrador" ~ "1",
    province == "Prince Edward Island" ~ "2",
    province == "Nova Scotia" ~ "3",
    province == "New Brunswick" ~ "4",
    province == "Quebec" ~ "5",
    province == "Ontario" ~ "6",
    province == "Manitoba" ~ "7",
    province == "Saskatchewan" ~ "8",
    province == "Alberta" ~ "9",
    province == "British Columbia" ~ "10",
    province == "Yukon" ~ "11",
    province == "Northwest Territories" ~ "12",
    province == "Nunavut" ~ "13",
  )) %>%
  mutate(province = as_factor(province))

#Now for clarity, we'll rename the dataset.

CO2_data <- merged_data

```

Now let's see how that's affected our data by taking a look at our structure. 

```{r}
str(CO2_data)
```

Great! We're ready to start building our model. 

## Part 2: Building our Multiple Regression Model

Now that we have our dataset ready and cleaned, let's start to think about building our model. What are the relationships that we're interested in investigating? For the dataset that we're working with, these would be : gross domestic product (GDP), electricity, and population. 

> _Think Deeper_: Why might we suspect that relationships exist between these variables? Is this consistent with economic theory? How would these relationships relate to your own experience? 

Let's begin investigating these relationships by making some visualizations.

```{r}
#(insert xlim and colour to finesse vizs as necessary)
a.1 + geom_point()

a <- ggplot(data = CO2_data, aes(x = gdp, y = CO2))+
  xlab("GDP")+
  ylab("CO2 Emissions") + scale_x_continuous()

a + geom_point()


b <- ggplot(data = CO2_data, aes(x = population, y = CO2))+
  xlab("Population")+
  ylab("CO2 Emissions") + scale_x_continuous()

b + geom_point()

c <- ggplot(data = CO2_data, aes(x = electricity, y = CO2))+
  xlab("Electricity")+
  ylab("CO2 Emissions") + scale_x_continuous()

c + geom_point()

```

Now that we've established some of these relationships, let's build our multiple regression model. (MENTION SLRs?)

```{r}

slr_1 <- lm(CO2 ~ gdp, data = CO2_data)
summary(slr_1)

slr_2 <- lm(CO2 ~ electricity, data = CO2_data)
summary(slr_2)

slr_3<- lm(CO2 ~ population, data = CO2_data)
summary(slr_3)

mlr_1 <- lm(CO2 ~ gdp + electricity + population, data = CO2_data)
summary(mlr_1)
```

As seen from the adjusted r-squared output, our multiple regression model has greater explanatory power than the any of the simple regressions alone, and all of the coefficients given are significant. 

## Part 3: Addressing Issues and Improving the Model

### Underlying Assumptions - Homoskedasticity 

Homoskedasticity, or constant variance, is an underlying assumption of OLS. Knowing that heteroskedasticity is another common issue in regression, we need to check our model to ensure that it meets this requirement. We'll start by checking visually with a residual plot for our first variable, GDP. 

```{r}
slr_1 <- lm(CO2 ~ gdp, data = CO2_data)

ggplot(data = CO2_data, aes(x = as.numeric(gdp), y = as.numeric(slr_1$residuals))
        )+geom_point()+labs(x = "GDP", y = "Residuals")
```

From this "eyeball test", it looks like the data display heterskedasticity. We'll test for this formally now with a Breusch-Pagan test. 
```{r}
CO2_data$resid_sqgdp <-  (slr_1$residuals)^2
residualsslr_1 <- lm(resid_sqgdp ~ gdp, data = CO2_data)
summary(residualsslr_1)
```

We reject the null hypothesis and conclude that the GDP data are heteroskedastic. Let's try to fix address this with a log transformation. 
```{r}
#transform the data
CO2_data <- CO2_data %>%
  mutate(ln_gdp = log(gdp))

#visualize the logged vlaue residuals
slr_ln1 <- lm(CO2 ~ ln_gdp, data = CO2_data) 

ggplot(data = CO2_data, aes(x = as.numeric(ln_gdp), y = as.numeric(slr_ln1$residuals))
)+geom_point()+labs(x = "Log GDP", y = "Residuals")

#conduct another Breusch-Pagan Test
CO2_data$resid_sq_lngdp <-  (slr_ln1$residuals)^2
residualsslr_ln1 <- lm(resid_sq_lngdp ~ ln_gdp, data = CO2_data)
summary(residualsslr_ln1)
```

This doesn't seem to have fixed the problem of heteroskedasticity within the gdp data. We'll overcome this in our final model by using robust standard errors. We'll now go through a similar process with the remaining two variables, and conclude that the electricity data are also heteroskedastic.  

```{r}
#For `electricity`
#Visualise the residuals
slr_2 <- lm(CO2 ~ electricity, data = CO2_data)
ggplot(data = CO2_data, aes(x = as.numeric(electricity), y = as.numeric(slr_2$residuals))
        )+geom_point()+labs(x = "Electricity", y = "Residuals")

#Fromally test the hypothesis
CO2_data$resid_sqelec <-  (slr_2$residuals)^2
residualsslr_2 <- lm(resid_sqelec ~ electricity, data = CO2_data)
summary(residualsslr_2)

#Log transform the data
CO2_data <- CO2_data %>%
  mutate(ln_electricity = log(electricity))

# visualize the logged value residuals
slr_ln2 <- lm(CO2 ~ ln_electricity, data = CO2_data)
ggplot(data = CO2_data, aes(x = as.numeric(ln_electricity), y = as.numeric(slr_ln2$residuals))
)+geom_point()+labs(x = "Log Electricity", y_ = "Residuals")

#Formally test 
CO2_data$resid_sq_lnelec <-  (slr_ln2$residuals)^2
residualsslr_ln2  <- lm(resid_sq_lnelec ~ ln_electricity, data = CO2_data)
summary(residualsslr_ln2)

#We reject Ho, and conclude heteroskedasticity in this data. 
```

```{r}
#For `population`
#Visualise the residuals
slr_3 <- lm(CO2 ~ population, data = CO2_data)
ggplot(data = CO2_data, aes(x = as.numeric(population), y = as.numeric(slr_3$residuals))
        )+geom_point()+labs(x = "Population", y = "Residuals")

#Formal hypothesis testing
CO2_data$resid_sqpop <- (slr_3$residuals)^2
residualsslr_3 <- lm(resid_sqpop ~ population, data = CO2_data)
summary(residualsslr_3)

library(lmtest)
lmtest::bptest(slr_3)

#We cannot reject the null hypothesis, and therefore cannot conclude heteroscedasticity for the population data. 
```

### Multicollinearity 

As we know, multicollinearity is a common issue that arises in developing a regression. To test how this shows up in our current model, we will calculate variance inflation factors (VIF), using the package `car`. 

> _Think Deeper_: Do you suspect any variables in the model may be affected by multicollinearity? How come? 

```{r}
car::vif(mlr_1)

coeftest(slr_3)
summary(slr_3)

slr_3.2$coefficients <- coeftest(slr_3)$coefficients
summary(slr_3.2)
```

The high VIF indicate that there's a problem with collinearity in our data. We'll try to combat this by creating a model which combines the effects of `GDP` and `population` into a single variable of per capita GDP. 

```{r}
#Create a new variable and view how it fits in the structure. 
CO2_data$per_capita_gdp <- CO2_data$gdp/CO2_data$population
str(CO2_data)

#Build a new model 
mlr_2 <- lm(CO2 ~ per_capita_gdp + electricity, data = CO2_data)
summary(mlr_2)

#Calculate VIF on the new model
car::vif(mlr_2)
```

This appears to have addressed out problems with multicollinearity in our model. 

### Adding Other Variables

There is still another variable that we haven't considered in our model. Let's take a look at how `province` affects CO2. Since our these variables are expressed qualitative factors, we will need to create dummies to represent them. We do this using the package `fastDummies`

```{r}
CO2_data <- dummy_cols(CO2_data, select_columns = 'province')
str(CO2_data)
```

Now we'll incorporate them into the model with `province_1` (Newfoundland and Labrador) excluded from the model as the reference variable.  

```{r}
slr_4 <- lm( CO2 ~ province_2 + province_3 + province_4 + province_5 + province_6 + province_7 + province_8 + province_9 + province_10 + province_11 + province_12 + province_13, data = CO2_data)
summary(slr_4)

mlr_4 <- lm(CO2 ~ gdp + population + electricity + province_2 + province_3 + province_4 + province_5 + province_6 + province_7 + province_8 + province_9 + province_10 + province_11 + province_12 + province_13, data = CO2_data)
summary(mlr_4)
```

This model has great explnatory power, but not all coefficients are significant anymore. We'll remove electricity and see how this affects our model. 

```{r}
mlr_5 <- lm(CO2 ~ gdp + population + province_2 + province_3 + province_4 + province_5 + province_6 + province_7 + province_8 + province_9 + province_10 + province_11 + province_12 + province_13, data = CO2_data)
summary(mlr_5)

car::vif(mlr_5)
```

Unsurprisingly, this model has high multicollinearity. Let's see what happens when we interact some of the terms. 

```{r}

#Province interacted with population 
mlr_6 <- lm(CO2 ~ gdp + electricity + population*province_2 + population*province_3 + population*province_4 + population*province_5 + population*province_6 + population*province_7 + population*province_8 + population*province_9 + population*province_10 + population*province_11 + population*province_12 + population*province_13, data = CO2_data)
summary(mlr_6)
car::vif(mlr_6)

#province dummies interacted with gdp
mlr_7 <- lm(CO2 ~ population + electricity + gdp:province_2 + gdp:province_3 + gdp:province_4 + gdp:province_5 + gdp:province_6 + gdp:province_7 + gdp:province_8 + gdp:province_9 + gdp:province_10 + gdp:province_11 + gdp:province_12 + gdp:province_13, data = CO2_data)
summary(mlr_7)
car::vif(mlr_7)

mlr_7.1 <- lm(CO2 ~ population + electricity + gdp*province_2 + gdp*province_3 + gdp*province_4 + gdp*province_5 + gdp*province_6 + gdp*province_7 + gdp*province_8 + gdp*province_9 + gdp*province_10 + gdp*province_11 + gdp*province_12 + gdp*province_13, data = CO2_data)

summary(mlr_7.1)
car::vif(mlr_7.1)

```

Now that we have a few different models, let's compare some of our results. 

```{r}
stargazer(mlr_1, mlr_2, mlr_3, mlr_4, mlr_5, mlr_6, mlr_7, title="Comparison of Muliple Regression Results",
          align = TRUE, type="text", keep.stat = c("n","rsq"))
```

## Interpretation: 

## Summary 


## READ HERE: 
I've checked the underlying assumptions, and both electricity and gdp display homoscedasticity. All versions which use those will need to use robust std. errors, so that can easily be worked around. VIF is huge on the base model (gdp + electricity + population), as well as anything which uses the province dummies (unsurprisingly). Below are some other iterations I've come up with, which we could compare and pick the best of, using some interactions (as given in module 5 of econ_326) which will need to be interpretted accordingly. 

```{r}

#GETTING THE DATA SORTED:

CO2_data$per_capita_gdp <- CO2_data$gdp/CO2_data$population

CO2_data <- CO2_data %>%
  mutate(ln_gdp = log(gdp))

CO2_data <- CO2_data %>%
  mutate(ln_electricity = log(electricity))

str(CO2_data)


```

```{r}
#(I will rename all of these as appropriate. The work to getting to them is all toward the bottom of the document)
#Option 1: standard 3 variables
reg_all <- lm(CO2 ~ gdp + electricity + population, data = CO2_data)
summary(reg_all)
    #problems: very high multicollinearity, omits provinces 
#Option 2: 2 terms, uses per capita gdp and electricity
reg4.0 <- lm(CO2 ~ per_capita_gdp + electricity, data = CO2_data)
summary(reg4.0) 
  #acceptable vif, will need robust standard errors, omits provinces
#Option 3: 3 terms, uses log(gdp) to help combat common issues which reduces multicollinearity
reg_log1 <- lm(CO2 ~ ln_gdp + electricity + population, data = CO2_data)
summary(reg_log1)  
  #acceptable VIF, will need robust standard errors , omits provinces 
#Option 4: 2 terms, uses interaction of gdp and population
reg_interact <- lm(CO2 ~ electricity + gdp:population, data = CO2_data)
summary(reg_interact) 
  #acceptable VIF, will need robust standard errors, omits provinces
#Option 5: uses interaction of gdp and population, and ln_electricity,
reg_interact2 <- lm(CO2 ~ ln_electricity + gdp:population, data = CO2_data)
summary(reg_interact2) 
#acceptable VIF, maybe won't need robust std errors? omits provinces
interact_all2 <- lm(CO2 ~ population + electricity + gdp:province_2 + gdp:province_3 + gdp:province_4 + gdp:province_5 + gdp:province_6 + gdp:province_7 + gdp:province_8 + gdp:province_9 + gdp:province_10 + gdp:province_11 + gdp:province_12 + gdp:province_13, data = CO2_dummies)
summary(interact_all2) #many terms, uses provinces interacted with gdp
  #super high VIF, but only way I've been able to incorporate the province dummies into the model with signifcant relationships

#to view the VIF (for multicollinearity) run the below code with whatever model
install.packages("car")
library(car)
car::vif(reg_interact2)

```

