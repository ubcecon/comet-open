---
title: "11 - ECON 326: An Example of a Final Project"
author: COMET Team <br> __
date: July 2023
description: INSERT DESCRIPTION HERE  
categories: [econ 326, regression, hypothesis testing, project]
format: 
  html: default
  ipynb:
    jupyter:
      kernelspec:
        display_name: R
        language: r
        name: ir
---

## Outline

### Prerequisites

* Introduction to Data in R
* Introduction to Data Visualization - I and II
* Simple Regression
* Multiple Regression
* Issues in Regression using R
* Interactions and Non-Linear Terms in Regressions

### Outcomes

## Introduction: 
Now that you are well armored with a statistical toolkit and experience with R, you are well on your way to embark on your own economic research adventure! This project serves as a sample to give you some intuition into the broad steps to a successful research project. It synthesizes the knowledge you have gained in your study of the ECON325 and ECON326 modules, and allows you to apply it to your own research project. It explains the steps involved in cleaning your data and preparing it for analysis, the actual analysis itself, and the careful interpretation and visualization of that analysis. 

It is important to note that while the more minute tasks in each of these big steps may vary according to the needs of the project, these steps remain mostly the same. Let's get started by importing all of the packages that we will use through out this module!

```{r}

# If any of the packages happened to not be installed for you, use the command install.packages() with the name of the packages, like 'stargazer'

library(ggplot2) 
library(haven)
library(stargazer)
library(tidyverse)
```

## Note:
Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.
R package version 5.2.3. https://CRAN.R-project.org/package=stargazer 

## Getting the Data:
For the sake of our analysis today, we hope to observe whether factors like Electricity Generation, GDP, and Population, have had any impact on CO2 Emissions across all the Canadian Provinces. 

## Importing Data into R
Once you have gathered data, R has great dependability and dexterity in the viewing and manipulation of that data. To do this, you will want to import your datasets into R, like you have observed in multiple other modules so far. The data that you have gathered could be in a host of different formats like,

- .csv (Comma-Separated Values file), 
- .dta (STATA data file), 
- .xlsx (Excel file),
- .sav (SPSS file) or, 
- .sas (SAS file) 

All of these files correspond to different softwares, like Microsoft Excel, STATA, or SPSS, but can nonetheless be conveniently imported onto R. Fortunately, we will not be needing separate packages to import these files; `haven` is our jack-of-all-trades. We used the command `library(haven)` to load it at beginning of this module. In this case, since all of our data is in the .csv format, we use the function `read_csv`. The corresponding functions for the other formats are, `read_dta`, `read_spss`, and so on.

```{r}

# Loading the Data into R

gdp_data <- read_csv("C:/GitHub/econometrics/econ_326/datasets/gdp_data.csv")
pollution_data <- read_csv("C:/GitHub/econometrics/econ_326/datasets/pollution_data.csv")
elec_data <- read_csv("C:/GitHub/econometrics/econ_326/datasets/elec_data.csv")
pop_data <- read_csv("C:/GitHub/econometrics/econ_326/datasets/pop_data.csv")
```

> NOTE: By default, some functions in the Haven package, like `read_csv()`, assume that the CSV file has a header row with variable names. If your file does not have a header, or you would like different headers for your columns, you can use the argument `col_names` to adjust the column names manually.

## Viewing the Data
Once you have imported your datasets in R, it is worthwhile to get an overview of the data. There are two main reasons for this:

* Not every dataset will come formatted in a way that is suitable for your analysis, and therefore it is important to understand the structure of your dataset and its variables
* An overview allows you to recognize any potential obvious issues that the data may have, like missing values, duplicates, or unnecessary variables, that would pose issues in your analysis at a later stage 

Commands that can be used to view and understand the structure of your data include: `head()`, `str()`, `summary()`, and `view()`. These four functions can be used roughly interchangeably understand the structure of your data

```{r}

# Make sure to run these commands individually!

head(gdp_data)
summary(pollution_data)
str(elec_data)
view(pop_data)
```

An overview of our data reveals a few interesting things. All of data has been collected for the years 2009 - 2020. However, while the GDP and CO2 Emissions data is Annual, the Electricity Generation Data is Monthly, and the Population Data is Quarterly. It is also interesting to note that the some of the values for Electricity Generation are missing for some years for the Provinces of Newfoundland and Labrador, and Prince Edward Island. 

## Cleaning the Data
Having recognized these potential issues, getting rid of them is important, and it deems the name "Cleaning the Data" to this section of the project. An important rough structure to keep in mind while cleaning your data is called "Tidy Data", introduced by the statistician Hadley Wickham, where,

* Each Variable has its own Column
* Each Observation has its own Row, and,
* Each Value has its own Cell

To begin with, we try to keep the column names of our variables such that they are short and easy to manipulate, so let's change some of the column names in our datasets. 
```{r}
# Changing the Names across our Datasets

pollution_data <- pollution_data %>% rename(c(year = REF_DATE, province = GEO, sector = Sector, CO2 = VALUE))

gdp_data <- gdp_data %>% rename(c(year = REF_DATE, province = GEO, NAICS = `North American Industry Classification System (NAICS)`, GDP = VALUE))

elec_data <- elec_data %>% rename(c(year = REF_DATE, province = GEO, type = `Type of electricity generation`, elec = VALUE))

pop_data <- pop_data %>% rename(c(year = REF_DATE, province = GEO, pop = VALUE))
```

Next, note that across our Pollution and Population datasets, there are aggregations to a Canada-wide level, while our analysis is limited to the Provinces. Therefore, an inclusion of the Canada-wide aggregations will lead to a bias in our results. Let's get rid of that by filtering them out.

```{r}
# Filtering to keep every observation for which the GEO isn't equal to Canada

pop_data <- pop_data %>% filter(province != 'Canada')
pollution_data <- pollution_data %>% filter(province != 'Canada')
```

As noted before, there were some missing values in the Electricity Generation dataset. Although there are multiple ways of dealing with missing data, like using averages, or using advanced imputation techniques like multiple imputation, we choose to deal with missing values here by omitting them from our data.
```{r}

elec_data <- elec_data %>% filter(elec != is.na(elec))
```

Similar aggregations also exist in the Pollution dataset for "Total, industries and households", "Total, industries", and "Total, households". They also exist in the Electricity Generation dataset as "Total all types of electricity generation". Let's filter them, only this time, we will keep the aggregates across the categories of electricity generation and pollution, and get rid of the sub-categories. 

```{r}

pollution_data <- pollution_data %>% filter(sector == "Total, industries and households")
elec_data <- elec_data %>% filter(type == 'Total all types of electricity generation')
```

Next, as we previously noted, while the GDP and CO2 Emissions data is Annual, the Electricity Generation Data is Monthly, and the Population Data is Quarterly. Therefore, let's group them both to Yearly levels. Before we do that, note that "REF_DATE" contains the variables **Month** and **Year**. Therefore, satisfying our principles Tidy Data, let's use the Substring function to break it down into Month and Year. 

```{r}
elec_data <- elec_data %>%
  mutate(year = substr(year, 1, 4), month = substr(year, 6, 7))

pop_data <- pop_data %>%
  mutate(year = substr(year, 1, 4), month = substr(year, 6, 7))
```

Now, let's work on making both the Electricity and Population datasets annual. 

```{r}
elec_data_grouped <- elec_data %>%
  group_by(year, province) %>%
  summarise(electricity = sum(elec))

pop_data_grouped <- pop_data %>%
  group_by(year, province) %>%
  summarise(population = sum(pop))
```

Our next step will be to merge our datasets, so that we can smoothly run the analysis from one clean reference.  

```{r}
# Making the Data types compatible for joining
pop_data_grouped <- pop_data_grouped %>% mutate(year = as.double(year))
elec_data_grouped <- elec_data_grouped %>% mutate(year = as.double(year))

# Merging the four datasets into two
merged_data_1 <- left_join(gdp_data, pop_data_grouped, by = c('year', 'province'))
merged_data_2 <- left_join(pollution_data, elec_data_grouped, by = c('year', 'province'))

# Performing the Final Merge
merged_data <- left_join(merged_data_1, merged_data_2, by = c('year', 'province'))
```

```{r}

View(merged_data)

```

```{r}

#renaming some categories
merged_data <- merged_data  %>%
  rename(gdp = GDP)

#Now we need some factors. `Province` should be a factor variable. 

merged_data  <- merged_data_3  %>%
  mutate(province = case_when(
    province == "Newfoundland and Labrador" ~ "1",
    province == "Prince Edward Island" ~ "2",
    province == "Nova Scotia" ~ "3",
    province == "New Brunswick" ~ "4",
    province == "Quebec" ~ "5",
    province == "Ontario" ~ "6",
    province == "Manitoba" ~ "7",
    province == "Saskatchewan" ~ "8",
    province == "Alberta" ~ "9",
    province == "British Columbia" ~ "10",
    province == "Yukon" ~ "11",
    province == "Northwest Territories" ~ "12",
    province == "Nunavut" ~ "13",
  )) %>%
  mutate(province = as_factor(province))

#Now for clarity, we'll rename the dataset.

CO2_data <- merged_data

```

Now let's see how that's affected our data by taking a look at our structure. 

```{r}
View(CO2_data)
```

Great! We're ready to start building our model. 

## Part 1: Building our Multiple Regression Model

Now that we have our dataset ready and cleaned, let's start to think about building our model. What are the relationships that we're interested in investigating? For the dataset that we're working with, these would be : gross domestic product (GDP), electricity, and population. 

> _Think Deeper_: Why might we suspect that relationships exist between these variables? Is this consistent with economic theory? How would these relationships relate to your own experience? 

Let's begin investigating these relationships by making some visualizations.

```{r}
#(insert xlim and colour to finesse vizs as necessary)
a.1 + geom_point()

a <- ggplot(data = CO2_data, aes(x = gdp, y = CO2))+
  xlab("GDP")+
  ylab("CO2 Emissions") + scale_x_continuous()

a + geom_point()


b <- ggplot(data = CO2_data, aes(x = population, y = CO2))+
  xlab("Population")+
  ylab("CO2 Emissions") + scale_x_continuous()

b + geom_point()

c <- ggplot(data = CO2_data, aes(x = electricity, y = CO2))+
  xlab("Electricity")+
  ylab("CO2 Emissions") + scale_x_continuous()

c + geom_point()

```

## SARTHAK READ HERE: 
I've checked the underlying assumptions, and both electricity and gdp display homoscedasticity. All versions which use those will need to use robust std. errors, so that can easily be worked around. VIF is huge on the base model (gdp + electricity + population), as well as anything which uses the province dummies (unsurprisingly). Below are some other iterations I've come up with, which we could compare and pick the best of, using some interactions (as given in module 5 of econ_326) which will need to be interpretted accordingly. 

Since our other variables are qualitative factor variables, we will need to create dummies to represent them. We do this using the package `"fastDummies"`

```{r}
library(fastDummies)
CO2_data <- dummy_cols(CO2_data, select_columns = 'province')
str(CO2_data)

#(we'll use province_1 (Newfoundland and Labrador) as our reference province in regression. This means that interpreting the coefficients with respect to that).

```

Now that we've established some of these relationships, let's build a first iteration of our model. 


```{r}

#GETTING THE DATA SORTED:

CO2_data$per_capita_gdp <- CO2_data$gdp/CO2_data$population

CO2_data <- CO2_data %>%
  mutate(ln_gdp = log(gdp))

CO2_data <- CO2_data %>%
  mutate(ln_electricity = log(electricity))

str(CO2_data)


```

```{r}
#(I will rename all of these as appropriate. The work to getting to them is all toward the bottom of the document)
#Option 1: standard 3 variables
reg_all <- lm(CO2 ~ gdp + electricity + population, data = CO2_data)
summary(reg_all)
    #problems: very high multicollinearity, omits provinces 
#Option 2: 2 terms, uses per capita gdp and electricity
reg4.0 <- lm(CO2 ~ per_capita_gdp + electricity, data = CO2_data)
summary(reg4.0) 
  #acceptable vif, will need robust standard errors, omits provinces
#Option 3: 3 terms, uses log(gdp) to help combat common issues which reduces multicollinearity
reg_log1 <- lm(CO2 ~ ln_gdp + electricity + population, data = CO2_data)
summary(reg_log1)  
  #acceptable VIF, will need robust standard errors , omits provinces 
#Option 4: 2 terms, uses interaction of gdp and population
reg_interact <- lm(CO2 ~ electricity + gdp:population, data = CO2_data)
summary(reg_interact) 
  #acceptable VIF, will need robust standard errors, omits provinces
#Option 5: uses interaction of gdp and population, and ln_electricity,
reg_interact2 <- lm(CO2 ~ ln_electricity + gdp:population, data = CO2_data)
summary(reg_interact2) 
#acceptable VIF, maybe won't need robust std errors? omits provinces
interact_all2 <- lm(CO2 ~ population + electricity + gdp:province_2 + gdp:province_3 + gdp:province_4 + gdp:province_5 + gdp:province_6 + gdp:province_7 + gdp:province_8 + gdp:province_9 + gdp:province_10 + gdp:province_11 + gdp:province_12 + gdp:province_13, data = CO2_dummies)
summary(interact_all2) #many terms, uses provinces interacted with gdp
  #super high VIF, but only way I've been able to incorporate the province dummies into the model with signifcant relationships

#to view the VIF (for multicollinearity) run the below code with whatever model
install.packages("car")
library(car)
car::vif(reg_interact2)

```

All the R2 values are comparable for anything where multicollinearity is addressed. They're also all on equal footing in the robest se would need to be used in any case.

## Part 2: Addressing the Issues and Improving the Model

### Underlying Assumptions - Homoskedasticity 

Homoskedasticity, or constant variance, is an underlying assumption of OLS. Knowing that heteroskedasticity is another common issue in regression, we need to check our model to ensure that it meets this assumption. 


```{r}

#for xvariable 1 - gdp 
regh1 <- lm(CO2 ~ gdp, data = trialdata2)

ggplot(data = trialdata2, aes(x = as.numeric(gdp), y = as.numeric(regh1$residuals))
        )+geom_point()+labs(x = "gdp", y = "y name residuals")

#for other variables (fill in as needed)
regh2 <- lm(y ~ x1, data = )

ggplot(data = ________, aes(x = as.numeric(x2), y = as.numeric(regh2$residuals))) +geom_point()+labs(x = "x1 name", y = "y name")

#for variable 3
regh3 <- lm(y ~ x1, data =)

ggplot(data = ________, aes(x = as.numeric(x3), y = as.numeric(regh3$residuals))) +geom_point()+labs(x = "x1 name", y = "y name")

```

As you can visually observe from the residuals plot, the data for gdp do not display homoskedasticity. We can test that formally with a  Bruesch-Pagan Test.

```{r}

trialdata2$resid_sqgdp <-  (regh1$residuals)^2

residualsreg <- lm(resid_sqgdp ~ gdp, data = trialdata2)

summary(residualsreg)
```

 We have failed the Breusch-Pagan test, meaning that we ... As a result, our model is (not) (BLUE). 

We can attempt to address this by transforming the problematic variable. Let's try a log transformation! 

```{r}
#insert log transformation 

trialdata2 <- trialdata2 %>%
  mutate(lngdp = log(gdp))

# visualize

lnregh1 <- lm(CO2 ~ lngdp, data = trialdata2) 

ggplot(data = trialdata2, aes(x = as.numeric(lngdp), y = as.numeric(lnregh1$residuals))
)+geom_point()+labs(x = "lngdp", y = "y name residuals")

#conduct another BP Test

trialdata2$resid_sqlngdp <-  (lnregh1$residuals)^2

residualsregln <- lm(resid_sqlngdp ~ gdp, data = trialdata2)

summary(residualsregln)

#(need to use White's test? HSKY was originally linear-looking, but the log transformed version seems to be more non-linear...)
```

As this has not adequately... 

## Multicollinearity 

As we know, multicollinearity is a common issue that arises in developing a regression. Let's first investigate this by visually creating a correlation matrix.

```{r}
#if ggally and plotly can't be added

datasubset <- subset(dataframe, select=c(v1, v2, ...))
pairs(datasubset,
      col = "blue"
      pch = 19 
      main = "Correlation Matrix Pairs")

#if ggally can be added:

p <- ggpairs(climatedata, title = "ggpairs", axisLabels = c("none"))
ggplotly(p)

```

From these results, we can see that multicollinearity....(INSERT DESCRIPTION). To test how this shows up in our model, we will calculate variance inflation factors (VIF). 

```{r}
cat("Variance inflation factor of (variable 1) on CO2 Emissions: ",vif(regression,SFS_data$income_after_tax,SFS_data$wealth),'\n')
cat("Variance inflation factor of (variable 2) on CO2 Emissions: ",vif(regression,SFS_data$income_before_tax,SFS_data$wealth),'\n')
cat("Variance inflation factor of (variable 3) on CO2 Emissions: ",vif(regression,SFS_data$income_before_tax,SFS_data$income_after_tax),'\n')

```

Notice that.... This means 


Now that we have a few different models, let's compare some of the results.
```{r}

stargazer(regression1, regression2, regression3..., title="Comparison of Muliple Regression Results",
          align = TRUE, type="text", keep.stat = c("n","rsq"))

```

```{r}

Functions: 

#this function was in the issues module, but I think it's wrong...
vif <- function(model,x_j,y){
  #s_2=RMSE(model)^2
  #var=var(x_j)
  R_2j =cor(x_j,y)
  v=1/(1-R_2j)
  return(v)
}
```

CHECKING FOR NORMALITY 
```{r}
#Starting with GDP
a = CO2_data$gdp
qqnorm(a, main='Normal Q-Q Plot for GDP')
qqline(a, col='steelblue')

shapiro.test(CO2_data$gdp)

ln_a = CO2_data$ln_gdp
qqnorm(ln_a, main='Normal Q-Q Plot for GDP')
qqline(ln_a, col='steelblue')

shapiro.test(CO2_data$ln_gdp)

CO2_data <- CO2_data %>%
  mutate(sqrt_gdp = sqrt(gdp))

sqrt_a = CO2_data$sqrt_gdp
qqnorm(sqrt_a, main='Normal Q-Q Plot for SQRT GDP')
qqline(sqrt_a, col='steelblue')

shapiro.test(CO2_data$sqrt_gdp)

CO2_data <- CO2_data %>%
  mutate(cbrt_gdp = cbrt(CO2_data$gdp))

#Not normally distributed! 
```

#Building some regressions

```{r}
#trying a regression using the dummy provinces variables
regprov1 <- lm(CO2 ~ province_2 + province_3 + province_4 + province_5 + province_6 + province_7 + province_8 + province_9 + province_10 + province_11 + province_12 + province_13, data = CO2_data)

summary(regprov1)

#province dummies as well as gdp, population, and electricity variables
mlr_all <- lm(CO2 ~ gdp + population + electricity + province_2 + province_3 + province_4 + province_5 + province_6 + province_7 + province_8 + province_9 + province_10 + province_11 + province_12 + province_13, data = CO2_data)
summary(mlr_all)

mlr_noelec <- lm(CO2 ~ gdp + population + province_2 + province_3 + province_4 + province_5 + province_6 + province_7 + province_8 + province_9 + province_10 + province_11 + province_12 + province_13, data = CO2_data)
summary(mlr_noelec)
```
```{r}

reg1.1 <- lm(CO2 ~ gdp, data = CO2_data)
summary(reg1.1)

reg1.2 <- lm(CO2 ~ gdp + electricity, data = CO2_data)
summary(reg1.2)

reg1.3 <- lm(CO2 ~ gdp + population, data = CO2_data)
summary(reg1.2)

reg2.1 <- lm(CO2 ~ electricity, data = CO2_data)
summary(reg1.2)

reg2.2 <- lm(CO2 ~ electricity + population, data = CO2_data)
summary(reg1.2)

reg3.0 <- lm(CO2 ~ population, data = CO2_data)
summary(reg1.3)

reg_all <- lm(CO2 ~ gdp + electricity + population, data = CO2_data)
summary(reg_all)


#create a new variable --> `GDP_per_capita` 

CO2_data$per_capita_gdp <- CO2_data$gdp/CO2_data$population
str(CO2_data)

reg4.0 <- lm(CO2 ~ per_capita_gdp + electricity, data = CO2_data)
summary(reg4.0)

#Using logs and interactions

reg_log1 <- lm(CO2 ~ ln_gdp + electricity + population, data = CO2_data)
summary(reg_log1)

reg_log2 <- lm(CO2 ~ gdp + ln_electricity + population, data = CO2_data)
summary(reg_log2)

reg_log12 <- lm(CO2 ~ ln_gdp + ln_electricity + population, data = CO2_data)
summary(reg_log12)

```

```{r}
#possible regressions to use 
summary(reg4.0) #2 terms uses per capita gdp
  #acceptable vif, will need robust standard errors
summary(reg_log1)  #3 terms, uses ln_gdp
  #acceptable VIF, will need robust standard errors  
summary(regbasicinteract) #2 terms, uses interaction of gdp and population
  #acceptable VIF, will need robust standard errors
summary(regbasicinteract_2) #2 terms, uses interaction of gdp and population and ln_electricity 
  #acceptable VIF, maybe won't need robust std errors? 
summary(mlr_interact2_all) #many terms, uses provinces interacted with gdp
  #super high VIF

#checking VIF
library(car)
car::vif()

#robust standard errors

library(sandwich)
coeftest(reg4.0)

#Comparing Regressions:
library(stargazer)
stargazer(reg4.0, reg_log1, regbasicinteract, regbasicinteract_2, mlr_interact2_all, title="Comparison of Muliple Regression Results", align = TRUE, type="text", keep.stat = c("n","rsq"))

```

MULTICOLLINEARITY 

```{r}
vif <- function(model,x_j,y){
  #s_2=RMSE(model)^2
  #var=var(x_j)
  R_2j =cor(x_j,y)
  v=1/(1-s_2j)
  return(v)
}

R_2j = cor(CO2_data$gdp,CO2_data$CO2)
1/(1- summary(reg_all)$r.squared)

```

```{r}
cat("Variance inflation factor of (gdp) on CO2 Emissions: ",vif(reg_all, CO2_data$gdp,CO2_data$CO2),'\n')
cat("Variance inflation factor of (population) on CO2 Emissions: ",vif(reg_all,CO2_data$population,CO2_data$CO2),'\n')
cat("Variance inflation factor of (electricity) on CO2 Emissions: ",vif(reg,CO2_data$electricity,CO2_data$CO2),'\n')
```

VIF: car package

```{r}
install.packages("car")
library(car)
car::vif(reg_log12)
#very different results? Conclusion --> the base function is incorrect? 
#ways to fix --> combine GDP and population? 

```

Let's try some different interactions


```{r}

#province dummies interacted with population 
mlr_interact_all <- lm(CO2 ~ gdp + electricity + population:province_2 + population:province_3 + population:province_4 + population:province_5 + population:province_6 + population:province_7 + population:province_8 + population:province_9 + population:province_10 + population:province_11 + population:province_12 + population:province_13, data = CO2_dummies)

#province dummies interacted with gdp
mlr_interact2_all <- lm(CO2 ~ population + electricity + gdp:province_2 + gdp:province_3 + gdp:province_4 + gdp:province_5 + gdp:province_6 + gdp:province_7 + gdp:province_8 + gdp:province_9 + gdp:province_10 + gdp:province_11 + gdp:province_12 + gdp:province_13, data = CO2_dummies)

summary(mlr_interact2_all)


mlr_all<- lm(CO2 ~ gdp + population + electricity + province_2 + province_3 + province_4 + province_5 + province_6 + province_7 + province_8 + province_9 + province_10 + province_11 + province_12 + province_13, data = CO2_dummies)
summary(mlr_all)

mlr4.1_all <- lm(CO2 ~ electricity + population + province_2 + province_4 + province_5 + province_6 + province_7 + province_8 + province_9 + province_10 + province_11 + province_12 + province_13, data = CO2_dummies)
summary(mlr4.1_all)

regbasicinteract <- lm(CO2 ~ electricity + gdp:population, data = CO2_data)
summary(regbasicinteract)

regbasicinteract_2 <- lm(CO2 ~ ln_electricity + gdp:population, data = CO2_data)
summary(regbasicinteract_2)

car::vif(regbasicinteract_2)


```

HETEROSKEDASTICITY 

```{r}

regh1 <- lm(CO2 ~ gdp, data = CO2_data)

CO2_data$resid_sqgdp <-  (regh1$residuals)^2

residualsreg <- lm(resid_sqgdp ~ gdp, data = CO2_data)

summary(residualsreg)

#log transform

CO2_dummies <- CO2_dummies %>%
  mutate(lngdp = log(gdp))

# visualize

lnregh1 <- lm(CO2 ~ lngdp, data = CO2_dummies) 

ggplot(data = CO2_dummies, aes(x = as.numeric(lngdp), y = as.numeric(lnregh1$residuals))
)+geom_point()+labs(x = "lngdp", y = "y name residuals")

#conduct another BP Test

CO2_dummies$resid_sqlngdp <-  (lnregh1$residuals)^2

residualsreglngdp <- lm(resid_sqlngdp ~ lngdp, data = CO2_dummies)

summary(residualsreglngdp)
```

Electricity

```{r}

regh2 <- lm(CO2 ~ electricity, data = CO2_data)

CO2_data$resid_sq_elec <-  (regh2$residuals)^2

residualsreg2 <- lm(resid_sq_elec ~ electricity, data = CO2_data)

summary(residualsreg2)

#visualise

ggplot(data = CO2_data, aes(x = as.numeric(electricity), y = as.numeric(regh2$residuals))
        )+geom_point()+labs(x = "electricity", y = "y name residuals")

#fix 

CO2_dummies <- CO2_dummies %>%
  mutate(ln_electricity = log(electricity))

# visualize

lnregh2 <- lm(CO2 ~ ln_electricity, data = CO2_dummies)

ggplot(data = CO2_dummies, aes(x = as.numeric(ln_electricity), y = as.numeric(lnregh2$residuals))
)+geom_point()+labs(x = "ln_electricity", y_ = "y name residuals")

#test

CO2_dummies$resid_sqln_electricity <-  (lnregh2$residuals)^2

residualsreglnelectricity <- lm(resid_sqln_electricity ~ ln_electricity, data = CO2_dummies)

summary(residualsreglnelectricity)

#reject Ho, still heteroskedastic 
```

Population

```{r}
regh3 <- lm(CO2 ~ population, data = CO2_data)

CO2_data$resid_sq_pop <-  (regh3$residuals)^2

residualsreg3 <- lm(resid_sq_pop ~ population, data = CO2_data)

summary(residualsreg3)

library(lmtest)
lmtest::bptest(regh3)

#cannot conclude heteroscedasticity . 

#visualise

ggplot(data = CO2_data, aes(x = as.numeric(population), y = as.numeric(regh3$residuals))
        )+geom_point()+labs(x = "population", y = "y name residuals")

#fix 

CO2_dummies <- CO2_dummies %>%
  mutate(ln_electricity = log(electricity))

# visualize

lnregh2 <- lm(CO2 ~ ln_electricity, data = CO2_dummies)

ggplot(data = CO2_dummies, aes(x = as.numeric(ln_electricity), y = as.numeric(lnregh2$residuals))
)+geom_point()+labs(x = "ln_electricity", y_ = "y name residuals")

#test

CO2_dummies$resid_sqln_electricity <-  (lnregh2$residuals)^2

residualsreglnelectricity <- lm(resid_sqln_electricity ~ ln_electricity, data = CO2_dummies)

summary(residualsreglnelectricity)

#reject Ho, still heteroskedastic 
```

Per Capita GDP

```{r}
regh4 <- lm(CO2 ~ per_capita_gdp, data = CO2_data)

CO2_dummies$resid_sq_pcg <-  (regh4$residuals)^2

residualsreg4 <- lm(resid_sq_pcg ~ per_capita_gdp, data = CO2_dummies)

summary(residualsreg4)

library(lmtest)
lmtest::bptest(regh4)

#conclude heteroscedasticity!

#visualise

ggplot(data = CO2_data, aes(x = as.numeric(per_capita_gdp), y = as.numeric(regh4$residuals))
        )+geom_point()+labs(x = "Per Capita GDP", y = "y name residuals")

#fix 

CO2_dummies <- CO2_dummies %>%
  mutate(ln_pcg = log(per_capita_gdp))

# visualize

lnregh4 <- lm(CO2 ~ ln_pcg, data = CO2_dummies)

ggplot(data = CO2_dummies, aes(x = as.numeric(ln_pcg), y = as.numeric(lnregh4$residuals))
)+geom_point()+labs(x = "ln_pcg", y_ = "y name residuals")

#test

CO2_dummies$resid_sqln_pcg <- (lnregh4$residuals)^2

residualsreglnpcg <- lm(resid_sqln_pcg ~ ln_pcg, data = CO2_dummies)

summary(residualsreglnpcg)

bptest(lnregh4)

#reject Ho, still heteroskedastic 
```

