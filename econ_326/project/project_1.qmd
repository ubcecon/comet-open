---
title: "11 - ECON 326: An Example of a Final Project"
author: COMET Team <br> __
date: July 2023
description: INSERT DESCRIPTION HERE  
categories: [econ 326, regression, hypothesis testing, project]
format: 
  html: default
  ipynb:
    jupyter:
      kernelspec:
        display_name: R
        language: r
        name: ir
---

## Outline

If you are reviewing the materials from ECON 326, or self-studying it, this is a good self-test to see if you understand all of the material.  After completing this course, you should be able to:

* Read this notebook, and understand what the difference analyses are, and how they are being used
* Critique the choices made, understanding their pros and cons
* Understand what the R code is doing, and how it implements the analyses
* Be able to describe how to adjust or change this to do other analysis or change the focus or assumptions made in the analysis so far

You can also use this as a model of a project of your own, if you're interested in getting started with econometric analysis.

```{r}

library(stargazer)
library(ggplot2)

```

## Introduction 
>>>> INSERT /Introduction  

```{r}
#TEMPORARY DATA MANIPULATIONS

gdp_data <- read.csv("C:/Data/CometData/gdp_data.csv")
pollution_data <- read.csv("C:/Data/CometData/pollution_data.csv")

view(gdp_data)
view(pollution_data)


merged_data <- left_join(gdp_data, pollution_data, by = c('REF_DATE', 'GEO'))
view(merged_data)


# Y(dependent) variable is going to be CO2 emissions
# X(independents)can be:
  # Year
  # GDP
  # Industry type?
  # province

trialdata1 <- merged_data

trialdata1 <- trialdata1 %>%
  rename(province = GEO) %>%
  rename(year = REF_DATE) %>%
  rename(industry = North.American.Industry.Classification.System..NAICS.)%>%
  rename(gdp = VALUE.x) %>%
  rename(CO2 = VALUE.y) %>%
  rename(emissions_sector = Sector)

view(trialdata1)

#Now we need some factors. Province, industry, and emissions sector should all be factorized

trialdata1 <- trialdata1 %>%
  mutate(province = case_when(
    province == "Newfoundland and Labrador" ~ "1",
    province == "Prince Edward Island" ~ "2",
    province == "Nova Scotia" ~ "3",
    province == "New Brunswick" ~ "4",
    province == "Quebec" ~ "5",
    province == "Ontario" ~ "6",
    province == "Manitoba" ~ "7",
    province == "Saskatchewan" ~ "8",
    province == "Alberta" ~ "9",
    province == "British Columbia" ~ "10",
    province == "Yukon" ~ "11",
    province == "Northwest Territories" ~ "12",
    province == "Nunavut" ~ "13",
  )) %>%
  mutate(province = as_factor(province))

view(trialdata1)


trialdata1 <- trialdata1 %>%
  mutate(emissions_sector = case_when(
    emissions_sector == "Total, industries and households" ~ "1",
    emissions_sector == "Total, industries" ~ "2",
    emissions_sector== "Total, households" ~ "3",
    emissions_sector == "Total, United Nations Framework Convention on Climate Change (UNFCCC), Canada's submission" ~ "4",
    emissions_sector == "Total, Reconciliation with Canada's submission to the United Nations Framework Convention on Climate Change (UNFCCC)" ~ "5",
    ))


trialdata2 <- subset(trialdata1, emissions_sector == "1")

```

## Part 1: Building our Multiple Regression Model

Now that we have our dataset ready and cleaned, let's start to think about building our model. What are the relationships that we're interested in investigating? For the dataset that we're working with, these would be : ___________________. 

> _Think Deeper_: Why might we suspect that relationships exist between these variables? Is this consistent with economic theory? How would these relationships relate to your own experience? 

Let's begin investigating these relationships by making some visualizations.

```{r}




```

```{r}
#(insert xlim and colour to finesse vizs as necessary)

f <- ggplot(data = trialdata2, aes(x = year, y = CO2))+
  xlab("year")+
  ylab("CO2 Emissions") + scale_x_continuous()

f + geom_point()

b <- ggplot(data = trialdata2, aes(x = gdp, y = CO2))+
  xlab("GDP")+
  ylab("CO2 Emissions") + scale_x_continuous()

b + geom_point()

```

Now that we've established some of these relationships, let's build a first iteration of our model. 

```{r}
regression1 <- lm(data = , y ~ x1 + x2 +....)

summary(regression1)
```

## Part 2: Addressing the Issues and Improving the Model

### Underlying Assumptions - Homoskedasticity 

Homoskedasticity, or constant variance, is an underlying assumption of OLS. Knowing that heteroskedasticity is another common issue in regression, we need to check our model to ensure that it meets this assumption. 

```{r}



```

```{r}

#for xvariable 1 - gdp 
regh1 <- lm(CO2 ~ gdp, data = trialdata2)

ggplot(data = trialdata2, aes(x = as.numeric(gdp), y = as.numeric(regh1$residuals))
        )+geom_point()+labs(x = "gdp", y = "y name residuals")

#for other variables (fill in as needed)
regh2 <- lm(y ~ x1, data = )

ggplot(data = ________, aes(x = as.numeric(x2), y = as.numeric(regh2$residuals))) +geom_point()+labs(x = "x1 name", y = "y name")

#for variable 3
regh3 <- lm(y ~ x1, data =)

ggplot(data = ________, aes(x = as.numeric(x3), y = as.numeric(regh3$residuals))) +geom_point()+labs(x = "x1 name", y = "y name")

```

As you can visually observe from the residuals plot, the data for gdp do not display homoskedasticity. We can test that formally with a  Bruesch-Pagan Test.

```{r}

trialdata2$resid_sqgdp <-  (regh1$residuals)^2

residualsreg <- lm(resid_sqgdp ~ gdp, data = trialdata2)

summary(residualsreg)
```

 We have failed the Breusch-Pagan test, meaning that we ... As a result, our model is (not) (BLUE). 

We can attempt to address this by transforming the problematic variable. Let's try a log transformation! 

```{r}
#insert log transformation 

trialdata2 <- trialdata2 %>%
  mutate(lngdp = log(gdp))

# visualize

lnregh1 <- lm(CO2 ~ lngdp, data = trialdata2) 

ggplot(data = trialdata2, aes(x = as.numeric(lngdp), y = as.numeric(lnregh1$residuals))
)+geom_point()+labs(x = "lngdp", y = "y name residuals")

#conduct another BP Test

trialdata2$resid_sqlngdp <-  (lnregh1$residuals)^2

residualsregln <- lm(resid_sqlngdp ~ gdp, data = trialdata2)

summary(residualsregln)

#(need to use White's test? HSKY was originally linear-looking, but the log transformed version seems to be more non-linear...)
```

As this has not adequately 


## Multicollinearity 

As we know, multicollinearity is a common issue that arises in developing a regression. Let's first investigate this by visually creating a correlation matrix.

```{r}
#if ggally and plotly can't be added

datasubset <- subset(dataframe, select=c(v1, v2, ...))
pairs(datasubset,
      col = "blue"
      pch = 19 
      main = "Correlation Matrix Pairs")

#if ggally can be added:

p <- ggpairs(climatedata, title = "ggpairs", axisLabels = c("none"))
ggplotly(p)

```

From these results, we can see that multicollinearity....(INSERT DESCRIPTION). To test how this shows up in our model, we will calculate variance inflation factors (VIF). 

```{r}
cat("Variance inflation factor of (variable 1) on CO2 Emissions: ",vif(regression,SFS_data$income_after_tax,SFS_data$wealth),'\n')
cat("Variance inflation factor of (variable 2) on CO2 Emissions: ",vif(regression,SFS_data$income_before_tax,SFS_data$wealth),'\n')
cat("Variance inflation factor of (variable 3) on CO2 Emissions: ",vif(regression,SFS_data$income_before_tax,SFS_data$income_after_tax),'\n')

```

Notice that.... This means 




Now that we have a few different models, let's compare some of the results.
```{r}

stargazer(regression1, regression2, regression3..., title="Comparison of Muliple Regression Results",
          align = TRUE, type="text", keep.stat = c("n","rsq"))

```

```{r}

Functions: 

vif <- function(model,x_j,y){
  #s_2=RMSE(model)^2
  #var=var(x_j)
  R_2j =cor(x_j,y)
  v=1/(1-R_2j)
  return(v)
}


```

