<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-GB" xml:lang="en-GB"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3.7 - Advanced - Transcription – COMET</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../docs/4_Advanced/advanced_vocalization/advanced_vocalization_draft.html" rel="next">
<link href="../../../docs/4_Advanced/advanced_sentiment_analysis/sentiment_analysis.html" rel="prev">
<link href="../../../media/comet_favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<meta name="keywords" content="economics, econometrics, R, data, machine learning, UBC, COMET, geog 374, econ 325, econ 326, learning, teaching, learn r, r help, help, tutorial, r tutorial for beginners,learning statistics with r, learn r programming, learn statistics, linear regression, r machine learning, learn machine learning, university of british columbia, british columbia, r programming for beginners, r language tutorial, r tutorial for beginners, economic data, econometrics tutoring, economics help for students, economics homework help, oer resources for teachers, open educational resources for teachers, educational resource, oer project, oer materials, oer resources, learn economics online, learn econometrics, teach yourself economics, teach yourself econometrics, econometrics basics for beginners">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../media/logo_no_tiny_text.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">COMET</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-get-started" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Get Started</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-get-started">    
        <li>
    <a class="dropdown-item" href="../../../pages/quickstart.html">
 <span class="dropdown-text">Quickstart Guide</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/installation/installing_locally.html">
 <span class="dropdown-text">Install and Use COMET</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_getting_started.html">
 <span class="dropdown-text">Get Started</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-learn-by-skill-level" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Learn By Skill Level</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-learn-by-skill-level">    
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_getting_started.html">
 <span class="dropdown-text">Getting Started</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_beginner.html">
 <span class="dropdown-text">Beginner</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_intermediate.html">
 <span class="dropdown-text">Intermediate - Econometrics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_geog.html">
 <span class="dropdown-text">Intermediate - Geospatial</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_advanced.html">
 <span class="dropdown-text">Advanced</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="../../../pages/index/all.html">
 <span class="dropdown-text">Browse All</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-learn-by-class" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Learn By Class</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-learn-by-class">    
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_226.html">
 <span class="dropdown-text">Making Sense of Economic Data (ECON 226/227)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_325.html">
 <span class="dropdown-text">Econometrics I (ECON 325)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_326.html">
 <span class="dropdown-text">Econometrics II (ECON 326)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_geog.html">
 <span class="dropdown-text">Statistics in Geography (GEOG 374)</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-learn-to-research" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Learn to Research</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-learn-to-research">    
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_research.html">
 <span class="dropdown-text">Learn How to Do a Project</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teach-with-comet" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Teach With COMET</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-teach-with-comet">    
        <li>
    <a class="dropdown-item" href="../../../pages/teaching_with_comet.html">
 <span class="dropdown-text">Learn how to teach with Jupyter and COMET</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/using_comet.html">
 <span class="dropdown-text">Using COMET in the Classroom</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/dissemination/dissemination.html">
 <span class="dropdown-text">See COMET presentations</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-contribute" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Contribute</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-contribute">    
        <li>
    <a class="dropdown-item" href="../../../pages/installation/installing_for_development.html">
 <span class="dropdown-text">Install for Development</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/documentation/writing_self_tests.html">
 <span class="dropdown-text">Write Self Tests</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-launch-comet" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-play" role="img">
</i> 
 <span class="menu-text">Launch COMET</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-launch-comet">    
        <li>
    <a class="dropdown-item" href="https://open.jupyter.ubc.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fubcecon%2Fcomet-project&amp;urlpath=lab%2Ftree%2Fcomet-project%2F&amp;branch=main"><i class="bi bi-cloud-check" role="img">
</i> 
 <span class="dropdown-text">Launch on JupyterOpen</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://ubc.syzygy.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fubcecon%2Fcomet-project&amp;urlpath=lab%2Ftree%2Fcomet-project%2F&amp;branch=main"><i class="bi bi-gear" role="img">
</i> 
 <span class="dropdown-text">Launch on Syzygy</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://colab.research.google.com/github/ubcecon/comet-project/blob/main/"><i class="bi bi-google" role="img">
</i> 
 <span class="dropdown-text">Launch on Collab</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/ubcecon/comet-project/archive/refs/heads/main.zip"><i class="bi bi-cloud-download" role="img">
</i> 
 <span class="dropdown-text">Launch Locally</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="https://github.com/ubcecon/comet-project/archive/refs/heads/data-only.zip"><i class="bi bi-clipboard-data" role="img">
</i> 
 <span class="dropdown-text">Project Datasets</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../#"> 
<span class="menu-text">|</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-about" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">About</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-about">    
        <li>
    <a class="dropdown-item" href="../../../pages/team.html">
 <span class="dropdown-text">COMET Team</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/copyright.html">
 <span class="dropdown-text">Copyright Information</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../pages/index/index_advanced.html">Advanced Modules</a></li><li class="breadcrumb-item"><a href="../../../docs/4_Advanced/advanced_transcription/advanced_transcription_whisper.html">Transcription (Python)</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
 <span class="menu-text"><h4>Learn by Skill Level</h4></span>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../pages/index/index_getting_started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started: Introduction to Data, R, and Econometrics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/1_Getting_Started/getting_started_intro_to_jupyter/getting_started_intro_to_jupyter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to JupyterNotebooks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/1_Getting_Started/getting_started_intro_to_r/getting_started_intro_to_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/1_Getting_Started/getting_started_intro_to_data/getting_started_intro_to_data1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Data (Part 1)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/1_Getting_Started/getting_started_intro_to_data/getting_started_intro_to_data2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Data (Part 2)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../pages/index/index_beginner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beginner: Using R and Data in Applied Econometrics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_intro_to_statistics1/beginner_intro_to_statistics1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Statistics I</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_intro_to_statistics2/beginner_intro_to_statistics2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Statistics II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_central_tendency/beginner_central_tendency.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Central Tendency</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_dispersion_and_dependence/beginner_dispersion_and_dependence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dispersion and Dependence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_confidence_intervals/beginner_confidence_intervals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Confidence Intervals</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_hypothesis_testing/beginner_hypothesis_testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hypothesis Testing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_intro_to_data_visualization1/beginner_intro_to_data_visualization1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Visualization I</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_intro_to_data_visualization2/beginner_intro_to_data_visualization2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Visualization II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_distributions/beginner_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_sampling_distributions/beginner_sampling_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sampling Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/intermediate_intro_to_regression/intermediate_intro_to_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../pages/index/index_intermediate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intermediate: Econometrics and Modeling Using R</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/intermediate_intro_to_regression/intermediate_intro_to_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/intermediate_multiple_regression/intermediate_multiple_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/intermediate_issues_in_regression/intermediate_issues_in_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Issues in Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/intermediate_interactions_and_nonlinear_terms/intermediate_interactions_and_nonlinear_terms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interactions</span></a>
  </div>
</li>
          <li class="px-0"><hr class="sidebar-divider hi "></li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../pages/index/index_geog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Geographic Computation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/geog_374/Lab_05_Chisquare/Lab_05_Chisquare.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chi-Square Test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/geog_374/Lab_06_Ttest/Lab_06_Ttest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">t-test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/geog_374/Lab_02_ANOVA/Lab_02_ANOVA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ANOVA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/geog_374/Lab_03_Regression/Lab_03_Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/geog_374/Climate_Disasters/Climate_Disasters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wrangling and Visualizing Data</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../pages/index/index_advanced.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Modules</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_classification_and_clustering/advanced_classification_and_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classification and Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_difference_in_differences/advanced_difference_in_differences.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Differences In Differences</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_geospatial/advanced_geospatial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Geospatial I</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_geospatial/advanced_geospatial_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Geospatial II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_instrumental_variables/advanced_instrumental_variables1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Instrumental Variables I</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_instrumental_variables/advanced_instrumental_variables2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Instrumental Variables II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_llm_apis2/advanced_llm_apis2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Large Language Model APIs (Python)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_linear_differencing/advanced_linear_differencing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Differencing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_ollama_llm/fine_tuning_llm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Training LLMS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_sentiment_analysis/sentiment_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sentiment Analysis Using LLMs (Python)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_transcription/advanced_transcription_whisper.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Transcription (Python)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_vocalization/advanced_vocalization_draft.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vocalization (Python)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_word_embeddings/advanced_word_embeddings_python_version.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings (Python)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_word_embeddings/advanced_word_embeddings_r_version.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings (R)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#prerequisites" id="toc-prerequisites" class="nav-link active" data-scroll-target="#prerequisites">Prerequisites</a></li>
  <li><a href="#learning-outcomes" id="toc-learning-outcomes" class="nav-link" data-scroll-target="#learning-outcomes">Learning outcomes</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">1. Introduction</a>
  <ul class="collapse">
  <li><a href="#what-is-audio-transcription" id="toc-what-is-audio-transcription" class="nav-link" data-scroll-target="#what-is-audio-transcription">1.1 What is audio transcription?</a></li>
  <li><a href="#what-is-whisper" id="toc-what-is-whisper" class="nav-link" data-scroll-target="#what-is-whisper">1.2 What is <em>Whisper</em>?</a></li>
  </ul></li>
  <li><a href="#installations" id="toc-installations" class="nav-link" data-scroll-target="#installations">2. Installations</a>
  <ul class="collapse">
  <li><a href="#activating-conda-environment-downloading-jupyter-lab" id="toc-activating-conda-environment-downloading-jupyter-lab" class="nav-link" data-scroll-target="#activating-conda-environment-downloading-jupyter-lab">2.1 Activating conda environment &amp; downloading Jupyter Lab</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/ubcecon/comet-project/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="advanced_transcription_whisper.ipynb" download="advanced_transcription_whisper.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../pages/index/index_advanced.html">Advanced Modules</a></li><li class="breadcrumb-item"><a href="../../../docs/4_Advanced/advanced_transcription/advanced_transcription_whisper.html">Transcription (Python)</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">3.7 - Advanced - Transcription</h1>
  <div class="quarto-categories">
    <div class="quarto-category">advanced</div>
    <div class="quarto-category">python</div>
    <div class="quarto-category">Whisper</div>
    <div class="quarto-category">audio transcription</div>
    <div class="quarto-category">PyTorch</div>
    <div class="quarto-category">preprocessing</div>
    <div class="quarto-category">diarization</div>
  </div>
  </div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<hr>
<section id="prerequisites" class="level2">
<h2 class="anchored" data-anchor-id="prerequisites">Prerequisites</h2>
<ul>
<li>Have installed Anaconda Navigator and Python on your computer</li>
</ul>
</section>
<section id="learning-outcomes" class="level2">
<h2 class="anchored" data-anchor-id="learning-outcomes">Learning outcomes</h2>
<ul>
<li>Understand the basic mechanics behild audio transcription</li>
<li>Be familiar with the various elements of Whisper audio transcription</li>
<li>Be able to transcribe and diarize short-form and long-form audio</li>
</ul>
<hr>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">1. Introduction</h2>
<p><img src="images/openai.png" alt="whisper audio" width="1000"></p>
<section id="what-is-audio-transcription" class="level3">
<h3 class="anchored" data-anchor-id="what-is-audio-transcription">1.1 What is audio transcription?</h3>
<p>Audio transcription is the language processing task of converting audio files containing human speech into text using a computer. This task most often includes the process of <em>diarization</em>, the process of distinguishing and labeling the various speakers in the audio file. Application of audio transcription include multi-lingual captions on online videos, real-time online meeting transcription, and much more.</p>
<p><em>Automatic speech recognition (ASR) systems</em> are interfaces that use machine learning/artificial intelligence to process speech audio files into text. In this module, we will be using the open-source ASR system <em>Whisper</em> by OpenAI to transcribe and diarize various audio files.</p>
</section>
<section id="what-is-whisper" class="level3">
<h3 class="anchored" data-anchor-id="what-is-whisper">1.2 What is <em>Whisper</em>?</h3>
<p>Whisper is a ASR model for transcription and speech recognition designed by OpenAI. Whisper stands out from it’s predecessors due to it being trained on roughly 680 thousand hours of labeled audio transcription data, signfificantly more than the models that came before it; thus, Whisper exhibits a much higher accuracy when tested against audio data outside of it’s training set compared to older models such as <em>Wav2Vec</em><span class="math inline">\(^{[1]}\)</span>.</p>
<section id="how-does-whisper-work" class="level4">
<h4 class="anchored" data-anchor-id="how-does-whisper-work">1.2.1 How does Whisper work?</h4>
<p>Whisper, and audio transcription models in general, work by converting raw audio data into a spectrogram, specifically a <em>Log-Mel spectrogam</em>, which plots the time on the x-axis, the mels scale (a logarithmic form of the Hertz frequency) on the y-axis, and colors the data with respect to the amplitude of the audio data at each mel frequency and point in time.</p>
<p>The mel-spectogram is then ran though a tokenizer, which converts the individual words in the spectrogram into lexical tokens- strings with assigned meaning that can be read by the language model. The encoder is a stack of transformer blocks that process the tokens, extracting features and relationships between different parts of the audio. The processed information from the encoder is passed to the decoder, another stack of transformer blocks that generate an output sequence (predicting the corresponding text captions word by word)<span class="math inline">\(^{[2]}\)</span>.</p>
<p><img src="images/transformers.png" alt="transformer process" width="800"></p>
</section>
<section id="optimizing-whisper-transcription" class="level4">
<h4 class="anchored" data-anchor-id="optimizing-whisper-transcription">1.2.2 Optimizing Whisper transcription</h4>
<p>Alongside whisper, there exist many libraries that aim to optimize the current whisper model by increasing transcription speed and accuracy. Some examples include:</p>
<p><strong><a href="https://github.com/huggingface/distil-whisper">Distil-Whisper</a></strong>: a smaller, optimized version of whisper created by <em>HuggingFace</em> using knowledge distillation. The Distil-Whisper model claims to be 6x faster, 50% smaller, and within a 1% word error rate relative to the original whisper model <span class="math inline">\(^{[3]}\)</span>. &gt; Pros: CPU-compatible, significantly faster compared to OpenAI’s Whisper model.</p>
<blockquote class="blockquote">
Cons: Only supports english-speech to english-text transcription.
<div class="alert alert-block alert-info">
This is the model that we will be using in this notebook, due to it’s relevance and compatability with our use cases for audio transcription. However, if you have a relatively powerful computer and feel up for the challenge, consider following along with one of the alternatives listed below.
</div>
</blockquote>
<p><strong><a href="https://github.com/sanchit-gandhi/whisper-jax">Whisper-Jax</a></strong>: Another optimized version of whisper built on the <em>Transformers</em> library. Whisper-Jax claims to be 70x faster than the original Whisper model <span class="math inline">\(^{[4]}\)</span>. &gt; Pros: CPU-compatible, significantly faster compared to OpenAI’s Whisper model.</p>
<blockquote class="blockquote">
<p>Cons: Optimized for GPU/TPU usage.</p>
</blockquote>
<p><strong><a href="https://github.com/Vaibhavs10/insanely-fast-whisper">Insanely-Fast-Whisper</a></strong>: A command-line interface that greatly speeds up whisper performance and claims to be able to trascribe 150 minutes of audio in less than 98 seconds <span class="math inline">\(^{[5]}\)</span>.. &gt; Pros: One of the fastest versions of whisper available today.</p>
<blockquote class="blockquote">
<p>Cons: Only works on NVIDIA GPUs.</p>
</blockquote>
<hr>
</section>
</section>
</section>
<section id="installations" class="level2">
<h2 class="anchored" data-anchor-id="installations">2. Installations</h2>
<section id="activating-conda-environment-downloading-jupyter-lab" class="level3">
<h3 class="anchored">2.1 Activating conda environment &amp; downloading Jupyter Lab</h3>
<p>(If you’ve already done this, please move on to section 2.2)</p>
<section id="setting-up-and-activating-a-conda-envornment" class="level4">
<h4 class="anchored" data-anchor-id="setting-up-and-activating-a-conda-envornment">2.1.1 Setting up and activating a conda envornment</h4>
<p>An <em>environment</em> is a repository of packages that you have installed on your computer. It acts similar to a virtual machine, keeping the packages needed for one project seperate from other projects, to avoid version conflicts, cluttering, etc.</p>
<p>Let’s start by opening up the conda command prompt. 1) On windows 11, press the windows icon at the bottom of the screen. 2) Press <em>“all apps”</em>, and open the <code>anaconda3 (64bit)</code> folder. 3) Left-click on <code>anaconda prompt</code>, select <code>more</code>, and press <code>run as administrator</code>. This will open the command prompt window. 4) Lets create a new environment and call it <em>“whisper”</em>. In the command prompt, copy-and-paste the following line of code: <code>conda create -n whisper</code>. 5) Let’s activate our new environment. Once your new environment is created, type <code>conda activate whisper</code>.</p>
<p>We’ve successfully created and activated our environment.</p>
</section>
<section id="installing-and-opening-jupyter-lab" class="level4">
<h4 class="anchored">2.1.2 Installing and opening Jupyter lab</h4>
<p>To install jupyter, type in the following line of code: <code>conda install jupyter</code>. Once jupyter is finished installing, simply type <code>jupyter lab</code> in the command prompt. This will open up jupyter locally in your default browser.</p>
<div class="alert alert-block alert-info">
<p><b>Note</b>: these steps only need to be done once on each computer. The next time you wish to open jupyter locally, you only need to activate your conda environment and type in “jupyter lab” in the conda prompt.</p>
<div class="alert alert-block alert-danger">
<p><b>Warning:</b> Make sure not to close the anaconda prompt while jupyter is running. Doing so will cause Jupyter to lose connection and may result in you losing unsaved work.</p>
</div>
<section id="installaling-whisper" class="level3">
<h3 class="anchored" data-anchor-id="installaling-whisper">2.2 Installaling Whisper</h3>
<section id="installing-pytorch" class="level4">
<h4 class="anchored" data-anchor-id="installing-pytorch">2.2.1 Installing Pytorch</h4>
<p>Lets start off by installing <em>PyTorch</em>, a machine learning library based on the Torch frame work, on which Whisper is built on. To install pytorch, open the conda prompt as an administrator, ensure that you are in the <code>whisper</code> enviornment that we created, and type in the following line of code:</p>
<p><code>conda install pytorch torchvision torchaudio cpuonly -c pytorch</code></p>
<p>If, for some reason, the installation does not work, you can also install pytorch through pip:</p>
<p><code>pip3 install torch torchvision torchaudio</code></p>
<p>Note: This installation is CPU only. If you have a NVIDIA GPU and would like to run whisper on your GPU, download <a href="https://developer.nvidia.com/cuda-downloads">CUDA</a> and follow the PyTorch GPU setup <a href="https://pytorch.org/get-started/locally/">here</a>.</p>
<center>
<img src="images/conda.png" alt="pytorch install" width="300">
</center>
<p>Note that the installation may take a few minutes to complete, and that the conda prompt will ask you to confirm installation by pressing ‘y’. If the end result looks like this, you’ve installed Pytorch correctly.</p>
</section>
<section id="installing-transformers" class="level4">
<h4 class="anchored" data-anchor-id="installing-transformers">2.2.2 Installing Transformers</h4>
<p><em>Transformers</em> is a python package developped by <em>HuggingFace</em> which allows for easier downloading and training of natural langauge processing models, such as Whisper. The transformers library simplifies the audio transcription process by converting our audio files into text tokens for transcription without redundant code <span class="math inline">\(^{[6]}\)</span>.</p>
<p>We can download the transformers library using the following line of code in our conda prompt. We’ll also install the <code>Datasets</code> library to in case you’d like to use additional short-form audio:</p>
<p><code>pip install --upgrade pip</code></p>
<p><code>pip install --upgrade transformers accelerate datasets[audio]</code></p>
</section>
<section id="installing-whisper" class="level4">
<h4 class="anchored" data-anchor-id="installing-whisper">2.2.3 Installing Whisper</h4>
<p>We can now install whisper. To do so, type the following line of code into the conda command prompt: <code>pip install -U openai-whisper</code>.</p>
<p>Additionally, we’ll need to install the command-line tool <em>FFmpeg</em>, a open source software that helps with audio and video processing. We can do so by running the following line of code in conda prompt: <code>conda install conda-forge::ffmpeg</code>.</p>
</section>
<section id="installing-librosa-and-soundfile" class="level4">
<h4 class="anchored" data-anchor-id="installing-librosa-and-soundfile">2.2.4 Installing Librosa and Soundfile</h4>
<p>Lastly, we’ll need to install librosa and soundfile, python packages for music and video analysis, which will allow us to preprocess our audio recordings before transcribing them. To do this, enter <code>pip install librosa soundfile</code> in the conda command prompt.</p>
<hr>
</section>
</section>
<section id="loading-audio-and-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="loading-audio-and-preprocessing">3. Loading audio and preprocessing</h2>
<section id="loading-audio-samples" class="level3">
<h3 class="anchored" data-anchor-id="loading-audio-samples">3.1 Loading audio samples</h3>
<p>It’s always a good idea to at least partially listen to the audio we wish to transcribe, to make sure that the audio file has no issues.</p>
<p>Lets start off by loading some of the audio samples provided in this module. We’ll do this using the <code>IPython</code> library, which should already be installed on your device. If the code fails to run, run the following line of code in the conda prompt: <code>pip install ipython</code>.</p>
<div id="ef2e4842" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> IPython</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>IPython.display.Audio(<span class="st">"audio samples/mixkit-cartoon-kitty-begging-meow-92.wav"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># warning: Turn down your volume as the audio may be loud!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is another example, this time from a longer <a href="https://www.youtube.com/watch?v=a32RLgqNfGs">ColdFusion Youtube video</a>.</p>
<div id="eb208936" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> IPython</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>IPython.display.Audio(<span class="st">"audio samples/The Boeing Scandal Just Got A LOT Worse.mp3"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># warning: Turn down your volume as the audio may be loud!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="preprocessing-audio" class="level3">
<h3 class="anchored" data-anchor-id="preprocessing-audio">3.2 Preprocessing audio</h3>
<p>A <em>sampling rate</em> is the number of samples per second (or per other unit) taken from a continuous signal (the actual audio) to make a discrete signal (the audio recording)<span class="math inline">\(^{[7]}\)</span>. It’s important to note that Whisper transcription is designed to work on <strong>16kHz audio samples</strong>. Since not all audio is 16kHz, we need to check the sampling rate of our audio file, and if it is not 16kHz, we can resample audio to the correct sampling rate using the librosa library.</p>
<p>Let’s start off by checking the sampling rate of the kitty audio sample:</p>
<div id="93db035d" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> librosa</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> soundfile</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the audio file</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>audio_file_path <span class="op">=</span> <span class="st">"audio samples/mixkit-cartoon-kitty-begging-meow-92.wav"</span>  </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(audio_file_path, sr<span class="op">=</span><span class="va">None</span>)  <span class="co"># Load the audio file and get the original sampling rate</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sampling rate:"</span>, sr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We see that the sampling rate, in this audio sample, is well above the 16khz sampling rate that Whisper requires. Thus, we need to convert it to the proper sampling rate of 16kHz. We’ll do this using the <code>librosa</code> package.</p>
<div id="c8a4e26a" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> librosa</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> soundfile <span class="im">as</span> sf</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the audio file</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>audio_file_path <span class="op">=</span> <span class="st">"audio samples/mixkit-cartoon-kitty-begging-meow-92.wav"</span>  </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(audio_file_path, sr<span class="op">=</span><span class="dv">44100</span>)  <span class="co"># Load the audio file with the current sampling rate</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Resample the audio to 16 kHz</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>y_resampled <span class="op">=</span> librosa.resample(y, orig_sr<span class="op">=</span><span class="dv">44100</span>, target_sr<span class="op">=</span><span class="dv">16000</span>)  <span class="co"># Resample the audio to a sampling rate of 16 kHz</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the resampled audio to a new file</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>output_file_path <span class="op">=</span> <span class="st">"audio samples/mixkit-cartoon-kitty-begging-meow-92_resamples.wav"</span>  <span class="co"># Path to save the resampled audio file</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>sf.write(output_file_path, y_resampled, <span class="dv">16000</span>)  <span class="co"># Save the resampled audio to a WAV file</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="b173cb23" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>audio_file_path <span class="op">=</span> <span class="st">"audio samples/mixkit-cartoon-kitty-begging-meow-92_resamples.wav"</span>  </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(audio_file_path, sr<span class="op">=</span><span class="va">None</span>)  <span class="co"># Load the audio file and get the new sampling rate</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sampling rate:"</span>, sr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p>This also works on MP3 files, such as the coldfusion video we played earlier:</p>
<div id="6465313c" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>audio_file_path <span class="op">=</span> <span class="st">"audio samples/House debates CPC motion of non-confidence against Trudeau's carbon tax CANADIAN POLITICS.mp3"</span>  <span class="co"># Replace "your_audio_file.wav" with the path to your audio file</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(audio_file_path, sr<span class="op">=</span><span class="va">None</span>)  <span class="co"># Load the audio file and get the original sampling rate</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sampling rate:"</span>, sr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="79908889" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the audio file</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>audio_file_path <span class="op">=</span> <span class="st">"audio samples/House debates CPC motion of non-confidence against Trudeau's carbon tax CANADIAN POLITICS.mp3"</span>  </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(audio_file_path, sr<span class="op">=</span><span class="dv">44100</span>)  <span class="co"># Load the audio file with the current sampling rate</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Resample the audio to 16 kHz</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>y_resampled <span class="op">=</span> librosa.resample(y, orig_sr<span class="op">=</span><span class="dv">44100</span>, target_sr<span class="op">=</span><span class="dv">16000</span>)  <span class="co"># Resample the audio to a sampling rate of 16 kHz</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the resampled audio to a new file</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>output_file_path <span class="op">=</span> <span class="st">"audio samples/House_debates_CPC_motion_of_non-confidence_against_Trudeau's_carbon_tax_CANADIAN POLITICS_resampled.mp3"</span>  <span class="co"># Path to save the resampled audio file</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>sf.write(output_file_path, y_resampled, <span class="dv">16000</span>)  <span class="co"># Save the resampled audio to a mp3 file</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="07d80d7b" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>audio_file_path <span class="op">=</span> <span class="st">"audio samples/House_debates_CPC_motion_of_non-confidence_against_Trudeau's_carbon_tax_CANADIAN POLITICS_resampled.mp3"</span>  </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(audio_file_path, sr<span class="op">=</span><span class="va">None</span>)  <span class="co"># Load the audio file and get the original sampling rate</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sampling rate:"</span>, sr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
</section>
</section>
<section id="transcribing-single-speaker-audio" class="level2">
<h2 class="anchored" data-anchor-id="transcribing-single-speaker-audio">4. Transcribing single-speaker audio</h2>
<p>We can now begin testing out audio transcription. There are two important distinctions to keep in mind when transcribing audio:</p>
<ol type="1">
<li>Short-form versus long form audio - whisper is trained on 30-second audio clips, and will thus cut off audio longer than 30 seconds. We can overcome this by <em>chuncking</em> our audio sample into multiple audio samples, and then stitching them back together after the transcription process.</li>
<li>Single-speaker versus multi-speaker audio: Audio with a single speaker is easier to transcribe compared to audio with multiple speakers. The segmentation of speech into individual speakers, known as <strong><em>diarization</em></strong>, requires a slightly different approach to transcription and will be covered in section 5.</li>
</ol>
<section id="transcribing-short-form-audio" class="level3">
<h3 class="anchored" data-anchor-id="transcribing-short-form-audio">4.1 Transcribing short form audio</h3>
<p>Let’s begin transcribing our first audio sample. We’ll be using a trimmed 25 second audio sample from the Wall Street Journal. As mentioned, it’s always a good idea to start off by listening to our audio sample before transcribing it.</p>
<div id="e7102a63" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> IPython</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>IPython.display.Audio(<span class="st">"audio samples/WSJ-23andme_resampled.wav"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="preprocessing" class="level4">
<h4 class="anchored" data-anchor-id="preprocessing">4.1.1 Preprocessing</h4>
<p>You’ll notice that the file in question is an mp4 file rather than a mp3/wav file, meaning that the original file contains both audio and video. This isn’t an issue as we can convert it to a mp3/wav file during the preprocessing step.</p>
<div id="b3d80006" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>audio_file_path <span class="op">=</span> <span class="st">"audio samples\WSJ-23andme.mp4"</span>  </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(audio_file_path, sr<span class="op">=</span><span class="va">None</span>)  <span class="co"># Load the audio file and get the original sampling rate</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sampling rate:"</span>, sr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="8372fc74" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> soundfile <span class="im">as</span> sf</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the audio file</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>audio_file_path <span class="op">=</span> <span class="st">"audio samples/WSJ-23andme.mp4"</span>  </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(audio_file_path, sr<span class="op">=</span><span class="dv">44100</span>)  <span class="co"># Load the audio file with the current sampling rate</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Resample the audio to 16 kHz</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>y_resampled <span class="op">=</span> librosa.resample(y, orig_sr<span class="op">=</span><span class="dv">44100</span>, target_sr<span class="op">=</span><span class="dv">16000</span>)  <span class="co"># Resample the audio to a sampling rate of 16 kHz</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the resampled audio to a new file</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>output_file_path <span class="op">=</span> <span class="st">"audio samples/WSJ-23andme_resampled.wav"</span>  <span class="co"># Path to save the resampled audio file</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>sf.write(output_file_path, y_resampled, <span class="dv">16000</span>)  <span class="co"># Save the resampled audio to a WAV file</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fcb33b71" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>audio_file_path <span class="op">=</span> <span class="st">"audio samples/WSJ-23andme_resampled.wav"</span> </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>y, sr <span class="op">=</span> librosa.load(audio_file_path, sr<span class="op">=</span><span class="va">None</span>)  <span class="co"># Load the audio file and get the original sampling rate</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sampling rate:"</span>, sr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="transcribing" class="level4">
<h4 class="anchored" data-anchor-id="transcribing">4.1.2 Transcribing</h4>
<p>We’re now ready for our first transcription. The transcription process using distill-whisper is divided into the following steps:</p>
<ol type="1">
<li><strong>Model specifications:</strong> We start with initializing a PyTorch model for transcription, selecting either GPU or CPU based on availability. We then specify the pre-trained model we wish to use, with options for optimizing memory usage and ensuring safety in tensor operations.</li>
</ol>
<div id="7cb0e443" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda:0"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span> <span class="co">#If you have CUDA, this will run the transcription process on your GPU. If not, it will default to your CPU.</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>torch_dtype <span class="op">=</span> torch.float16 <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> torch.float32 <span class="co">#specifying GPU/CPU parameters for pytorch</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>model_id <span class="op">=</span> <span class="st">"distil-whisper/distil-large-v3"</span> <span class="co">#specifies the model ID, in this case we are using distil-large-v3</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># you can replace the model with any model you want that is compatible</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSpeechSeq2Seq.from_pretrained(</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    model_id, torch_dtype<span class="op">=</span>torch_dtype, low_cpu_mem_usage<span class="op">=</span><span class="va">True</span>, use_safetensors<span class="op">=</span><span class="va">True</span> <span class="co">#specifying CPU parameters and model, you can change low_cpu_mem_usage to `false` for faster transcription </span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>model.to(device)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>processor <span class="op">=</span> AutoProcessor.from_pretrained(model_id) <span class="co">#specifying processor</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="2" type="1">
<li><strong>Pipeline:</strong> We then create a pipeline for automatic speech recognition using the specified model, tokenizer, and feature extractor, utilizing the specified torch data type and device for computation.</li>
</ol>
<p>A <strong><em>pipeline</em></strong> is a series of interconnected steps or processes designed to accomplish a specific task efficiently. The <i>huggingface</i> audio transcription pipeline is structured to take raw audio inputs and convert them into transcriptions using automatic speech recognition. You can read more about the pipeline used in this tutorial <a href="https://huggingface.co/docs/transformers/main/en/pipeline_tutorial">here</a>.</p>
<div id="c68af2f8" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline( </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"automatic-speech-recognition"</span>, <span class="co">#specifies what we want our model to do</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>processor.tokenizer,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    feature_extractor<span class="op">=</span>processor.feature_extractor,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    max_new_tokens<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    torch_dtype<span class="op">=</span>torch_dtype,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="3" type="1">
<li><strong>Transcription:</strong> Finally, we <em>pipe</em> our audio sample into our pipeline, and generate an output.</li>
</ol>
<p>Note that steps 1 and 2 will only need to be ran once in a given notebook, unless you need to change the model specifications at a later point.</p>
<div id="ae9c6a95" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> pipe(<span class="st">"audio samples/WSJ-23andme_resampled.wav"</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result[<span class="st">"text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You’ll notice that the transcription has minor mistakes, namely transcribing “23andMe” incorrectly. One limitation with automated transcription is that ASR models are trained on a finite vocabulary, and thus struggle with transcribing uncommon or out-of-vocabulary words accurately. Therefore, it’s always a good idea to proofread the generated output.</p>
</section>
</section>
<section id="transcribing-long-form-output" class="level3">
<h3 class="anchored" data-anchor-id="transcribing-long-form-output">4.2 Transcribing long-form output</h3>
<p>Realistically, most audio you’ll be working with is longer than 30 seconds. However, the Whisper ASR model is inherently built on 30 second samples. Any audio shorter than 30 seconds will have additional white noise added to it to bring it to 30 seconds, and any audio longer than 30 seconds will be cut at the 30 second mark. To overcome this, we can modify our code to allow for long-form audio transcription by “chuncking” our audio into 30-second segments, transcribing each segment individually, and then “stitching” the resulting text back together to form the complete transcription.</p>
<p>You can learn more about long-form audio transcription on huggingface <a href="https://huggingface.co/blog/asr-chunking">here</a>.</p>
<center>
<img src="images/audio segmentation.png" alt="segmentation" width="400">
</center>
<p>We will modify our code by adding the following lines of code to our pipeline: <code>chunk_length_s=25,</code> <code>batch_size=16,</code> and <code>stride_length_s=(4, 2)</code>. The <code>chunk_length_s</code> argument specifies the length of each individual chunk to be cut from our audio sample. The <code>stride_length_s</code> argument specifies the length of each <em>stride</em>, the overlapping section between individual chunks. The <code>batch_size</code> argument specifies how many chunks whisper should process at once.</p>
<div id="411271d9" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipeline( </span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"automatic-speech-recognition"</span>, <span class="co">#specifies what we want our model to do</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>processor.tokenizer,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    feature_extractor<span class="op">=</span>processor.feature_extractor,</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    max_new_tokens<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    chunk_length_s<span class="op">=</span><span class="dv">25</span>,</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    stride_length_s<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">2</span>),</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    torch_dtype<span class="op">=</span>torch_dtype,</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device,</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s test out our long-form transcription model on the parliamentary debate sample we saw earlier.</p>
<div id="707d8171" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> pipe(<span class="st">"audio samples/House_debates_CPC_motion_of_non-confidence_against_Trudeau's_carbon_tax_CANADIAN POLITICS_resampled.mp3"</span> )</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result[<span class="st">"text"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="transcribing-multi-speaker-audio" class="level2">
<h2 class="anchored" data-anchor-id="transcribing-multi-speaker-audio">5. Transcribing multi-speaker audio</h2>
<p><strong><em>Speech diarization</em></strong> is the process of partitioning audio containing human speech into segments according to the identity of each speaker <span class="math inline">\(^{[7]}\)</span>.</p>
<center>
<img src="images/speakers.png" alt="speakers" width="400">
</center>
<p>Most audio contains more than one speaker. Thus, diarization can be a useful tool for determining who is speaking, and when. Whisper, on its own, does not support speaker diarization. For this reason, we’ll be combining a number of tools to allow us to diarize audio output. Namely, we’ll be using <em>pyannote</em>, a open-source toolkit for speaker diarization in python <span class="math inline">\(^{[8]}\)</span>, and <em>pyannote-whisper</em>, a python library that extends pyannote diarization to whisper ASR <span class="math inline">\(^{[9]}\)</span>.</p>
<section id="installations-1" class="level3">
<h3 class="anchored">5.1 Installations</h3>
<p><em>Pyannote</em> is built on a number of libraries that require huggingface access tokens to access. Therefore, the first thing we’ll need to do is create an account on <a href="https://huggingface.co/">huggingface</a> and create our own personal access token.</p>
<ol type="1">
<li>Go to https://huggingface.co/join and create an account.</li>
<li>Navigate to <strong>settings</strong> by pressing the circular button at the top right of the screen.</li>
</ol>
<center>
<img src="images/button to press.png" alt="speakers" width="400">
</center>
<ol start="3" type="1">
<li>Nagivate to the left-hand side of the screen and press <strong>Access Tokens</strong>.</li>
</ol>
<center>
<img src="images/access token.png" alt="speakers" width="300">
</center>
<ol start="4" type="1">
<li>Press <strong>New token</strong>, and create a new token. Make sure the token type is a <em>read</em> token. Then, <strong>copy your token</strong>.</li>
</ol>
<center>
<left><img src="images/new token.png" alt="speakers" width="200"></left> <right><img src="images/new token 2.png" alt="speakers" width="200"></right>
</center>
<ol start="5" type="1">
<li>Head over to https://huggingface.co/pyannote/segmentation-3.0 and accept the user license. Make sure you do this while logged in.</li>
<li>Head over to https://huggingface.co/pyannote/speaker-diarization-3.1 and accept the user license. Make sure you do this while logged in.</li>
<li>Lastly, we’ll need to install pyannote. Head over to your conda navigator in administrator mode, activate your environment, and enter <code>pip install pyannote.audio</code>.</li>
</ol>
<p>You should now be all set!</p>
<div class="alert alert-block alert-warning">
<p><b>Warning:</b> When running the cell below, you <i>may</i> get a warning stating that you must accept the user agreements for a few other libraries. Please accept the user agreements for those libraries as well (they will be linked in the error message) and re-run the cell below.</p>
<section id="diarization" class="level3">
<h3 class="anchored" data-anchor-id="diarization">5.2 Diarization</h3>
<p>Let’s transcribe and diarize the CBC interview we played earlier. The first thing we must do is import the pipeline from pyannote and authenticate ourselves.</p>
<div id="873c549e" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyannote.audio <span class="im">import</span> Pipeline</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> Pipeline.from_pretrained(</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"pyannote/speaker-diarization-3.1"</span>,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    use_auth_token<span class="op">=</span><span class="st">"INSERT_TOKEN_HERE"</span>) <span class="co">#replace this with your authentication token!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll also need to specify the number of speakers in the audio. If you are unsure about the number of speakers, you can enter <code>none</code> for one or all of the categories below. The pipeline segment below <em>diarizes</em> our audio into the individual speakers, without transcribing it.</p>
<div id="503ff598" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>who_speaks_when <span class="op">=</span> pipeline(<span class="st">"audio samples\House_debates_CPC_motion_of_non-confidence_against_Trudeau's_carbon_tax_CANADIAN_POLITICS_resampled.mp3"</span>,</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                                      num_speakers<span class="op">=</span><span class="dv">2</span>,  </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                                      min_speakers<span class="op">=</span><span class="dv">2</span>,  </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>                                      max_speakers<span class="op">=</span><span class="dv">2</span>)  <span class="co">#since this code is diarizing the entire audio file, it may take a while to run!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can take a look at the contents of our audio by running the result of the pipeline. We can see that there are two speakers in this interview.</p>
<div id="da1f0e13" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>who_speaks_when</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we’ve diarized our audio sample, let’s transcribe it using whisper. We’ll also add timestamps and speaker identifiers. The OpenAI whisper model is better suited for diarization, therefore, we’ll be working with the whisper-small model rather than the distill-whisper model.</p>
<div id="985d2e90" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load OpenAI Whisper ASR</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> whisper</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># choose among "tiny", "base", "small", "medium", "large"</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># see https://github.com/openai/whisper/</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> whisper.load_model(<span class="st">"small"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="4b725801" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>audio_file <span class="op">=</span> <span class="st">"audio samples\House_debates_CPC_motion_of_non-confidence_against_Trudeau's_carbon_tax_CANADIAN_POLITICS_resampled.mp3"</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyannote.audio <span class="im">import</span> Audio</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> segment, _, speaker <span class="kw">in</span> who_speaks_when.itertracks(yield_label<span class="op">=</span><span class="va">True</span>): <span class="co">#iterating over segments of the audio file and creating speaker labels</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    waveform, sample_rate <span class="op">=</span> audio.crop(audio_file, segment) <span class="co"># extract the waveform data and sampling rate</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> model.transcribe(waveform.squeeze().numpy())[<span class="st">"text"</span>] <span class="co"># transcribes the speech in the segment into text</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>segment<span class="sc">.</span>start<span class="sc">:06.1f}</span><span class="ss">s </span><span class="sc">{</span>segment<span class="sc">.</span>end<span class="sc">:06.1f}</span><span class="ss">s </span><span class="sc">{</span>speaker<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span>) <span class="co">#formats start and end times</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As we can see, the individual speakers have successfully been segmented. However, the resulting output is a bit untidy. Let’s clean it up by assigning names to our two speakers, fixing the timestamps, and adding vertical spacing between each speaker.</p>
<div id="f5176521" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyannote.audio <span class="im">import</span> Audio</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rename_speaker(speaker):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> speaker <span class="op">==</span> <span class="st">"SPEAKER_00"</span>:</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Mike"</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> speaker <span class="op">==</span> <span class="st">"SPEAKER_01"</span>:</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Todd"</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add more elif conditions if you are using a different audio with more speakers</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> speaker  </span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to format output for each speaker</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_speaker_output(segment, speaker, text):</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    start_minutes, start_seconds <span class="op">=</span> <span class="bu">divmod</span>(segment.start, <span class="dv">60</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    formatted_output <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span><span class="bu">int</span>(start_minutes)<span class="sc">:02d}</span><span class="ss">:</span><span class="sc">{</span>start_seconds<span class="sc">:04.1f}</span><span class="ss"> - </span><span class="sc">{</span>rename_speaker(speaker)<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> formatted_output</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>audio_file <span class="op">=</span> <span class="st">"audio samples/House_debates_CPC_motion_of_non-confidence_against_Trudeau's_carbon_tax_CANADIAN_POLITICS_resampled.mp3"</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="co">#feel free to try any other audio file </span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> segment, _, speaker <span class="kw">in</span> who_speaks_when.itertracks(yield_label<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>    waveform, sample_rate <span class="op">=</span> audio.crop(audio_file, segment)</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> model.transcribe(waveform.squeeze().numpy())[<span class="st">"text"</span>]</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    formatted_output <span class="op">=</span> format_speaker_output(segment, speaker, text)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(formatted_output)</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As we can see, the transcription isn’t perfect: Whisper often struggles with last names due to them not being included in the training data. For this reason, it’s important to proof-read the resulting output. If you’d like to try out different audio, add your audio to the <code>audio samples</code> folder and repeat the process using the correct file path. Additionally, if you’d like to use a different model, a full list can be found <a href="https://github.com/openai/whisper">here</a>.</p>
</section>
<section id="optional-converting-asr-transcription-output-into-a-pdf-document" class="level3">
<h3 class="anchored" data-anchor-id="optional-converting-asr-transcription-output-into-a-pdf-document">5.2.1 (Optional) Converting ASR transcription output into a PDF document</h3>
<p>The sample code below uses the reportlab library to automatically convert generated output into a PDF, and serves as an example of an application for ASR transcription. As metioned, proof-reading is still very important, as transcriptions may have errors. Feel free to edit the formatting to your liking. Make sure to install <em>reportlab</em> using <code>pip install reportlab</code> if it is not installed already.</p>
<div id="7ba0f9f0" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyannote.audio <span class="im">import</span> Audio</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> reportlab.lib.pagesizes <span class="im">import</span> letter</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> reportlab.platypus <span class="im">import</span> SimpleDocTemplate, Paragraph</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> reportlab.lib.styles <span class="im">import</span> getSampleStyleSheet</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_pdf(formatted_output_list, output_file<span class="op">=</span><span class="st">"output_transcription_whisper.pdf"</span>):</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> SimpleDocTemplate(output_file, pagesize<span class="op">=</span>letter)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    styles <span class="op">=</span> getSampleStyleSheet() </span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    custom_style <span class="op">=</span> ParagraphStyle(<span class="st">"CustomStyle"</span>, parent<span class="op">=</span>styles[<span class="st">"Normal"</span>], fontName<span class="op">=</span><span class="st">"Times-Roman"</span>, spaceAfter<span class="op">=</span><span class="dv">8</span>) <span class="co">#PDF formatting specifications</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    content <span class="op">=</span> [] <span class="co">#empty list used to store paragraphs and spacers</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> formatted_output <span class="kw">in</span> formatted_output_list:</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        content.append(Paragraph(formatted_output, custom_style))</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>        content.append(Spacer(<span class="dv">1</span>, <span class="fl">0.2</span> <span class="op">*</span> inch)) </span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">#for-loop used to iterate over each formatted output string; creates and appends new paragraphs to the `content` list.</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    doc.build(content) <span class="co">#generates PDF</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rename_speaker(speaker):</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> speaker <span class="op">==</span> <span class="st">"SPEAKER_00"</span>:</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Mike"</span></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> speaker <span class="op">==</span> <span class="st">"SPEAKER_01"</span>:</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Todd"</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add more elif conditions if you are using a different audio with more speakers</span></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> speaker  </span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>formatted_output_list <span class="op">=</span> []</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to format output for each speaker</span></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_speaker_output(segment, speaker, text):</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    start_minutes, start_seconds <span class="op">=</span> <span class="bu">divmod</span>(segment.start, <span class="dv">60</span>)</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    formatted_output <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span><span class="bu">int</span>(start_minutes)<span class="sc">:02d}</span><span class="ss">:</span><span class="sc">{</span>start_seconds<span class="sc">:04.1f}</span><span class="ss"> - </span><span class="sc">{</span>rename_speaker(speaker)<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>text<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> formatted_output</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>audio_file <span class="op">=</span> <span class="st">"audio samples/House_debates_CPC_motion_of_non-confidence_against_Trudeau's_carbon_tax_CANADIAN_POLITICS_resampled.mp3"</span></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a><span class="co">#feel free to try any other audio file </span></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> segment, _, speaker <span class="kw">in</span> who_speaks_when.itertracks(yield_label<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>    waveform, sample_rate <span class="op">=</span> audio.crop(audio_file, segment)</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> model.transcribe(waveform.squeeze().numpy())[<span class="st">"text"</span>]</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>    formatted_output <span class="op">=</span> format_speaker_output(segment, speaker, text)</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>    formatted_output_list.append(formatted_output)</span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>generate_pdf(formatted_output_list)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">6. Resources</h2>
<section id="in-text-citations" class="level3">
<h3 class="anchored" data-anchor-id="in-text-citations">6.1 In-text citations</h3>
<ol type="1">
<li>https://huggingface.co/learn/audio-course/en/chapter5/asr_models</li>
<li>https://en.wikipedia.org/wiki/Whisper_(speech_recognition_system)</li>
<li>https://github.com/huggingface/distil-whisper</li>
<li>https://github.com/sanchit-gandhi/whisper-jax</li>
<li>https://github.com/Vaibhavs10/insanely-fast-whisper</li>
<li>https://huggingface.co/docs/transformers/en/index</li>
<li>https://en.wikipedia.org/wiki/Sampling_(signal_processing)</li>
<li>https://github.com/pyannote/pyannote-audio</li>
<li>https://github.com/yinruiqing/pyannote-whisper</li>
</ol>
</section>
<section id="audio-sources" class="level3">
<h3 class="anchored" data-anchor-id="audio-sources">6.2 Audio sources</h3>
<ol type="1">
<li>https://mixkit.co/free-sound-effects/cat/</li>
<li>https://www.youtube.com/watch?v=a32RLgqNfGs</li>
<li>https://www.youtube.com/watch?v=9x6IN_zOvoQ&amp;t=11s</li>
<li>https://www.youtube.com/watch?v=gkxxtP9F6FY</li>
</ol>
</section>
<section id="additional-resources" class="level3">
<h3 class="anchored" data-anchor-id="additional-resources">6.3 Additional resources</h3>
<ol type="1">
<li>https://www.youtube.com/watch?v=wjZofJX0v4M&amp;t=193s</li>
</ol>


</section>
</section>
</div>
</section>
</section>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../../../docs/4_Advanced/advanced_sentiment_analysis/sentiment_analysis.html" class="pagination-link" aria-label="Sentiment Analysis Using LLMs (Python)">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Sentiment Analysis Using LLMs (Python)</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../docs/4_Advanced/advanced_vocalization/advanced_vocalization_draft.html" class="pagination-link" aria-label="Vocalization (Python)">
        <span class="nav-page-text">Vocalization (Python)</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png"></a>.  <a rel="license" href="https://comet.arts.ubc.ca/pages/copyright.html">See details.</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ubcecon/comet-project/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 The COMET Project and the UBC Vancouver School of Economics are located on the traditional, ancestral and unceded territory of the xʷməθkʷəy̓əm (Musqueam) and Sḵwx̱wú7mesh (Squamish) peoples.
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>