<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-GB" xml:lang="en-GB"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-07-29">
<meta name="description" content="An introduction to fine-tuning LLMs using BERT, in Python.">

<title>4.6 - Advanced - Fine-Tuning Large Language Models for Sentiment Analysis – COMET</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../docs/4_Advanced/advanced_sentiment_analysis/sentiment_analysis.html" rel="next">
<link href="../../../docs/4_Advanced/advanced_linear_differencing/advanced_linear_differencing.html" rel="prev">
<link href="../../../media/comet_favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-7e7dc768f2871c181612adf2ed73633f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<meta name="keywords" content="economics, econometrics, R, data, machine learning, UBC, COMET, geog 374, econ 325, econ 326, learning, teaching, learn r, r help, help, tutorial, r tutorial for beginners,learning statistics with r, learn r programming, learn statistics, linear regression, r machine learning, learn machine learning, university of british columbia, british columbia, r programming for beginners, r language tutorial, r tutorial for beginners, economic data, econometrics tutoring, economics help for students, economics homework help, oer resources for teachers, open educational resources for teachers, educational resource, oer project, oer materials, oer resources, learn economics online, learn econometrics, teach yourself economics, teach yourself econometrics, econometrics basics for beginners">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../media/logo_no_tiny_text.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">COMET</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-get-started" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Get Started</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-get-started">    
        <li>
    <a class="dropdown-item" href="../../../pages/quickstart.html">
 <span class="dropdown-text">Quickstart Guide</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/installation/installing_locally.html">
 <span class="dropdown-text">Install and Use COMET</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_getting_started.html">
 <span class="dropdown-text">Get Started</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-learn-by-skill-level" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Learn By Skill Level</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-learn-by-skill-level">    
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_getting_started.html">
 <span class="dropdown-text">Getting Started</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_beginner.html">
 <span class="dropdown-text">Beginner</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_intermediate.html">
 <span class="dropdown-text">Intermediate - Econometrics</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_geog.html">
 <span class="dropdown-text">Intermediate - Geospatial</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_advanced.html">
 <span class="dropdown-text">Advanced</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="../../../pages/index/all.html">
 <span class="dropdown-text">Browse All</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-learn-by-class" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Learn By Class</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-learn-by-class">    
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_226.html">
 <span class="dropdown-text">Making Sense of Economic Data (ECON 226/227)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_325.html">
 <span class="dropdown-text">Econometrics I (ECON 325)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_326.html">
 <span class="dropdown-text">Econometrics II (ECON 326)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_geog.html">
 <span class="dropdown-text">Statistics in Geography (GEOG 374)</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-learn-to-research" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Learn to Research</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-learn-to-research">    
        <li>
    <a class="dropdown-item" href="../../../pages/index/index_research.html">
 <span class="dropdown-text">Learn How to Do a Project</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-teach-with-comet" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Teach With COMET</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-teach-with-comet">    
        <li>
    <a class="dropdown-item" href="../../../pages/teaching_with_comet.html">
 <span class="dropdown-text">Learn how to teach with Jupyter and COMET</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/using_comet.html">
 <span class="dropdown-text">Using COMET in the Classroom</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/dissemination/dissemination.html">
 <span class="dropdown-text">See COMET presentations</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-contribute" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Contribute</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-contribute">    
        <li>
    <a class="dropdown-item" href="../../../pages/installation/installing_for_development.html">
 <span class="dropdown-text">Install for Development</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/documentation/writing_self_tests.html">
 <span class="dropdown-text">Write Self Tests</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-launch-comet" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-play" role="img">
</i> 
 <span class="menu-text">Launch COMET</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-launch-comet">    
        <li>
    <a class="dropdown-item" href="https://open.jupyter.ubc.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fubcecon%2Fcomet-notebooks&amp;urlpath=lab%2Ftree%2Fcomet-notebooks%2F&amp;branch=main"><i class="bi bi-cloud-check" role="img">
</i> 
 <span class="dropdown-text">Launch on JupyterOpen (with Data)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://open.jupyter.ubc.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fubcecon%2Fcomet-project&amp;urlpath=lab%2Ftree%2Fcomet-project%2F&amp;branch=main"><i class="bi bi-cloud-check" role="img">
</i> 
 <span class="dropdown-text">Launch on JupyterOpen (lite)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://ubc.syzygy.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fubcecon%2Fcomet-project&amp;urlpath=lab%2Ftree%2Fcomet-project%2F&amp;branch=main"><i class="bi bi-gear" role="img">
</i> 
 <span class="dropdown-text">Launch on Syzygy</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://colab.research.google.com/github/ubcecon/comet-notebooks/blob/main/"><i class="bi bi-google" role="img">
</i> 
 <span class="dropdown-text">Launch on Colab</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/ubcecon/comet-notebooks/archive/refs/heads/main.zip"><i class="bi bi-cloud-download" role="img">
</i> 
 <span class="dropdown-text">Launch Locally</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="https://github.com/ubcecon/comet-open/archive/refs/heads/datasets.zip"><i class="bi bi-clipboard-data" role="img">
</i> 
 <span class="dropdown-text">Project Datasets</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/ubcecon/comet-open">
 <span class="dropdown-text">Github Repository</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../#"> 
<span class="menu-text">|</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-about" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">About</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-about">    
        <li>
    <a class="dropdown-item" href="../../../pages/team.html">
 <span class="dropdown-text">COMET Team</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../pages/copyright.html">
 <span class="dropdown-text">Copyright Information</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../pages/index/index_advanced.html">Advanced Modules</a></li><li class="breadcrumb-item"><a href="../../../docs/4_Advanced/advanced_ollama_llm/fine_tuning_llm.html">Training LLMS</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
 <span class="menu-text"><h4>Learn by Skill Level</h4></span>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../pages/index/index_getting_started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started: Introduction to Data, R, and Econometrics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/1_Getting_Started/getting_started_intro_to_jupyter/getting_started_intro_to_jupyter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to JupyterNotebooks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/1_Getting_Started/getting_started_intro_to_r/getting_started_intro_to_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/1_Getting_Started/getting_started_intro_to_data/getting_started_intro_to_data1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Data (Part 1)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/1_Getting_Started/getting_started_intro_to_data/getting_started_intro_to_data2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro to Data (Part 2)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../pages/index/index_beginner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beginner: Using R and Data in Applied Econometrics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_intro_to_statistics1/beginner_intro_to_statistics1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Statistics I</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_intro_to_statistics2/beginner_intro_to_statistics2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Statistics II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_central_tendency/beginner_central_tendency.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Central Tendency</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_dispersion_and_dependence/beginner_dispersion_and_dependence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dispersion and Dependence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_confidence_intervals/beginner_confidence_intervals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Confidence Intervals</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_hypothesis_testing/beginner_hypothesis_testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hypothesis Testing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_intro_to_data_visualization1/beginner_intro_to_data_visualization1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Visualization I</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_intro_to_data_visualization2/beginner_intro_to_data_visualization2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Visualization II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_distributions/beginner_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/2_Beginner/beginner_sampling_distributions/beginner_sampling_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sampling Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/intermediate_intro_to_regression/intermediate_intro_to_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../pages/index/index_intermediate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intermediate: Econometrics and Modeling Using R</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/intermediate_intro_to_regression/intermediate_intro_to_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/intermediate_multiple_regression/intermediate_multiple_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/intermediate_issues_in_regression/intermediate_issues_in_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Issues in Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/intermediate_interactions_and_nonlinear_terms/intermediate_interactions_and_nonlinear_terms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interactions</span></a>
  </div>
</li>
          <li class="px-0"><hr class="sidebar-divider hi "></li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../pages/index/index_geog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Geographic Computation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/geog_374/Lab_05_Chisquare/Lab_05_Chisquare.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chi-Square Test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/geog_374/Lab_06_Ttest/Lab_06_Ttest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">t-test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/geog_374/Lab_02_ANOVA/Lab_02_ANOVA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ANOVA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/geog_374/Lab_03_Regression/Lab_03_Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/3_Intermediate/geog_374/Climate_Disasters/Climate_Disasters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wrangling and Visualizing Data</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../pages/index/index_advanced.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Modules</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_classification_and_clustering/advanced_classification_and_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classification and Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_difference_in_differences/advanced_difference_in_differences.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Differences In Differences</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_geospatial/advanced_geospatial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Geospatial I</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_geospatial/advanced_geospatial_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Geospatial II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_instrumental_variables/advanced_instrumental_variables1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Instrumental Variables I</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_instrumental_variables/advanced_instrumental_variables2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Instrumental Variables II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_llm_apis2/advanced_llm_apis2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Large Language Model APIs (Python)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_linear_differencing/advanced_linear_differencing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Differencing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_ollama_llm/fine_tuning_llm.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Training LLMS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_sentiment_analysis/sentiment_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sentiment Analysis Using LLMs (Python)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_transcription/advanced_transcription_whisper.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transcription (Python)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_vocalization/advanced_vocalization_draft.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vocalization (Python)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_word_embeddings/advanced_word_embeddings_python_version.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings (Python)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_word_embeddings/advanced_word_embeddings_r_version.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings (R)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_panel_data/advanced_panel_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Panel Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../docs/4_Advanced/advanced_synthetic_control/advanced_synthetic_control.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Synthetic Controls</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#prerequisites" id="toc-prerequisites" class="nav-link active" data-scroll-target="#prerequisites">0. Prerequisites</a>
  <ul class="collapse">
  <li><a href="#prior-knowledge" id="toc-prior-knowledge" class="nav-link" data-scroll-target="#prior-knowledge">0.1 Prior Knowledge</a></li>
  </ul></li>
  <li><a href="#understanding-llms-and-fine-tuning" id="toc-understanding-llms-and-fine-tuning" class="nav-link" data-scroll-target="#understanding-llms-and-fine-tuning">1. Understanding LLMs and Fine-Tuning</a>
  <ul class="collapse">
  <li><a href="#what-is-a-llm" id="toc-what-is-a-llm" class="nav-link" data-scroll-target="#what-is-a-llm">1.1 What is a LLM?</a></li>
  <li><a href="#how-does-a-llm-work" id="toc-how-does-a-llm-work" class="nav-link" data-scroll-target="#how-does-a-llm-work">1.2 How does a LLM work?</a></li>
  <li><a href="#weights-weight-matrices-and-fine-tuning" id="toc-weights-weight-matrices-and-fine-tuning" class="nav-link" data-scroll-target="#weights-weight-matrices-and-fine-tuning">1.3 Weights, Weight Matrices, and Fine-tuning</a></li>
  <li><a href="#bidirectional-vs-left-right-encoding-models" id="toc-bidirectional-vs-left-right-encoding-models" class="nav-link" data-scroll-target="#bidirectional-vs-left-right-encoding-models">1.4 Bidirectional VS left-right encoding models</a></li>
  <li><a href="#self-tests" id="toc-self-tests" class="nav-link" data-scroll-target="#self-tests">1.4 Self tests</a></li>
  </ul></li>
  <li><a href="#setting-up" id="toc-setting-up" class="nav-link" data-scroll-target="#setting-up">2. Setting up</a>
  <ul class="collapse">
  <li><a href="#creating-an-envrionment" id="toc-creating-an-envrionment" class="nav-link" data-scroll-target="#creating-an-envrionment">2.1 Creating an envrionment</a></li>
  <li><a href="#installing-cuda" id="toc-installing-cuda" class="nav-link" data-scroll-target="#installing-cuda">2.2 Installing CUDA</a></li>
  <li><a href="#installing-required-libraries" id="toc-installing-required-libraries" class="nav-link" data-scroll-target="#installing-required-libraries">2.3 Installing required libraries</a></li>
  <li><a href="#logging-into-huggingface" id="toc-logging-into-huggingface" class="nav-link" data-scroll-target="#logging-into-huggingface">2.4 Logging into huggingface</a></li>
  <li><a href="#creating-a-huggingface-model-card" id="toc-creating-a-huggingface-model-card" class="nav-link" data-scroll-target="#creating-a-huggingface-model-card">2.5 Creating a huggingface model card</a></li>
  </ul></li>
  <li><a href="#fine-tuning-bert-on-a-given-dataset" id="toc-fine-tuning-bert-on-a-given-dataset" class="nav-link" data-scroll-target="#fine-tuning-bert-on-a-given-dataset">3. Fine-tuning BERT on a given dataset</a>
  <ul class="collapse">
  <li><a href="#loading-in-the-imdb-dataset" id="toc-loading-in-the-imdb-dataset" class="nav-link" data-scroll-target="#loading-in-the-imdb-dataset">3.1 Loading in the IMDB dataset</a></li>
  <li><a href="#defining-tokenizer-and-metrics-functions" id="toc-defining-tokenizer-and-metrics-functions" class="nav-link" data-scroll-target="#defining-tokenizer-and-metrics-functions">3.2 Defining tokenizer and metrics functions</a></li>
  <li><a href="#configuring-and-quantizing-bert" id="toc-configuring-and-quantizing-bert" class="nav-link" data-scroll-target="#configuring-and-quantizing-bert">3.3 Configuring and quantizing BERT</a></li>
  <li><a href="#training-arguments" id="toc-training-arguments" class="nav-link" data-scroll-target="#training-arguments">3.4 Training arguments</a></li>
  <li><a href="#creating-a-trainer-instance-and-training-the-model" id="toc-creating-a-trainer-instance-and-training-the-model" class="nav-link" data-scroll-target="#creating-a-trainer-instance-and-training-the-model">3.5 Creating a trainer instance and training the model</a></li>
  <li><a href="#training-the-model" id="toc-training-the-model" class="nav-link" data-scroll-target="#training-the-model">3.6 Training the model</a></li>
  </ul></li>
  <li><a href="#putting-it-all-together-analyzing-financial-sentiment-around-gamestop-stock-using-finlbert" id="toc-putting-it-all-together-analyzing-financial-sentiment-around-gamestop-stock-using-finlbert" class="nav-link" data-scroll-target="#putting-it-all-together-analyzing-financial-sentiment-around-gamestop-stock-using-finlbert">4. Putting it all together: Analyzing financial sentiment around Gamestop stock using FinlBERT</a>
  <ul class="collapse">
  <li><a href="#loading-in-the-dataset-and-creating-testingtraininginference-splits" id="toc-loading-in-the-dataset-and-creating-testingtraininginference-splits" class="nav-link" data-scroll-target="#loading-in-the-dataset-and-creating-testingtraininginference-splits">4.1 Loading in the dataset and creating testing/training/inference splits</a></li>
  <li><a href="#fine-tuning-the-finbert-model" id="toc-fine-tuning-the-finbert-model" class="nav-link" data-scroll-target="#fine-tuning-the-finbert-model">4.2 Fine-tuning the FinBERT model</a></li>
  <li><a href="#running-inference" id="toc-running-inference" class="nav-link" data-scroll-target="#running-inference">4.3 Running inference</a></li>
  </ul></li>
  <li><a href="#self-test-poem_sentiment-dataset" id="toc-self-test-poem_sentiment-dataset" class="nav-link" data-scroll-target="#self-test-poem_sentiment-dataset">6. Self-test: Poem_sentiment dataset</a></li>
  <li><a href="#citations" id="toc-citations" class="nav-link" data-scroll-target="#citations">7. Citations</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/ubcecon/comet-open/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="fine_tuning_llm.ipynb" download="fine_tuning_llm.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../pages/index/index_advanced.html">Advanced Modules</a></li><li class="breadcrumb-item"><a href="../../../docs/4_Advanced/advanced_ollama_llm/fine_tuning_llm.html">Training LLMS</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">4.6 - Advanced - Fine-Tuning Large Language Models for Sentiment Analysis</h1>
  <div class="quarto-categories">
    <div class="quarto-category">python</div>
    <div class="quarto-category">fine-tuning</div>
    <div class="quarto-category">sentiment-analysis</div>
    <div class="quarto-category">LLMs</div>
    <div class="quarto-category">AI</div>
  </div>
  </div>

<div>
  <div class="description">
    An introduction to fine-tuning LLMs using BERT, in Python.
  </div>
</div>


<div class="quarto-title-meta column-body">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p><i>COMET Team</i><br> Irene Berezin </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">29 July 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<hr>
<p>Sentiment analysis is a useful tool for gathering a high-level understanding of the emotions expressed in written text. For instance, a finance firm may wish to gather information about market sentiment pertaining to bitcoin. It would do so by first gathering a corpus of tweets and posts from various sources online, and analysing it by comparing posts to a special kind of dictionary, called a <em>sentiment dictionary</em>, which contains a list of words and their predetermined sentiment. This process is called <em>lexicon-based sentiment analysis</em>. If you’d like to learn more about lexicon-based sentiment analysis, you can consult <a href="">this notebook</a>.</p>
<p>The issue with lexicon-based sentiment analysis, is that especially in modern times, it can be inaccurate: Dictionary based sentiment analysis is <em>context ignorant</em>, meaning that it struggles with things such as sarcasm and irony, as well as mixed emotions <span class="math inline">\(^{[1]}\)</span>. Additionally, language is constantly changing: for instance, the term “bad” is traditionally associated with negative sentiment, but often holds a different, positive connotation on the internet.</p>
<p>For these reasons, this notebook outlines a novel method of sentiment analysis, which uses large language models (LLMs) to conduct sentiment analysis on a given dataset. In particular, this notebook outlines the process of <em>fine-tuning</em> an LLM for the explicit purpose of sentiment analysis.</p>
<section id="prerequisites" class="level2">
<h2 class="anchored" data-anchor-id="prerequisites">0. Prerequisites</h2>
<section id="prior-knowledge" class="level3">
<h3 class="anchored" data-anchor-id="prior-knowledge">0.1 Prior Knowledge</h3>
<ul>
<li><p>A basic understanding of coding in Python.</p></li>
<li><p>A basic understanding of linear algebra is useful for the theory, but not required for running this notebook. ### 0.2 Hardware/Software requirements</p></li>
<li><p><strong>This notebook requires access to NVIDIA GPU, with at least 12 gigabites of VRAM. Additionally, you will need at least 12 gigabites of RAM.</strong> If you are running on a mac, or your computer doesn’t meet the above requirements, consider running this notebook using <a href="https://colab.research.google.com/">google collab</a>.</p></li>
</ul>
<div class="alert alert-block alert-warning">
<p><b>Warning:</b> For the reason outlined above, this notebook <b>cannot be run on Sygyzy</b>, which limits students to two gigabites of memory. See the installation instructions for installing locally on how to run this notebook directly on your computer.</p>
</div>
<ul>
<li>Conda/miniconda installed on your device.</li>
<li>If not on Collab, either a local instance of jupyterlab, or an IDE.</li>
</ul>
</section>
</section>
<section id="understanding-llms-and-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="understanding-llms-and-fine-tuning">1. Understanding LLMs and Fine-Tuning</h2>
<p>This section gives a introductory, high-level overview of large language models and how they work.</p>
<section id="what-is-a-llm" class="level3">
<h3 class="anchored" data-anchor-id="what-is-a-llm">1.1 What is a LLM?</h3>
<p>In short, a <strong>Large language model (LLM)</strong> is any deep learning model that can comprehend and generate human text <span class="math inline">\(^{[2]}\)</span>. In other words, an LLM is a sophisticated artificial intelligence program designed to understand and generate text based on the input it receives. One such example that you may be familiar with is ChatGPT. This is one of many, many language models available for use on the internet. Other notable examples include LLama (Facebook), and Bard (Google). An LLM learns from vast amounts of text data to improve its ability to understand and respond effectively, similarly to a human.</p>
<p>LLMs are a subset of a wider class of models called <strong>natural language processing models (NLPs)</strong>, computational models designed to understand and interpret human language in order to perform tasks such as text classification, transcription, translation, and more <span class="math inline">\(^{[3]}\)</span>. A <strong>Neural Network</strong> is a computational model that works similar to how the human brain functions. Neural networks consist of layers of interconnected nodes, called neurons, that process information (speech, text, images, etc). These networks are trained to learn patterns and relationships in data, making them capable of tasks like image and speech recognition, natural language processing (chatgpt), as well as Generative Adversarial Networks, which generate images from textual prompts <span class="math inline">\(^{[4]}\)</span>.</p>
</section>
<section id="how-does-a-llm-work" class="level3">
<h3 class="anchored" data-anchor-id="how-does-a-llm-work">1.2 How does a LLM work?</h3>
<p>Sure, giving ChatGPT a prompt and watching it produce an output is interesting, but have you ever wondered <em>how</em> it can do that? In this section, we introduce the basic mechanisms behind large language models powered by generative transformers (GPTs). What makes models such as ChatGPT, Gemini, and LLama so much better than older NLP models is the use of a <strong>transformer architecture</strong> (the “T” in ChatGPT), which allows them to <em>understand</em> prompts and generate human-like text. The transformer architecture is a type of neural network that is able to learn context and meaning of a given input text by tracking relationships within the input text <span class="math inline">\(^{[5]}\)</span>.</p>
<p><strong>1) Vector embedding of input text:</strong> First, the model converts each word in the input sequence into a vector representation known as a token embedding. We won’t go into detail as to how this is done; for that, you can consult the <a href="">notebook on vector embeddings here.</a> Additionally, since transformers do not inherently understand the order of tokens, positional encodings are added, which allow the model to understand where each word is relative to other words in the input text.</p>
<p><strong>2) Attention Mechanism:</strong> First outlined in the landmark research paper “Attention is all you need”<span class="math inline">\(^{[6]}\)</span> by Google in 2017, the attention mechanism or attention block allows the model to focus in on different parts of the input text and calculate how much <em>attention</em> it should pay to every word by comparing it to each other word in the input text. The result is a weighted combination of words’ value vectors, reflecting their relevance. This allows the model to prioritize important words and capture meaningful relationships in the sequence, effectively understanding the context and meaning of a text <span class="math inline">\(^{[7]}\)</span> <span class="math inline">\(^{[8]}\)</span>. For instance, in the phrase “<em>The quick brown fox jumps over the lazy…</em>”, the attention mechanism would allow the model to place more emphasis on the words “fox”, ’quick” and “brown”, and less emphasis on the word “the”.</p>
<p><img src="transformer.png" class="img-fluid"></p>
<p><strong>3) Multi-layer perceptron/feed-forward network:</strong> The multi-layer perceptron, also called a feed-forward network, transforms complex representations of input data by processing it through layers of interconnected “neurons”. This transformation helps the network make predictions, classify data, or generate meaningful outputs, using a process called forward propagation. <span class="math inline">\(^{[9]}\)</span>. Essentially, it allows the model to map input data to desired outputs effectively. You can think of the feed-forward network as asking a series of questions to the each word in the input sequence <span class="math inline">\(^{[10]}\)</span>. For instance, returning to the previous example of <em>“The quick brown fox jumps over the lazy…”</em>, the word “fox” could be asked the question “<em>are you a noun?</em>” and it’s vector embedding would be updated accordingly.</p>
<p>This process is then repeated a number of times: the resulting vectors are parsed through the attention mechanism, and then back into the feed forward network. Each layer’s output becomes the input for the next layer, gradually refining the data. The final layer, which corresponds to the last feed-forward network, produces the network’s prediction. For text generation tasks, this would be take the form of a probability distribution <span class="math inline">\(^{[10]}\)</span>.</p>
<p><strong>4) Unembedding matrix:</strong> The last step multiplies the very last vector in the result of the feed-forward network by a special matrix called the <em>unembedding matrix</em>. The result of this multiplication results in a new matrix, for which each entry corresponds to each word in the english language. The values within this vector correspond to the respective probabilities of each word being the correct “next” word <span class="math inline">\(^{[10]}\)</span> <span class="math inline">\(^{[11]}\)</span>.</p>
</section>
<section id="weights-weight-matrices-and-fine-tuning" class="level3">
<h3 class="anchored" data-anchor-id="weights-weight-matrices-and-fine-tuning">1.3 Weights, Weight Matrices, and Fine-tuning</h3>
<p><strong>Weights:</strong> Weights are parameters within a neural network that are learned during the training process. They determine the strength and direction of the connections in the network <span class="math inline">\(^{[12]}\)</span>. Intially, weights are set randomly; during training, the weights are adjusted to minimize the error between the predicted output and the actual output, by minimizing a loss function. This process is known as <em>gradient descent</em> <span class="math inline">\(^{[10]}\)</span> <span class="math inline">\(^{[13]}\)</span>.</p>
<p><strong>Weight matrices</strong> are structured collections of weights arranged in matrix form. They represent the connections between layers in a neural network. The operation of passing inputs through the network involves matrix multiplication: the input vector is multiplied by the weight matrix to produce the output vector for the next layer <span class="math inline">\(^{[14]}\)</span>.</p>
<p>In the attention mechanism, each word in the input sequence is transformed into three different vectors: the query vector (used to search for relevant information from other words in the sequence), the key vector (represents the words in the sequence and is used to match with query vectors), and the value vector (holds the actual information of the words in the sequence and is used to generate the output of the attention mechanism), using separate weight matrices <span class="math inline">\(^{[14]}\)</span>. For example, if the input is a sequence of words represented as vectors, the queries, keys, and values are computed as:</p>
<p><span class="math display">\[Q=W_{Q}(X), K=W_{K}(X), V=W_{V}(X)\]</span></p>
<p>where <span class="math inline">\(W_{Q}\)</span>​, <span class="math inline">\(W_{K}\)</span>​, and <span class="math inline">\(W_{V}\)</span>​ are weight matrices <span class="math inline">\(^{[14]}\)</span> <span class="math inline">\(^{[15]}\)</span>. These vectors are used to calculate attention scores, which determine how much focus each word should give to every other word in the sequence.</p>
<p><img src="attention_mechanism.png" class="img-fluid"></p>
<p><strong>Fine-tuning</strong> is the process of updating the key, query and value matrices to reflect new data <span class="math inline">\(^{[16]}\)</span>. Because the weight matrices contain both the original, general weights and the new adjustments from the fine-tuning process, fine-tuning allows the model to retain the broad, general knowledge from the pre-training phase while specializing in the a new task, such as sentiment analysis, customer feedback, etc.</p>
</section>
<section id="bidirectional-vs-left-right-encoding-models" class="level3">
<h3 class="anchored" data-anchor-id="bidirectional-vs-left-right-encoding-models">1.4 Bidirectional VS left-right encoding models</h3>
<p>Model LLMs can be grouped into two categories: Those that have bidirectional encoders, and left-right encoders. Left-right encoder models are models that process text sequentially, at any given point in the encoded text sequence, the model can only use information from the current and previous tokens, not future tokens <span class="math inline">\(^{[17]}\)</span>. For instance, when processing the text “The quick brown fox jumps over the lazy dog”, a left-right encoder processing the word “fox” would only have access to the words “the”, “quick” and “brown” when assigning how much attention should be paid to the word “fox”.</p>
<p>Bidirectional encoder models, on the other hand, process the input sequence in both directions, from start to end and from end to start. This allows the model to take into account both the left and right context of each token simultaneously <span class="math inline">\(^{[18]}\)</span>. This makes bidirectional encoder models particularly strong at sentiment analysis tasks, as they are better able to capture the sentiment assigned to each given word <span class="math inline">\(^{[19]}\)</span>.</p>
<p><strong>For this reason, if you wish to use large language models for sentiment analysis, it’s recommended you use bi-directional encoder models for both greater accuracy and faster training speeds.</strong></p>
<p>Some popular models include:</p>
<ul>
<li><a href="https://huggingface.co/ProsusAI/finbert">Finbert</a> (For analyzing financial sentiment)</li>
<li><a href="https://huggingface.co/docs/transformers/en/model_doc/roberta">RoBERTa</a></li>
<li><a href="https://huggingface.co/google-bert/bert-base-uncased">BERT</a></li>
<li><a href="https://huggingface.co/distilbert/distilbert-base-uncased">distilBERT</a> (used in this notebook)</li>
</ul>
</section>
<section id="self-tests" class="level3">
<h3 class="anchored" data-anchor-id="self-tests">1.4 Self tests</h3>
<section id="self-test-1" class="level4">
<h4 class="anchored" data-anchor-id="self-test-1">1.4.1 Self-test 1</h4>
<p>In the phrase “<em>The quick brown fox jumps over the lazy…</em>”, a left-right encoding model reading the word “fox” would have access to the words _____ when determining the word’s ____.</p>
<p>Assign your answer to an object called <code>answer_1</code> as a string in the cell below. For instance, if I were to pick the non-existent option “Z”, I would enter <code>answer_1 = "Z"</code>.</p>
<ul>
<li><ol type="A">
<li>“jumps”, “over”, “the”, and “lazy”. Relevance.</li>
</ol></li>
<li><ol start="2" type="A">
<li>“The”, “quick”, “brown”, “jumps”, “over”, “the”, and “lazy”. Vector embedding.</li>
</ol></li>
<li><ol start="3" type="A">
<li>“The”, “quick”, and “brown”, Vector embedding.</li>
</ol></li>
<li><ol start="4" type="A">
<li>“jumps”, “over”, “the”, and “lazy”. Vector embedding.</li>
</ol></li>
<li><ol start="5" type="A">
<li>“The”, “quick”, and “brown”, Relevance.</li>
</ol></li>
<li><ol start="6" type="A">
<li>“The”, “quick”, “brown”, “jumps”, “over”, “the”, and “lazy”. Relevance.</li>
</ol></li>
</ul>
<div id="0335e84a" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#input your answer here</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="24f2a067" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hashlib</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hashlib <span class="im">import</span> sha256</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>h<span class="op">=</span>hashlib.new(<span class="st">"SHA256"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>h.update(answer_1.encode())</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">str</span>(h.hexdigest()) <span class="op">==</span> <span class="st">"a9f51566bd6705f7ea6ad54bb9deb449f795582d6529a0e22207b8981233ec58"</span>:</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"correct! </span><span class="ch">\U0001f600</span><span class="st">"</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"incorrect, recall the the difference between left-right and bidirectional encoder models."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="7672bfca" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>correct <span class="op">=</span> <span class="st">"C"</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>h<span class="op">=</span>hashlib.new(<span class="st">"SHA256"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>h.update(correct.encode())</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>h.hexdigest()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="self-test-2" class="level4">
<h4 class="anchored" data-anchor-id="self-test-2">1.4.2 Self Test 2</h4>
<p>Suppose an LLM was given the following text and tasked to perform sentiment analysis: “It’s a beautiful sunny day outside”. It’s first take would be to <strong>embed</strong> each word. Which of the following is a reasonable embedding for the word “sunny”?</p>
<ul>
<li><ol type="A">
<li>isjfk29ndlsavbm4_2u3n</li>
</ol></li>
<li><ol start="2" type="A">
<li>” sun-ny ”</li>
</ol></li>
<li><ol start="3" type="A">
<li>&lt;3820.2, 38573.6, 1826.2, 23.3, … 4958.3&gt;</li>
</ol></li>
<li><ol start="4" type="A">
<li>🌞</li>
</ol></li>
</ul>
<p>Assign your answer to an object called <code>answer_2</code> as a string in the cell below. For instance, if I were to pick the non-existent option “Z”, I would enter <code>answer_2 = "Z"</code>.</p>
<div id="b3ff99ab" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#input your answer here</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="7779b60e" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hashlib</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hashlib <span class="im">import</span> sha256</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>h<span class="op">=</span>hashlib.new(<span class="st">"SHA256"</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>h.update(answer_2.encode())</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">str</span>(h.hexdigest()) <span class="op">==</span> <span class="st">'6b23c0d5f35d1b11f9b683f0b0a617355deb11277d91ae091d399c655b87940d'</span>:</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"correct! </span><span class="ch">\U0001f600</span><span class="st">"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>: <span class="bu">print</span>(<span class="st">"incorrect, recall that embeddings have both magnitude and direction."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
</section>
<section id="setting-up" class="level2">
<h2 class="anchored" data-anchor-id="setting-up">2. Setting up</h2>
<p>Before we begin, we’ll need to create a new python environment for our required libraries, as well as install CUDA.</p>
<section id="creating-an-envrionment" class="level3">
<h3 class="anchored" data-anchor-id="creating-an-envrionment">2.1 Creating an envrionment</h3>
<p><strong>Skip this step if you are using Google Collab.</strong></p>
<p>Let’s first create a python environment, using conda.</p>
<ol type="1">
<li><p>Make sure you have miniconda installed, and open up the miniconda prompt.</p></li>
<li><p>In the miniconda prompt, enter <code>conda create -n llm_finetuning jupyter</code>. This will create a new environment called llm_finetuning, with jupyter installed.</p></li>
<li><p>Next, activate the environment by typing <code>conda activate llm_finetuning</code>.</p></li>
</ol>
</section>
<section id="installing-cuda" class="level3">
<h3 class="anchored" data-anchor-id="installing-cuda">2.2 Installing CUDA</h3>
<p>We’ll now need to install CUDA. CUDA is a parallel computing platform that allows computers with NVIDIA GPUs to harness their GPUs for tasks other than graphics rendering (NVIDIA, 2024). This is essential for running LLMs, which require loading in massive amounts of data simultaneously. <strong>For this reason, if you do not have access to an NVIDIA GPU, you will not be able to run this notebook.</strong></p>
<p>Head to <a href="https://developer.nvidia.com/cuda-12-1-0-download-archive">CUDA toolkit 12.1</a> and follow the on-screen prompts to install it. <strong>Note that pytorch requires this specific version of CUDA. If you have a different version already installed, you may need to uninstall it using <code>conda remove cuda</code> or using the windows app installation menu.</strong></p>
</section>
<section id="installing-required-libraries" class="level3">
<h3 class="anchored" data-anchor-id="installing-required-libraries">2.3 Installing required libraries</h3>
<p>We can now install the required libraries.</p>
<ol type="1">
<li><p>The first library we’ll need to install is pytorch: pytorch is an open-source deep learning framework for building deep learning models (NVIDIA, 2024). You can install pytorch using <code>conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia</code>.</p></li>
<li><p>Additionally, we’ll need to install the transformers library. The transformers library is an open-source framework for deep-learning models, which provides access to useful APIs and pre-trained models (Huggingface, 2024). At the same time, we will install the datasets, accelerate, peft, optimum and bitsandbytes libraries. We can install them using:</p></li>
</ol>
<div id="5158a9f4" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install transformers datasets accelerate peft optimum bitsandbytes</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The datasets library is a library that provides access to useful datasets for training LLMs. The other libraries are extensions of the transformers library that provide support for faster training and quantization.</p>
<ol start="3" type="1">
<li>Lastly, we’ll install the huggingface login library, which will allow us to use gated models uploaded to huggingface, as well as upload our own fine-tuned model. You can install it using:</li>
</ol>
<div id="7160df16" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install huggingface_hub</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="4" type="1">
<li>Finally, we’ll need to restart our kernel, so that it recognizes the installed libraries. if you are in VSCode, you can do so by pressing “restart” at the top of the screen. If you are in jupyterlab, you can do so by pressing the “restart the kernel” button at the top left of your screen.</li>
</ol>
</section>
<section id="logging-into-huggingface" class="level3">
<h3 class="anchored" data-anchor-id="logging-into-huggingface">2.4 Logging into huggingface</h3>
<p>We’ll now log into huggingface directly in this notebook, which will allow us to use BERT, as well as upload our own fine-tuned model.</p>
<ol type="1">
<li><p>If you haven’t already, create an account at https://huggingface.co/join.</p></li>
<li><p>Once your account is created, navigate to <code>settings (located at the top right corner of your screen) &gt; Access Tokens &gt; +Create new token</code>. Give your token a name, and select, under user permissions:</p></li>
</ol>
<ul>
<li>Read access to contents of all repos under your personal namespace</li>
<li>Read access to contents of all public gated repos you can access</li>
<li>Write access to contents/settings of all repos under your personal namespace</li>
</ul>
<p>Lastly, press <code>create</code> and copy your token. Save it somewhere, such as in a notepad.</p>
<ol start="3" type="1">
<li>We can now log into huggingface, directly in this notebook. Run the following command, and input your token:</li>
</ol>
<div id="f3ea365f" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> huggingface_hub <span class="im">import</span> login</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>login()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="creating-a-huggingface-model-card" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-huggingface-model-card">2.5 Creating a huggingface model card</h3>
<p>After we train our model, we’d like to be able to save it on huggingface and call it directly from there.</p>
<ol type="1">
<li><p>In Hugginface, navigate to the top-right corner of your screen and press the circular account icon.</p></li>
<li><p>Press <code>new model</code> and create a model card.</p></li>
<li><p>Copy the model ID of the model card by pressing “copy model name to clipboard”.</p></li>
</ol>
</section>
</section>
<section id="fine-tuning-bert-on-a-given-dataset" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuning-bert-on-a-given-dataset">3. Fine-tuning BERT on a given dataset</h2>
<p>As our LLM example, we’ll use BERT. BERT is an open-source large language model created by Goggle, Specifically, we’ll be using distilBERT, a faster and smaller version of BERT created by the HuggingFace team <span class="math inline">\(^{[20]}\)</span>.</p>
<div id="5fcc266f" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset, DatasetDict</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig, TrainingArguments, Trainer, EarlyStoppingCallback, DataCollatorWithPadding</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> peft <span class="im">import</span> prepare_model_for_kbit_training, LoraConfig, get_peft_model</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Dict, Any</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="loading-in-the-imdb-dataset" class="level3">
<h3 class="anchored" data-anchor-id="loading-in-the-imdb-dataset">3.1 Loading in the IMDB dataset</h3>
<p>We’ll fine-tune this model on the imdb dataset <span class="math inline">\(^{[21]}\)</span>, a dataset containing 100 thousand movie reviews and their sentiment: either negative or positive. For teaching purposes, we’ll use a sample of the full dataset, which contains 2000 reviews. 1000 will be used for training, and another 1000 will be used for predicting.</p>
<p><strong>Our goal is to fine-tune a model by training it on a collection of movie reviews, such that is more accurately predicts the sentiment of movie reviews compared to the base model.</strong></p>
<p>Let’s start by taking a look at the dataset:</p>
<div id="9e50bfde" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> load_dataset(<span class="st">'shawhin/imdb-truncated'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we’ve loaded in the dataset, let’s take a closer look at it:</p>
<div id="8d5d52e8" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>dataset</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see that the dataset contains 2 splits: One for training, and one for testing, each with 1000 rows. Let’s preview the hundredth row in the training set:</p>
<div id="8ac8a43c" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">'train'</span>][<span class="dv">100</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see that it contains a movie review, as well as a corresponding label. A label of 0 corresponds to a negative review, and a label of 1 corresponds to a positive review.</p>
</section>
<section id="defining-tokenizer-and-metrics-functions" class="level3">
<h3 class="anchored" data-anchor-id="defining-tokenizer-and-metrics-functions">3.2 Defining tokenizer and metrics functions</h3>
<p>Let’s define some functions required for the LLM to process and evaluate our dataset.</p>
<section id="tokenizer-function" class="level4">
<h4 class="anchored" data-anchor-id="tokenizer-function">3.2.1 Tokenizer function</h4>
<p>The first function is the tokenizer function, designed to tokenize our data, ie, convert each movie review into tokens.</p>
<p>Inputs:</p>
<ul>
<li>examples: A dictionary containing the text data that needs to be tokenized.</li>
<li>tokenizer: An instance of AutoTokenizer from the Huggingface library. This tokenizer is used to convert text into tokens that can be - processed by a transformer model.</li>
</ul>
<p>Operation: The tokenizer is applied to the text data in examples[‘text’]. The text is tokenized with the following parameters:</p>
<ul>
<li>padding=“max_length”: Adjusts the length of the text data to a uniform size by adding extra tokens. Pads the sequences to the maximum length specified by max_length (512 tokens).</li>
<li>truncation=True: Truncates the sequences to ensure they are no longer than max_length.</li>
<li>max_length=512: Sets the maximum length of the tokenized sequences to 512 tokens.</li>
</ul>
<p>Output:</p>
<ul>
<li>A dictionary containing the tokenized text, ready for input into a transformer model.</li>
</ul>
<div id="9df8d4d1" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_function(examples: Dict[<span class="bu">str</span>, Any], tokenizer: AutoTokenizer) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(examples[<span class="st">'text'</span>], padding<span class="op">=</span><span class="st">"max_length"</span>, truncation<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span><span class="dv">512</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a> <span class="co">#Tokenizes the input examples using the provided tokenizer.</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Args:</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        <span class="co">#examples (Dict[str, Any]): A dictionary containing text data to be tokenized.</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">#tokenizer (AutoTokenizer): The tokenizer to be used for tokenizing the text.</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Returns:</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">#Dict[str, Any]: A dictionary with tokenized text.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="computing-accuracy-function" class="level4">
<h4 class="anchored" data-anchor-id="computing-accuracy-function">3.2.2 Computing accuracy function</h4>
<p>This function calculates the accuracy of the model’s predictions.</p>
<p>Input: eval_pred: A tuple containing two elements:</p>
<ul>
<li>logits: The unstandardized predictions from the model, ie, the labels assigned to the movie reviews <em>by the model</em>.</li>
<li>labels: The <em>true</em> labels for the data, ie, the labels assigned to the movie reviews <em>by humans</em>, contained within the dataset.</li>
</ul>
<p>Operation:</p>
<ul>
<li>The logits are converted to standardized predictions using a mathematical function called argmax.</li>
<li>The accuracy is computed by comparing the predictions to the true labels and calculating the mean of correct predictions.</li>
</ul>
<p>Output: - A dictionary with a single key-value pair: {“accuracy”: accuracy}, where accuracy is the computed accuracy of the model’s predictions.</p>
<div id="98bdff70" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_metrics(eval_pred: Any) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, <span class="bu">float</span>]:</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    logits, labels <span class="op">=</span> eval_pred</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> np.argmax(logits, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> np.mean(predictions <span class="op">==</span> labels)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"accuracy"</span>: accuracy}</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">#Computes accuracy metrics from evaluation predictions.</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Args:</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">#eval_pred (Any): A tuple containing logits and labels.</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Returns:</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        <span class="co">#Dict[str, float]: A dictionary with accuracy metrics.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="configuring-and-quantizing-bert" class="level3">
<h3 class="anchored" data-anchor-id="configuring-and-quantizing-bert">3.3 Configuring and quantizing BERT</h3>
<p>We’ll now configure the model in order to fine-tune it. This involves the following steps:</p>
<ol type="1">
<li><p>Specifying the model ID (in this notebook, we use BERT. You can use other LLMs.)</p></li>
<li><p>Tokenizing the IMDB dataset and inserting padding tokens</p></li>
<li><p>Quantizing the model using bitsandbytes</p></li>
<li><p>Setting the parameters we wish to finetune using Lora</p></li>
</ol>
<section id="specifying-the-model-id-tokenizing-and-padding" class="level4">
<h4 class="anchored" data-anchor-id="specifying-the-model-id-tokenizing-and-padding">3.3.1 Specifying the Model ID, tokenizing, and padding</h4>
<div id="225ca2f7" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model_id <span class="op">=</span> <span class="st">"distilbert/distilbert-base-uncased"</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_id)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>tokenizer.add_special_tokens({<span class="st">'pad_token'</span>: <span class="st">'[PAD]'</span>}) <span class="co">#Adding the padding tokens</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>tokenized_datasets <span class="op">=</span> dataset.<span class="bu">map</span>(<span class="kw">lambda</span> example: tokenize_function(example, tokenizer))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="quantizing-and-configuring-lora" class="level4">
<h4 class="anchored" data-anchor-id="quantizing-and-configuring-lora">3.3.2 Quantizing and configuring Lora</h4>
<p>If we want to use a model as big as BERT without frying our computer, we’ll need to <em>quantize</em> it. <strong>Quantization</strong> in machine learning is a process of reducing the precision of the numbers used to represent a model’s parameters, in order to decrease the model size and computational requirements. This often involves converting 32-bit floating-point numbers to lower precision formats like 16-bit or 8-bit integers <span class="math inline">\(^{[22]}\)</span> <span class="math inline">\(^{[23]}\)</span>. In other words, quantization is a technique to reduce the number of bits used to represent each parameter in the model. Mathematically, quantization can be viewed as grouping parameters into buckets. The issue with this is that multiple slightly different parameters are now read as the same parameter!</p>
<center>
<img src="quantization.png" width="500" height="340">
</center>
<p>The primary benefit is faster inference and reduced memory usage, which is especially advantageous for deploying models on resource-constrained devices like laptops and computers designed for casual use <span class="math inline">\(^{[23]}\)</span>. Note that quantization can introduce some loss in model accuracy <span class="math inline">\(^{[24]}\)</span>., therefore, we want to avoid quantizing a model’s parameters down too severely (such as to 2 bits).</p>
<p>We’ll quantize our model using the bitsandbytes library, provided by huggingface:</p>
<ul>
<li><strong>load_in_4bit=True:</strong> This parameter specifies that the model should be loaded using 4-bit quantization.</li>
<li><strong>bnb_4bit_use_double_quant=True:</strong> This parameter indicates the use of double quantization for the 4-bit quantized model. Double quantization is an additional step that can further compress the model weights, typically resulting in better compression ratios and sometimes improved performance.</li>
<li><strong>bnb_4bit_quant_type=“nf4”:</strong> This specifies the type of quantization to use, in this case, 4-bit NormalFloat (nf4).</li>
<li><strong>bnb_4bit_compute_dtype=torch.bfloat16:</strong> This sets the computer number format to be used for computations to bfloat16. bfloat16 is a 16-bit floating-point data type that is often used in machine learning to reduce memory usage while maintaining numerical stability and performance, especially on hardware that supports it (Wikipedia, NA).</li>
</ul>
<div id="8d996422" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>bnb_config <span class="op">=</span> BitsAndBytesConfig(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    load_in_4bit<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_use_double_quant<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_quant_type<span class="op">=</span><span class="st">"nf4"</span>,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_compute_dtype<span class="op">=</span>torch.bfloat16</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s now load our model, and prepare it for training:</p>
<ul>
<li><strong>model = AutoModelForSequenceClassification.from_pretrained(…):</strong> This loads our model into our notebook, while specifying it’s quantization and usage for sequence classification.</li>
<li><strong>model.gradient_checkpointing_enable():</strong> This function enables gradient checkpointing for the model. Gradient checkpointing is a technique to reduce memory usage during training.</li>
<li><strong>prepare_model_for_kbit_training:</strong> This function prepares the model for training with quantization.</li>
</ul>
<div id="51ce1f66" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_id, num_labels<span class="op">=</span><span class="dv">2</span>, quantization_config<span class="op">=</span>bnb_config, device_map<span class="op">=</span>{<span class="st">""</span>:<span class="dv">0</span>})</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a> <span class="co"># This function loads a pre-trained model for sequence classification.</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># model_id is the identifier for the pre-trained model.</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># num_labels=2: This specifies that the model will perform classification with 2 labels (binary classification).</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># quantization_config=bnb_config: This applies the previously defined quantization configuration (bnb_config) to the model, which includes loading the model in 4-bit quantization, using double quantization, etc.</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># device_map={"cuda"}: This maps the model to your GPU.</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>model.gradient_checkpointing_enable()</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> prepare_model_for_kbit_training(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we’ll need to set up LoRA. <strong>LoRA (Low-Rank Adaptation)</strong> is a highly efficient method of fine-tuning, which involves adding <strong>adapters</strong>, trainable additional parameters to the model. Then, when training the model, we’d freeze all other parameters, and only train the additional adapters, thus greatly decreasing training time.</p>
<div id="d27226f3" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> LoraConfig(</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>        lora_alpha<span class="op">=</span><span class="dv">64</span>, <span class="co"># This is a scaling factor for the LoRA layers.</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>        lora_dropout<span class="op">=</span><span class="fl">0.05</span>, <span class="co">#This helps prevent overfitting of the model to the data.</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>        r<span class="op">=</span><span class="dv">4</span>, <span class="co">#This is the rank of the low-rank matrices. It determines the size of the additional trainable parameters. A lower rank means fewer parameters and less memory usage.</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>        bias<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        task_type<span class="op">=</span><span class="st">"SEQ_CLS"</span>,</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>        target_modules<span class="op">=</span>[</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"q_lin"</span>, <span class="st">"k_lin"</span>, <span class="st">"v_lin"</span>, <span class="st">"out_lin"</span>,  <span class="co"># Attention layers</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"lin1"</span>, <span class="st">"lin2"</span>  <span class="co"># Feed-forward network layers</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> get_peft_model(model, config)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="training-arguments" class="level3">
<h3 class="anchored" data-anchor-id="training-arguments">3.4 Training arguments</h3>
<p>Additionally, we’ll need to set our training arguments. These arguments tell the trainer how exactly to train the model. There are many training arguments, and a full list can be found <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments">here</a>. All of these, except the first, are optional, but help reduce training time.</p>
<div class="alert alert-block alert-warning">
<p>output_dir=“yourname/yourmodel” is required and saves the trained model to your huggingface account. <b>Make sure you specify the correct output directory, which is the model name of the model card we created at the start of this notebook.</b></p><b>
</b></div><b>
<div id="838979ac" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> TrainingArguments, Trainer</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the training arguments</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"./results"</span>,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    evaluation_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,  <span class="co"># Set save strategy to match evaluation strategy</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">1</span>,  <span class="co"># Lower batch size to save memory</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">1</span>,  <span class="co"># Lower evaluation batch size to save memory</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    logging_dir<span class="op">=</span><span class="st">"./logs"</span>,</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    save_total_limit<span class="op">=</span><span class="dv">1</span>,  <span class="co"># Only save the most recent model</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">2</span>,  <span class="co"># Accumulate gradients over 2 steps</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    fp16<span class="op">=</span><span class="va">True</span>,  <span class="co"># Enable mixed precision training</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</b></section><b>
<section id="creating-a-trainer-instance-and-training-the-model" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-trainer-instance-and-training-the-model">3.5 Creating a trainer instance and training the model</h3>
<p>Let’s create a instance of the trainer which we’ll use to train the model. Additionally, we’ll specify a padding object that will handle the padding of the input sequences, using the tokenizer.</p>
<div id="019a1e4b" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model, <span class="co"># Specifies the model to be trained.</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args, <span class="co"># Provides the training arguments.</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_datasets[<span class="st">"train"</span>], <span class="co"># Specifies the training dataset.</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>tokenized_datasets[<span class="st">"validation"</span>],  <span class="co"># Specifies the testing dataset.</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>tokenized_datasets[<span class="st">"validation"</span>],</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics, <span class="co"># specifies the accuracy metric function</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,  <span class="co"># Adds the data collator</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training-the-model" class="level3">
<h3 class="anchored" data-anchor-id="training-the-model">3.6 Training the model</h3>
<p>Finally, we can train our model on the dataset. We’ll run the <code>trainer.train</code> command, which will iteratively train our model on the training set and evaluate it on the validation set. It will do so three times, each time using the previous trained version on the testing and validations sets.</p>
<p>Note that the code below may take a long time to run, depending on your computer capabilities. On a GeForce RTX 3090 with 24 GB of VRAM, training time was 50 minutes.</p>
<div id="53ec9ffc" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Once the code below has run, you’ll see the model’s accuracy metrics on both the training and testing set, which should progressively increase with each cycle (epoch).</p>
<p>Here, we’ve only ran training for three epochs. Often times, particularly if you want to actually use your model for inference, you may need to train it over more cycles. You may ask <em>“How do I know when to stop training the model?”</em> It’s important to note that running the model over 400 epochs will not increase accuracy. In fact, it may lead to a decrease in accuracy, by <em>overfitting</em> the model on the training set. Imagine studying for an exam: <strong>overfitting</strong> a model can be thought of as memorizing the solution to each practice question in the practice final instead of understanding the material. You might be great at solving questions from the practice final, but chances are, you’ll do terrible on the exam! Instead, aim to stop training when the accuracy values for the training and validation sets are equal.</p>
<p>Additionally, if the model’s accuracy on the training set is already nearly 100%, you’re unlikely to get any significant improvements in accuracy by continually running training cycles. If you have a low validation accuracy, you may need to change your training arguments or avoid quantizing the default model.</p>
<p>This code will provide evaluation metrics of the model’s accuracy on the validation set.</p>
<div id="43438f94" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>po <span class="op">=</span> trainer.predict(tokenized_datasets[<span class="st">"validation"</span>])</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(po.metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</b></section><b>
<section id="putting-it-all-together-analyzing-financial-sentiment-around-gamestop-stock-using-finlbert" class="level2">
<h2 class="anchored" data-anchor-id="putting-it-all-together-analyzing-financial-sentiment-around-gamestop-stock-using-finlbert">4. Putting it all together: Analyzing financial sentiment around Gamestop stock using FinlBERT</h2>
<p>The financial phrasebank is a dataset of 4845 english articles on global finance, split up into sentences <span class="math inline">\(^{[25]}\)</span>. We want to finetune FinBERT, a model built on the BERT model specifically for financial sentiment <span class="math inline">\(^{[26]}\)</span>, on a section of this corpus, and then use it for inference by having it predict the remainder of the corpus.</p>
<ol type="1">
<li>Pulling the dataset and uploading it to huggingface</li>
<li>Manually creating testing and training splits</li>
<li>Fine-tuning the model on the dataset</li>
<li>Applying it to a collection of gamestop-related sentences</li>
</ol>
<section id="loading-in-the-dataset-and-creating-testingtraininginference-splits" class="level3">
<h3 class="anchored" data-anchor-id="loading-in-the-dataset-and-creating-testingtraininginference-splits">4.1 Loading in the dataset and creating testing/training/inference splits</h3>
<p>The first thing we’ll need to do is create splits for our data. Currently, the financial sentiment is fully labeled by humans, meaning that each text has a sentiment value attached to it. Let’s suppose we only had sentiment labels for half the dataset, use those labels to train our model, and then have the model predict the rest of the sentiment values.</p>
<p>We’ll do this by creating two initial splits of the data: the first will be our dataset used for training the model and validating it’s outputs, while the second will contain no sentiment values. Those values will be inferred by our fine-tuned model. Second, we’ll create two more splits in our training/validation dataset: the first will contain our training data, and the second will contain our validation data.</p>
<div id="4bc55043" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>file_path <span class="op">=</span> <span class="st">'all-data.csv'</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(file_path, encoding<span class="op">=</span><span class="st">'latin1'</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the dataset into training/validation and inference sets</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>training_data, inference_data <span class="op">=</span> train_test_split(data, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>inference_data[<span class="st">'sentiment'</span>] <span class="op">=</span> <span class="st">""</span> <span class="co">#removing the provided sentiment values, we want to generate our own!</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>inference_data.to_csv(<span class="st">"inference_data.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>train_data, test_data <span class="op">=</span> train_test_split(training_data, test_size<span class="op">=</span><span class="fl">0.4</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>train_data.to_csv(<span class="st">"training_data.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>test_data.to_csv(<span class="st">"testing_data.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s take a look at our new datasets:</p>
<div id="11357411" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"# of rows inference:"</span>, <span class="bu">len</span>(inference_data))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"#of rows validation"</span>, <span class="bu">len</span>(test_data))</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"#of rows training:"</span>, <span class="bu">len</span>(train_data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll also convert our datasets into a format that can be read by huggingface libraries, and combine the testing and training datasets into a dictionary, a data structure that stores data in key-value pairs.</p>
<div id="3716dada" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>label_map <span class="op">=</span> {<span class="st">'neutral'</span>: <span class="dv">0</span>, <span class="st">'positive'</span>: <span class="dv">1</span>, <span class="st">'negative'</span>: <span class="dv">2</span>}</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>train_data[<span class="st">'label'</span>] <span class="op">=</span> train_data[<span class="st">'sentiment'</span>].<span class="bu">map</span>(label_map)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>test_data[<span class="st">'label'</span>] <span class="op">=</span> test_data[<span class="st">'sentiment'</span>].<span class="bu">map</span>(label_map)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> Dataset.from_pandas(train_data)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> Dataset.from_pandas(test_data)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> DatasetDict({</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"train"</span>: train_dataset,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"test"</span>: test_dataset</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s take a look at the first entry of this dictionary:</p>
<div id="7bf52298" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">"train"</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="fine-tuning-the-finbert-model" class="level3">
<h3 class="anchored" data-anchor-id="fine-tuning-the-finbert-model">4.2 Fine-tuning the FinBERT model</h3>
<p>We are now ready to fine-tune the finBERT model.</p>
<div id="83e6b80b" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_function(examples: Dict[<span class="bu">str</span>, Any], tokenizer: AutoTokenizer) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, Any]:</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenizer(examples[<span class="st">' text'</span>], padding<span class="op">=</span><span class="st">"max_length"</span>, truncation<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span><span class="dv">512</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_metrics(eval_pred: Any) <span class="op">-&gt;</span> Dict[<span class="bu">str</span>, <span class="bu">float</span>]:</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    logits, labels <span class="op">=</span> eval_pred</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> np.argmax(logits, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> np.mean(predictions <span class="op">==</span> labels)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"accuracy"</span>: accuracy}</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>model_id <span class="op">=</span> <span class="st">"ProsusAI/finbert"</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_id)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>tokenizer.add_special_tokens({<span class="st">'pad_token'</span>: <span class="st">'[PAD]'</span>})</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Tokenize the datasets</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_and_format(examples):</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    tokenized <span class="op">=</span> tokenizer(examples[<span class="st">' text'</span>], padding<span class="op">=</span><span class="st">"max_length"</span>, truncation<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span><span class="dv">512</span>)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    tokenized[<span class="st">'label'</span>] <span class="op">=</span> examples[<span class="st">'label'</span>]</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenized</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>tokenized_datasets <span class="op">=</span> dataset.<span class="bu">map</span>(tokenize_and_format, batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>bnb_config <span class="op">=</span> BitsAndBytesConfig(</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>    load_in_4bit<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_use_double_quant<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_quant_type<span class="op">=</span><span class="st">"nf4"</span>,</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    bnb_4bit_compute_dtype<span class="op">=</span>torch.bfloat16</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_id, num_labels<span class="op">=</span><span class="dv">3</span>, quantization_config<span class="op">=</span>bnb_config, device_map<span class="op">=</span>{<span class="st">""</span>:<span class="dv">0</span>})</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>lora_config <span class="op">=</span> LoraConfig(</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>    lora_alpha<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>    lora_dropout<span class="op">=</span><span class="fl">0.05</span>,</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    r<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>    bias<span class="op">=</span><span class="st">"none"</span>,</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>    task_type<span class="op">=</span><span class="st">"SEQ_CLS"</span>, </span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>    target_modules<span class="op">=</span>[</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">"attention.self.query"</span>, <span class="st">"attention.self.key"</span>, <span class="st">"attention.self.value"</span>, <span class="st">"attention.output.dense"</span>,  <span class="co"># Attention layers</span></span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>        <span class="st">"intermediate.dense"</span>, <span class="st">"output.dense"</span>  <span class="co"># Feed-forward network layers</span></span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> prepare_model_for_kbit_training(model)</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> get_peft_model(model, lora_config)</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"test"</span>,</span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>    eval_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>    logging_dir<span class="op">=</span><span class="st">"./logs"</span>,</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>    metric_for_best_model<span class="op">=</span><span class="st">"accuracy"</span>,</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a>    push_to_hub<span class="op">=</span><span class="va">True</span></span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>data_collator <span class="op">=</span> DataCollatorWithPadding(tokenizer)</span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_datasets[<span class="st">"train"</span>],</span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a>    eval_dataset<span class="op">=</span>tokenized_datasets[<span class="st">"test"</span>],</span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a>    data_collator<span class="op">=</span>data_collator,</span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a>    compute_metrics<span class="op">=</span>compute_metrics,</span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a>    callbacks<span class="op">=</span>[EarlyStoppingCallback(early_stopping_patience<span class="op">=</span><span class="dv">3</span>)]</span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb27-76"><a href="#cb27-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-77"><a href="#cb27-77" aria-hidden="true" tabindex="-1"></a>trainer.push_to_hub()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="running-inference" class="level3">
<h3 class="anchored" data-anchor-id="running-inference">4.3 Running inference</h3>
<p>We are now ready to run inference on our model, ie, have it generate predictions on our unlabelled half of the financial sentiment dataset. We’ll do so using transformers’ pipeline feature, which greatly simplifies running LLMs for inference.</p>
<p>The code below will run inference on the inference_data.csv dataset, and generate a new csv called “predictions” which will contain the labeled texts.</p>
<div id="42185064" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>inference_df <span class="op">=</span> pd.read_csv(<span class="st">'inference_data.csv'</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the pipeline with the fine-tuned model</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">'IreneBerezin/test'</span>  <span class="co"># Path to the saved model directory</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>classifier <span class="op">=</span> pipeline(<span class="st">'text-classification'</span>, model<span class="op">=</span>model_path, tokenizer<span class="op">=</span>model_path, device_map<span class="op">=</span><span class="st">"cuda"</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform inference</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify_text(text):</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> classifier(text)[<span class="dv">0</span>][<span class="st">'label'</span>]</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the classification to each row in the DataFrame</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>inference_df[<span class="st">'sentiment'</span>] <span class="op">=</span> inference_df[<span class="st">'text'</span>].<span class="bu">apply</span>(classify_text)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the predictions to a new CSV file</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>inference_df.to_csv(<span class="st">'predictions_inf.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Inference complete. Predictions saved to predictions.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="self-test-poem_sentiment-dataset" class="level2">
<h2 class="anchored" data-anchor-id="self-test-poem_sentiment-dataset">6. Self-test: Poem_sentiment dataset</h2>
<p>Your turn! The <a href="https://huggingface.co/datasets/google-research-datasets/poem_sentiment">google-research-datasets/poem_sentiment</a> library is a huggingface library with 1100 extracts from poems. These poems are grouped into four categories: positive, negative, mixed, and no-impact (no emotion). Your task is to fine-tune distilBERT on this dataset, then run inference on three poem extracts and see if you obtain the correct sentiment.</p>
<p>The code for inference is provided below.</p>
<div id="3bd2ba7d" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">' '</span>  <span class="co"># Path to the saved model directory</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>classifier <span class="op">=</span> pipeline(<span class="st">'text-classification'</span>, model<span class="op">=</span>model_path, tokenizer<span class="op">=</span>model_path)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> [<span class="st">"Nothing cheers my day more than seeing your radiant face"</span>, </span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>         <span class="st">"The world was clouded in a dark sadness"</span>, </span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>         <span class="st">"The leaves are orange"</span>]</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> classifier(texts)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> result <span class="kw">in</span> results:</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(result)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="citations" class="level2">
<h2 class="anchored" data-anchor-id="citations">7. Citations</h2>
<ol type="1">
<li><p>What are some common challenges or pitfalls of lexicon-based sentiment analysis? (2023, April 12). www.linkedin.com. https://www.linkedin.com/advice/1/what-some-common-challenges-pitfalls-lexicon-based</p></li>
<li><p>What are Large Language Models? NVIDIA Glossary. (n.d.). NVIDIA. https://www.nvidia.com/en-us/glossary/large-language-models/</p></li>
<li><p>What is NLP (Natural Language Processing)? IBM. (n.d.). https://www.ibm.com/topics/natural-language-processing</p></li>
<li><p>Wikipedia contributors. (2024, June 30). Natural language processing. Wikipedia. https://en.wikipedia.org/wiki/Natural_language_processing#Neural_NLP_(present)</p></li>
<li><p>What are Transformers? - Transformers in Artificial Intelligence Explained. (n.d.). Amazon Web Services, Inc.&nbsp;https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/</p></li>
<li><p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., &amp; Polosukhin, I. (2017, June 12). Attention is all you need. arXiv.org. https://arxiv.org/abs/1706.03762</p></li>
<li><p>Sarkar, A. (2023, May 19). All you need to know about ‘Attention’ and ‘Transformers’ — In-depth Understanding — Part 1. Medium. https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021</p></li>
<li><p>Kalra, R. (2024, February 8). Introduction to transformers and attention mechanisms. Medium. https://medium.com/<span class="citation" data-cites="kalra.rakshit/introduction-to-transformers-and-attention-mechanisms-c29d252ea2c5">@kalra.rakshit/introduction-to-transformers-and-attention-mechanisms-c29d252ea2c5</span></p></li>
<li><p>Luhaniwal, V. (2023, May 5). Forward propagation in neural networks — Simplified math and code version. Medium. https://towardsdatascience.com/forward-propagation-in-neural-networks-simplified-math-and-code-version-bbcfef6f9250</p></li>
<li><p>3Blue1Brown. (2024, April 1). But what is a GPT?&nbsp; Visual intro to transformers | Chapter 5, Deep Learning. YouTube. https://www.youtube.com/watch?v=wjZofJX0v4M</p></li>
<li><p>Rohrer, B. (2021, October 9). Transformers from Scratch. https://e2eml.school/transformers.html#attention</p></li>
<li><p>Weights and Biases in machine learning. (n.d.). H2O.ai. https://h2o.ai/wiki/weights-and-biases/</p></li>
<li><p>Trehan, D. (2021, December 14). Gradient descent explained - towards data science. Medium. https://towardsdatascience.com/gradient-descent-explained-9b953fc0d2c</p></li>
<li><p>3Blue1Brown. (2024b, April 7). Attention in transformers, visually explained | Chapter 6, Deep Learning [Video]. YouTube. https://www.youtube.com/watch?v=eMlx5fFNoYc</p></li>
<li><p>Serrano.Academy. (2023b, August 31). The math behind Attention: Keys, Queries, and Values matrices [Video]. YouTube. https://www.youtube.com/watch?v=UPtG_38Oq8o</p></li>
<li><p>Exploration of Parameters-efficient fine-tuning methods (LoRA/MoRA/DoRA) in LLM. (2024, June 14). https://towardsai.net/p/machine-learning/exploration-of-parameters-efficient-fine-tuning-methods-lora-mora-dora-in-llm</p></li>
<li><p>Siva, G. (2022, January 4). BERT — Bidirectional Encoder Representations from Transformer. Medium. https://gayathri-siva.medium.com/bert-bidirectional-encoder-representations-from-transformer-8c84bd4c9021</p></li>
<li><p>Uni-directional transformer VS bi-directional BERT. (n.d.). Stack Overflow. https://stackoverflow.com/questions/55114128/uni-directional-transformer-vs-bi-directional-bert</p></li>
<li><p>Mittal, H., &amp; Garg, N. (2024). Comment Sentiment Analysis Using Bidirectional Encoder Representations from Transformers. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.4770927</p></li>
<li><p>Huggingface Team. DistilBERT. (n.d.). https://huggingface.co/docs/transformers/en/model_doc/distilbert</p></li>
<li><p>Stanford. (n.d.). stanfordnlp/imdb. https://huggingface.co/datasets/stanfordnlp/imdb</p></li>
<li><p>What is quantization? | How it works &amp; applications. (n.d.). MATLAB &amp; Simulink. https://www.mathworks.com/discovery/quantization.html</p></li>
<li><p>Quantization. (n.d.). https://huggingface.co/docs/optimum/en/concept_guides/quantization</p></li>
<li><p>Coelho, A. (2024, January 10). Quantization in LLMs: Why does it matter? https://blog.dataiku.com/quantization-in-llms-why-does-it-matter</p></li>
<li><p>Sentiment analysis for financial news. (2020, May 27). Kaggle. https://www.kaggle.com/datasets/ankurzing/sentiment-analysis-for-financial-news</p></li>
<li><p>ProsusAI/finbert (n.d.). https://huggingface.co/ProsusAI/finbert</p></li>
</ol>


</section>

</b></main><b> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../../../docs/4_Advanced/advanced_linear_differencing/advanced_linear_differencing.html" class="pagination-link" aria-label="Linear Differencing">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Linear Differencing</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../docs/4_Advanced/advanced_sentiment_analysis/sentiment_analysis.html" class="pagination-link" aria-label="Sentiment Analysis Using LLMs (Python)">
        <span class="nav-page-text">Sentiment Analysis Using LLMs (Python)</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</b></div><b> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png"></a>.  <a rel="license" href="https://comet.arts.ubc.ca/pages/copyright.html">See details.</a>
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ubcecon/comet-open/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 The COMET Project and the UBC Vancouver School of Economics are located on the traditional, ancestral and unceded territory of the xʷməθkʷəy̓əm (Musqueam) and Sḵwx̱wú7mesh (Squamish) peoples.
  </li>  
</ul>
    </div>
  </div>
</footer>




</b></body></html>