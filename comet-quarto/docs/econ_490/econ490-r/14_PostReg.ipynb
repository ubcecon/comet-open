{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3124f872-f26c-4bb7-99b1-7dbeeaeb37c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ECON 490: Good Regression Practice (14)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Importing data into R.\n",
    "2. Creating new varables in R.\n",
    "3. Running OLS regressions.\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "1. Identify and correct for outliers by trimming or winsorizing the dependent variable. \n",
    "2. Identify and correct for the problem of multicollinearity.\n",
    "3. Identify and correct for the problem of heteroskedasticity. \n",
    "4. Identify and correct for the problem of non-linearity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461282c4-5024-4716-8824-8235fae5212a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 14.1 Dealing with Outliers \n",
    "\n",
    "Imagine that we have constructed a dependent variable which contains the earnings growth of individual workers and we see that some worker's earnings increased by more than 400%. We might wonder if this massive change is just a coding error made by the statisticians that produced the data set. Even without that type of error, though, we might worry that the earnings growth of a small number of observations are driving the results of our analysis. If this is the case, we are producing an inaccurate analysis based on results that are not associated with the majority of our observations. \n",
    "\n",
    "The standard practice in these cases is to either winsorize or trim the subset of observations that are used in that regression. Both practices remove the outlier values in the dependent variable to allow us to produce a more accurate empirical analysis. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> You should only consider fixing outliers when there is a clear reason to address this issue. Do not apply the tools below if the summary statistics in your data make sense to you in terms of abnormal values. For example, outliers might be a sign that your dependent and independent variables have a non-linear relationship. If that is the case, you will want to consider including an interaction term that addresses that non-linearity. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250148f-17b3-4b97-950d-c8cb318c34ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 14.1.1 Winsorizing a dependent variable\n",
    "\n",
    "Winsorizing is the process of limiting the extreme values of a dependent variable to reduce the effect of (possibly erroneous) outliers. It consists of replacing values below the $a$ percentile with that percentile value and values above the $b$ percentile with that percentile value. Consider the following example using our fake data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb96f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- \u001b[1mAttaching packages\u001b[22m ------------------------------------------------------------------------------- tidyverse 1.3.1 --\n",
      "\n",
      "\u001b[32mv\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.5     \u001b[32mv\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32mv\u001b[39m \u001b[34mtibble \u001b[39m 3.1.5     \u001b[32mv\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.7\n",
      "\u001b[32mv\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.4     \u001b[32mv\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32mv\u001b[39m \u001b[34mreadr  \u001b[39m 2.0.2     \u001b[32mv\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "-- \u001b[1mConflicts\u001b[22m ---------------------------------------------------------------------------------- tidyverse_conflicts() --\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m2861772\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m9\u001b[39m\n",
      "\n",
      "\u001b[36m--\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m------------------------------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (1): sex\n",
      "\u001b[32mdbl\u001b[39m (8): workerid, year, birth_year, age, start_year, region, treated, earnings\n",
      "\n",
      "\n",
      "\u001b[36mi\u001b[39m Use \u001b[30m\u001b[47m\u001b[30m\u001b[47m`spec()`\u001b[47m\u001b[30m\u001b[49m\u001b[39m to retrieve the full column specification for this data.\n",
      "\u001b[36mi\u001b[39m Specify the column types or set \u001b[30m\u001b[47m\u001b[30m\u001b[47m`show_col_types = FALSE`\u001b[47m\u001b[30m\u001b[49m\u001b[39m to quiet this message.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Clear the memory from any pre-existing objects\n",
    "rm(list=ls())\n",
    "\n",
    "# loading in our packages\n",
    "library(tidyverse) #This includes ggplot2! \n",
    "library(haven)\n",
    "library(IRdisplay)\n",
    "\n",
    "#Open the dataset \n",
    "fake_data <- read_csv(\"../econ490-stata/fake_data.csv\")  #change me!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cfedc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>1%</dt><dd>2037.38933</dd><dt>99%</dt><dd>540520.427</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1\\textbackslash{}\\%] 2037.38933\n",
       "\\item[99\\textbackslash{}\\%] 540520.427\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1%\n",
       ":   2037.3893399%\n",
       ":   540520.427\n",
       "\n"
      ],
      "text/plain": [
       "        1%        99% \n",
       "  2037.389 540520.427 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantile(fake_data$earnings, probs = c(0.01,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a271fdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "8.881357"
      ],
      "text/latex": [
       "8.881357"
      ],
      "text/markdown": [
       "8.881357"
      ],
      "text/plain": [
       "[1] 8.881357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min(fake_data$earnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873ad269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1.9e+08"
      ],
      "text/latex": [
       "1.9e+08"
      ],
      "text/markdown": [
       "1.9e+08"
      ],
      "text/plain": [
       "[1] 1.9e+08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max(fake_data$earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f64c4df",
   "metadata": {},
   "source": [
    "From the summary statistics above, we can see that that the income earned by the individual at the 1st percentile is 2,037.23 and that the lowest earner in the data set earned 8.88.  \n",
    "\n",
    "We can also see that income earned by the individual at the 99th percentile is only 540,525.90 and that the highest earner in the data earned over 190,000,000!\n",
    "\n",
    "This table suggests to us that there are large outliers in our dependent variable.\n",
    "\n",
    "We want to get rid of these outliers by winsorizing our data set. What that will mean is replacing the earnings of all observations below the 1st percentile by exactly the earnings of the individual at the 1st percentile. Further, it means replacing the earnings of all observations above the 99th percentile by exactly the earnings of the individual at the 99th percentile. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26ae53-4f54-485f-aaa9-b2371687de07",
   "metadata": {},
   "source": [
    "To winsorize this data, we do the following:\n",
    "\n",
    "1. Create a new variable using the command `mutate` with the same values as earnings that we call *log_earnings_winsor*. We decide to store the winsorized version of the dependent variable as a different variable for organizational purposes - we don't want to overwrite the original data set.\n",
    "2. If earnings are smaller than the 1st percentile, we replace the values of *log_earnings_winsor* with the earnings of the individual at the 1st percentile: `(quantile(fake_data$earnings, probs = 0.01) = 2037.38)`.\n",
    "3. If earnings are larger than the 1st percentile, we replace the values of *earnings_winsor* with the earnings of the individual at the 99th percentile: `(quantile(fake_data$earnings, probs = 0.99) = 540520.4 )`.\n",
    "\n",
    "The values of this new variable will be created using the command `ifelse()`. If earnings are less than 2037, the value of *log_earnings_winsor* is replaced by the log(2037) using this command.\n",
    "\n",
    "You can run these commands yourself below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed3ddf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data <- fake_data %>%\n",
    "        mutate(log_earnings_winsor = ifelse(earnings<2037 ,  log(2037),  ifelse( earnings  > 540520 , log(540520), log(earnings))  )  ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e01f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can use this new dependent variable in our regression analysis. If the outliers were not creating problems, there will be no change in the results. If they were creating problems, those problems will now be fixed. \n",
    "\n",
    "Let's take a look at this by first running the regression from [Module 12](econometrics/econ490-r/12_Linear_Reg.ipynb) with the original earning variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1969b50-431f-4832-8a36-f5266a3b0e2b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = log(earnings) ~ as.factor(sex), data = fake_data)\n",
       "\n",
       "Coefficients:\n",
       "    (Intercept)  as.factor(sex)M  \n",
       "        10.1384           0.5467  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm(data=fake_data, log(earnings) ~ as.factor(sex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02e0f204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = log_earnings_winsor ~ as.factor(sex), data = fake_data)\n",
       "\n",
       "Coefficients:\n",
       "    (Intercept)  as.factor(sex)M  \n",
       "        10.1466           0.5356  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm(data=fake_data, log_earnings_winsor ~ as.factor(sex))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b07933-77fe-405b-8308-3fecb3896484",
   "metadata": {},
   "source": [
    "Do you think that in this case the outliers were having a significant impact before being winsorized?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9db9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 14.1.2 Trimming a dependent variable \n",
    "\n",
    "Trimming consists of replacing both values below the $a$ percentile and values above the $b$ percentile by a missing value. This is done to exclude these outliers from regression, since R by design does not include missing (`NA`) observations in the `lm` command.\n",
    "\n",
    "Below we trim our earnings variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c59570e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_data <- fake_data %>%\n",
    "        mutate(log_earnings_trimmed = ifelse(earnings<2037 ,  NA,  ifelse( earnings  > 540520 , NA, log(earnings))  )  ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba74dae-65ea-4bd7-ba82-dff0341489eb",
   "metadata": {},
   "source": [
    "Here is the result of the regression with the new dependent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c300756-667f-4d75-9fe9-f89e7e1e85b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm(data=fake_data, log_earnings_trimmed ~ as.factor(sex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5026b02d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 14.2 Multicollinearity \n",
    "\n",
    "If two variables are linear combinations of one another they are multicollinear. Ultimately, R does not allow us to include two variables in a regression that are perfect linear combinations of one another, such as a constant or a dummy variable for male and a dummy for female (since female = 1 - male). In all of the regressions above, we see that one of those variables was dropped from the regression \"because of collinearity\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83d5c1",
   "metadata": {},
   "source": [
    "Is this a problem? Not really. Multicollinearity is a sign that a variable is not adding any new information. Notice that with the constant term and a male dummy we can know the mean earnings of females. In this case, the constant term is by construction the mean earnings of females, and the male dummy gives the earning premium for male workers.\n",
    "\n",
    "While there are some statistical tests for multicollinearity, nothing beats having the right intuition when running a regression. If it is clear that two variables contain essentially the same information, we should avoid including both in our analysis. For instance, we might have an age variable that includes both years and months (e.g. if a baby is 1 year and 1 month old, then this age variable would be coded as 1 + 1/12 = 1.083). If we include this variable in a regression that also includes an age variable for only years (e.g the baby's age would be coded as 1) then we would have the problem of multicollinearity. Because they are not perfectly collinear, R might still produce some results, but the coefficients on these two variables would be biased. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6588110",
   "metadata": {},
   "source": [
    "## 14.3 Heteroskedasticity \n",
    "\n",
    "When we run a linear regression, we essentially split the outcome into a (linear) part explained by observables and an error term:\n",
    "\n",
    "$$\n",
    "y_i = a + b x_i + e_i\n",
    "$$ \n",
    "\n",
    "The standard errors in our coefficients depend on $e_i^2$ (as you might remember from ECON 326). Heteroskedasticity refers to the case in which the variance of this projection error depends on the observables $x_i$. For instance, the variance of wages tends to be higher for people who are university educated (i.e. there are some people with very high wages) whereas it is small for people who are non-university educated (i.e. they tend to be concentrated in smaller paying jobs). R by default assumes that the variance does not depend on the observables, which is known as homoskedasticity. It is safe to say that this is an incredibly restrictive assumption.\n",
    "\n",
    "While there are tests for heteroskedasticity, the more empirical economists rely on including heteroskedastic consistent standard errors as a default in their regressions. The most standard way to do this is to use another command similar to `lm()` that comes from the `fixest` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca6eef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'fixest' was built under R version 4.1.3\"\n"
     ]
    }
   ],
   "source": [
    "library(fixest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f610df1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: 57,232 observations removed because of NA values (LHS: 57,232).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = feols(log_earnings_trimmed ~ as.factor(sex) , fake_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ec61d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OLS estimation, Dep. Var.: log_earnings_trimmed\n",
       "Observations: 2,804,540 \n",
       "Standard-errors: Heteroskedasticity-robust \n",
       "                 Estimate Std. Error  t value  Pr(>|t|)    \n",
       "(Intercept)     10.180511   0.001074 9475.687 < 2.2e-16 ***\n",
       "as.factor(sex)M  0.484686   0.001332  363.857 < 2.2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "RMSE: 1.06373   Adj. R2: 0.045382"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(model, vcov=\"HC1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e28c20",
   "metadata": {
    "tags": []
   },
   "source": [
    "A best practice is simply to always use robust standard errors in your ECON 490 project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41387be7-188f-4015-a7db-80ce88a203ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 14.4 Non-linearity\n",
    "\n",
    "Our regression analysis so far assumes that the relationship between our explained and explanatory variables is linear. If this is not the case, meaning the relationship is non-linear, then we will get inaccurate results from our analysis. \n",
    "\n",
    "Let's consider an example. We know that earnings increase with age, but what if economic theory predicts that the amount that earnings increases for each year of age when workers are younger is larger than the amount that earnings increases for each year of age when workers are older? Put another way, what if we predict that earnings increase with age at a decreasing rate?\n",
    "\n",
    "We can correct for this in our model by including a new interaction term that is simply age interacted with itself. You learned how to do this in [Module 13](econometrics/econ490-r/13_Dummy.ipynb). Let's include this in the regression above, remembering that age is a continuous variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bffee3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data <- fake_data %>%\n",
    "        mutate(age2 = age^2 ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10ab7d5b-3683-4868-b0ac-8cc00ebab38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(log_earnings_trimmed ~ as.factor(sex) + age + age2, fake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f031c5-c260-4d14-9b0b-c6ee793bd7da",
   "metadata": {},
   "source": [
    "summary(model, vcov=\"HC1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c201c2-f7e4-415e-a931-659ef9ae04d6",
   "metadata": {},
   "source": [
    "There does seem to be some evidence in our regression results that this economic theory is correct, since the coefficient on the interaction term is both negative and statistically significant.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "\n",
    "**Note:** If there is a theoretical reason for believing that non-linearity exists, R provides some tests for non-linearity. You can also create a scatter plot to see if you can observe a non-linear relationship in the data. We covered that approach in [Module 9](econometrics/econ490-r/9_ggplot_graphs.ipynb).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511af6f3-f148-462c-a63b-33e1510060af",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Run a regression checking how age, sex and the treatment affect log_earnings. Should we include an interaction $age^2$ interaction term in this particular case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8ad5f-a0df-4794-96aa-3e03690cf99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- lm()\n",
    "summary(model, vcov=\"HC1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218d7e7-d8f4-488a-925d-5b899dcef9b3",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Run the code cell below to see the exercise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec05d723-500c-47d1-8473-10199d29d2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://h5p.open.ubc.ca/wp-admin/admin-ajax.php?action=h5p_embed&id=1211\" width=\"841\" height=\"310\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\" title=\"module 12 q2\"></iframe><script src=\"https://h5p.open.ubc.ca/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js\" charset=\"UTF-8\"></script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_html('<iframe src=\"https://h5p.open.ubc.ca/wp-admin/admin-ajax.php?action=h5p_embed&id=1211\" width=\"841\" height=\"310\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\" title=\"module 12 q2\"></iframe><script src=\"https://h5p.open.ubc.ca/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js\" charset=\"UTF-8\"></script>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92848021-4f88-410e-84cb-b13780079c8e",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Winsorize the variable _age_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93943a85-2544-41b5-8981-414752b40a39",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:4:0: unexpected end of input\n2: fake_data <- fake_data %>%\n3:         mutate(\n  ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:4:0: unexpected end of input\n2: fake_data <- fake_data %>%\n3:         mutate(\n  ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "quantile()\n",
    "fake_data <- fake_data %>%\n",
    "        mutate("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaca8ff2-3cc5-4f75-a91d-c80c6f7f38a9",
   "metadata": {},
   "source": [
    "## 14.5 Wrap Up \n",
    "\n",
    "While it is important to always follow best practices for regression analysis, such as checking and correcting for outliers, heteroskedaticity, multicollinearity and non-linearity, this can be more of an art than a science. If you need any guidance on whether or not you need to address these issues, please speak with your instructor or TA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
