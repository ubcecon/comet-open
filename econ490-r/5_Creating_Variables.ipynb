{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52dcbe2e-5db6-46dd-9728-89de39d13c4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ECON 490: Generating Variables (5)\n",
    "\n",
    "## Prerequisites \n",
    "---\n",
    "1. Import datasets in csv and dta format \n",
    "2. Save files \n",
    "\n",
    "## Learning objectives:\n",
    "---\n",
    "In this module, you will learn to:\n",
    "1. Explore a dataset with commands like `glimpse`, `View`, `head`, `summary`, `sapply`, `count` and `table`\n",
    "2. Generate dummy (or indicator) variables using `ifelse`\n",
    "3. Create new variables using `mutate`\n",
    "4. Rename variables using `rename`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51cc109",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.1 Getting Started\n",
    "---\n",
    "We'll continue working with the fake data dataset introduced in the previous lecture. Recall that this dataset is simulating information of workers in the years 1982-2012 in a fake country where a training program was introduced in 2003 to boost their earnings.  \n",
    "\n",
    "Last lecture we introduced the process of loading our `fake_data` dataset into R.\n",
    "1. Import the relevant package (Haven) which gives us access to commands for loading the data. Also import the Tidyverse package in order to clean our data.\n",
    "2. Use the read_csv or read_dta functions to load our dataset. \n",
    "3. Clean our data by factorizing all important variables.\n",
    "\n",
    "Let's run through this procedure quickly so that we are all ready to do our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da404a56-1c12-4f0d-90ff-b72578f6682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘haven’ was built under R version 4.1.3”\n",
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.7     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.9\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 4.1.3”\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 4.1.3”\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 4.1.3”\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(haven)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1594da8-97a5-48c6-8c34-ce8fcdf18e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- read_csv(\"../econ490-stata/fake_data.csv\")\n",
    "data <- as_factor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0942e8-6e3f-4b6c-8a8f-7b47306db9aa",
   "metadata": {},
   "source": [
    "## 5.2 Commands to Explore the Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91dec57",
   "metadata": {},
   "source": [
    "### 5.2.1 `glimpse`\n",
    "\n",
    "The first command we are going to use describes the basic characteristics of the variables in the loaded data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "glimpse(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcd0c7c-f23f-4e98-9f53-28545cf21a95",
   "metadata": {},
   "source": [
    "Alternatively, we can use the `print` command, which displays the same information as the `glimpse` command but in horizontal form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa9206-0d67-4c46-8e9f-d57d461b8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391cfe5-0f51-4865-bd82-765c1bc2bb23",
   "metadata": {},
   "source": [
    "With many variables, this can be harder to read than the `glimpse` command. Thus, we typically prefer to use the `glimpse` command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490d9ed3-7ace-494a-9059-3eb2c48f4de7",
   "metadata": {},
   "source": [
    "### 5.2.2 `View` and `head`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabaaeaa",
   "metadata": {},
   "source": [
    "In addition to use the `glimpse` command, in R Studio we can also open our data editor and see the raw data we have imported as if it were an Excel file. To do so we can use the `View` function. This command will open a new tab with an interactive representation of our data. We can also use the command `head`. This prints out by default the first ten rows of our dataset exactly as it would appear in Excel. We can then specify numeric arguments to the function to increase or decrease the number of rows we want to see, as well as the specific rows we want via indicating their positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812753b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a546b79-3f19-467c-a812-ec02aa43e5ad",
   "metadata": {},
   "source": [
    "There is even the function `tail`, which functions identically to `head` but works from the back of the dataset (outputs the final rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e28764f-32b1-44ce-bb9a-fe926ecdc3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea772ee",
   "metadata": {},
   "source": [
    "Opening the data editor has many benefits. Most importantly we get to see our data as a whole, allowing us to have a clearer perspective of the information the dataset is providing us. For example, here we observe that we have unique worker codes, the year where they are observed, worker characteristics (sex, age, and earnings), and whether or not they participated in the traning program. This is particularly useful when we first load a dataset, since it lets us know if our data has been loaded in correctly and looks appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2db56c-5e83-44cf-ab6b-2771dd875c3e",
   "metadata": {},
   "source": [
    "### 5.2.3 `summary` and `sapply`\n",
    "\n",
    "We can further analyze any variable by using the `summary` command. This commands gives us the minimum, 25th percentile, 50th percentile (median), 75th percentile, and max of each our variables, as well as the mean of each of these variables. It is a good command for getting a quick overview of the general spread of all variables in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97231fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75006e7-bcde-4190-8a87-6d02d56a0694",
   "metadata": {},
   "source": [
    "We can also apply summary to specific variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4dff985f-8cd7-49fc-b47f-24179bea034e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in data$earnings: object of type 'closure' is not subsettable\n",
     "output_type": "error",
     "traceback": [
      "Error in data$earnings: object of type 'closure' is not subsettable\nTraceback:\n",
      "1. summary(data$earnings)"
     ]
    }
   ],
   "source": [
    "summary(data$earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa94c0c-a648-4abe-85d2-efbdb079e542",
   "metadata": {},
   "source": [
    "If we want to quickly access more specific information about our variables, such as their standard deviations, we can supply this as an argument to the function `sapply`. It will output the standard deviations of each of our numeric variables. However, it will not operate on character variables. Remember, we can check the type of each variable using the `glimpse` function from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e35fb0-a8ad-44d1-9036-7b99b0d32460",
   "metadata": {},
   "outputs": [],
   "source": [
    "sapply(data, sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d3e066",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can also apply arguments such as mean, min, and median to the function above; however, sd is a good one since it is not covered in the `summary` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100494f-29d8-4f6b-9372-bb355fa15b30",
   "metadata": {},
   "source": [
    "### 5.2.4 `count` and `table`\n",
    "\n",
    "We can also learn more about the frequency of the different measures of our variables by using the command `count`. We simply supply a specific variable to the function to see the distribution of values for that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78397323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count(data, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc1690-b92e-470c-b4b1-70f8203da6a6",
   "metadata": {},
   "source": [
    "Here we can see that there are five regions indicated in this data set, that more people surveyed came from region 1 and then fewer people surveyed came from region 3. Similarly, we can use the `table` function and specify our variable to accomplish the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686ac47-fdd0-47ea-a5a0-bdb75ed6466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table(data$region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b4d140-2057-46f6-b7f1-9b65ae6a450c",
   "metadata": {},
   "source": [
    "We can also use `group_by` before our `count` command if we want more information about these regions. We can try this below with region and sex. We will see that there were 234,355 female identified persons surveyed in region 1 and 425,698 male identified persons surveyed in region 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f1ffa-e658-4388-9554-02f3639dff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data %>% groupby(region) %>% count(sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a46ea4",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  5.3 Generate Dummy Variables\n",
    "---\n",
    "Dummy variables are variables that can only take on two values: 0 and 1. It is useful to think of a dummy variable as being the answer to a question that can be answered \"yes\" or \"no\". With a dummy variable the answer yes is coded as \"1\" and no is coded as \"0\".\n",
    "\n",
    "Examples of question that are used to create dummy variables can include:\n",
    "\n",
    "1. Is the person female? Females are coded \"1\" and males are coded \"0\".\n",
    "2. Does the person have a university degree? People with a university degree are coded \"1\" and everyone else is coded \"0\".\n",
    "3. Is the person married? Married people are coded \"1\" and everyone else is coded \"0\".\n",
    "4. Is the person a millennial? People born between 1980 and 1996 are coded \"1\" and those born in other years are coded \"0\".\n",
    "\n",
    "As you have probably already figured out, dummy variables are used primarily for data that is qualitative and cannot be ranked in any way. For example, being married is qualitative and \"married\" is neither higher nor lower than \"single\".  However, dummy variables sometimes also refer to variables that are qualitative and ranked, such as level of education, and sometimes for variables that are quantitative, such as age groupings. \n",
    "\n",
    "It is important to remember that dummy variables must always be used when we want to include categorical (qualitative) variables in our analysis. These are variables such as sex, gender, race, marital status, religiosity, immigration status etc. Without creating dummy variables for these demographics, analysis of the results from data analysis, regression, and other research will not be meaningful, as we are working with variables which have been numerically scaled in an arbitrary way. This is especially true for interpreting the coefficients outputted from a regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255798d5-6b3e-4e8b-99bd-b7d52f34e742",
   "metadata": {},
   "source": [
    "### 5.3.1 Creating Dummy Variables using `ifelse`\n",
    "\n",
    "Let's do an example where we create a dummy variable that indicates if the observation identified as female. We are going to use the command `ifelse` which generates a completely new variable based on certain conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c260f56-9654-417b-b082-82e60419e417",
   "metadata": {},
   "outputs": [],
   "source": [
    "data$female = ifelse(data$sex == \"F\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd62c04",
   "metadata": {},
   "source": [
    "What R interprets here is that if the condition `sex == \"F\" ` holds, then our dummy will take the value of 1, else it will take the value of zero. This is where the `ifelse` functional component comes in. Depending on what you're doing, you may want it to be the case that when `sex` is missing, our dummy is zero. We can first check if we have any missing observations for a given variable by using the `is.na` function nested within the `any` function. If there are any missing values for the `sex` variable in this dataset, the code below will return TRUE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c12c9-a46c-441c-81b2-d74f91cd79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(data$sex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5801ee-59c2-47ab-990a-512a49fb6bf6",
   "metadata": {},
   "source": [
    "If we want to account for missing values and ensure that they are denoted as 0 for the dummy `female`, we can again invoke the `is.na` function as an additional condition in our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f54d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data$female = ifelse(data$sex == \"F\" & !is.na(data$sex), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa0c38-c633-4370-8d45-4f15e07471d7",
   "metadata": {},
   "source": [
    "The above condition within our function says that `female` == 1 only when `sex` == \"F\" and `sex` is not marked as NA (since !is.na must be TRUE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae02e4-c392-4524-8e82-2e1f6aaca3e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.3.2 Creating A Series of Dummy Variables using `ifelse`\n",
    "\n",
    "We now know how to create dummy variables with `ifelse`. However, we may also want to create dummy variables corresponding to a whole set of categories for a given variable - for example, one for each region identified in the data set. To do this, we can just meticulously craft a dummy for each category, such as `reg1`, `reg2`, `reg3`, and `reg4`. We must leave out one region to serve as our base group, being region 5, in order to avoid the dummy variable trap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5307149-68fd-41ec-965d-47783d515ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data$reg1 = ifelse(data$region == 1 & !is.na(data$region), 1, 0)\n",
    "data$reg2 = ifelse(data$region == 2 & !is.na(data$region), 1, 0)\n",
    "data$reg3 = ifelse(data$region == 3 & !is.na(data$region), 1, 0)\n",
    "data$reg4 = ifelse(data$region == 4 & !is.na(data$region), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054be0df-f104-47c6-82bd-d01a026e9d77",
   "metadata": {},
   "source": [
    "This command generated five new dummy variables, one for each category for region. We asked Stata to call those variables \"reg\" and so these new dummy variables are called reg1, reg2, reg3, reg4. This is quite cumbersome. There are packages out there which help to expedite this process. Luckily, if we are running a regression on a qualitative variable such as `region`, R will generate the necessary dummy variables for us automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e4c19",
   "metadata": {},
   "source": [
    "## 5.4 Generating Variables based on Expressions\n",
    "---\n",
    "Sometimes we want to generate variables after some transformations (e.g. squaring, taking logs, combining different variables). We can do that by simply writing the expression as an argument to the function `mutate`. For example, let's create a new variable that is simply the natural log of earnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54948c-fc2d-4d42-89f1-82507bb57f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- data %>% mutate(log_earnings = log(earnings))\n",
    "\n",
    "summary(data$log_earnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a94a0-3caa-4a15-97db-36cb7abc0588",
   "metadata": {},
   "source": [
    "Let's try a second example, let's create a new variable that is the number of years since the year the individual started working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270af9fb-e2a3-47c1-aaa8-56d57ac5e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- data %>% mutate(experience_proxy = year - start_year)\n",
    "\n",
    "summary(data$experience_proxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00f18cd-2072-4ee2-bcca-5d923f4dacb4",
   "metadata": {},
   "source": [
    "The `mutate` function allows us to easily add new variables to our dataframe. If we wanted to instead replace a given variable with a new feature, say add one default year to all experience_proxy observations, we can simply redefine it directly in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780e119-25f4-4df2-bb60-a950605d184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data$experience_proxy <- data$experience_proxy + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0d630",
   "metadata": {},
   "source": [
    "## 5.5 Following Good Naming Conventions\n",
    "---\n",
    "Choosing good names for your variables is more important, and harder, than you might think! Sometimes, the variables in a dataset have unrecognizable names, which may be confusing when conducting research. In these cases, it is a good idea to change them immediately. In your research, you will also be creating your own variables (like dummy variables) for qualitative measures and will want to be careful about giving them good names. This is especially important for generating tables, since you will want your tables to be easily legible in your paper.\n",
    "\n",
    "\n",
    "We can rename variables with the `rename` function found inside the `dplyr` package (which we can access via having loaded in R's tidyverse). Let' try to rename one of those dummy variables we created above. Maybe we know that if region = 3 then the region is in the west."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8431c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rename(data, west = reg3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12996cd5",
   "metadata": {},
   "source": [
    "Don’t think that you need to include every piece of information in your variable names. Most of the important information pertaining to a variable is included in its label (more on that in a moment). Avoid variable names that include unnecessary pieces of information and can only be interpreted by you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadca34f-a4c3-4f4f-86d5-366dc5bef9f2",
   "metadata": {},
   "source": [
    "## Wrapping Up\n",
    "---\n",
    "When we are doing your own research, we *always* have to spend some time working with the data before beginning the analysis. In this module we have learned some important tools for manipulating data to get it ready for that analysis. Like everything else that you do in R, emphasis should be on readibility and reproducibility in your code. This is pivotal for you and your audience to understand your research."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
