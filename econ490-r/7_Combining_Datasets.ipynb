{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61624905-f3ef-4dab-9b31-9c940277852d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ECON 490: Combining Datasets (7)\n",
    "---\n",
    "## Prerequisites: \n",
    "---\n",
    "1. Import datasets in csv and dta format. \n",
    "2. Create new variables for a variety of purposes. \n",
    "3. Use group_by and other functions to conduct group level analysis.\n",
    "\n",
    "## Learning Objectives:\n",
    "---\n",
    "- Append new observations and variables to an already existing dataset using `rbind` and `cbind`.\n",
    "- Merge variables and their values from one dataset into another using `left_join`, `right_join`, `inner_join`, and `full_join`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3ca873-2339-492d-ab4c-7d78da4fc393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘haven’ was built under R version 4.1.3”\n",
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.9\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 4.1.3”\n",
      "Warning message:\n",
      "“package ‘tidyr’ was built under R version 4.1.2”\n",
      "Warning message:\n",
      "“package ‘readr’ was built under R version 4.1.2”\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 4.1.3”\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(haven)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17e51d-c139-42b2-9f11-7598fcbe4e4c",
   "metadata": {},
   "source": [
    "We'll continue working with the fake data dataset introduced in the previous lecture. Recall that this dataset is simulating information of workers in the years 1982-2012 in a fake country where a training program was introduced in 2003 to boost their earnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f500256f-d9b9-4cc0-b4db-ce56a312b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data <- read_csv(\"../econ490-stata/fake_data.csv\")  # change me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f79bee-10b8-40ea-aae0-6af2d7925b59",
   "metadata": {},
   "source": [
    "Since we are working with multiple datasets in this module, we will also import the region year dataset below. This dataset is much smaller and gives the average log earnings and total number of people employed among each region in a series of years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a77e519-3300-43df-b968-54ab8c57a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_year_data <- read_dta(\"../econ490-stata/region_year_data.dta\") # change me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7bc762-837a-45ef-8a30-d3915fe2dd9e",
   "metadata": {},
   "source": [
    "Often we will need to draw on data from multiple datasets such as these. Most of the time, these datasets will be available for download in different files (each for a given year, month, country, etc.) and may store different variables or observations. Thus, if we want to compile them we need to combine them into the same data frame.\n",
    "\n",
    "There are two key ways of combining data, each reflecting different goals:\n",
    "\n",
    "1. When we want to paste data directly beside or under our existing dataset, we call this **appending** data.\n",
    "    * If you think of a dataset as a spreadsheet, this is like taking one dataset and \"pasting\" it into the bottom of another to add more observations, or pasting one dataset directly beside another to add more variables. We do this when two datasets have identical columns/variables (so that we can stack them vertically) or identical number of observations (so that we can stick them beside each other horizontally).\n",
    "2. When we want to add new variables and their data from another dataset into our existing dataset, we call this **merging** data.\n",
    "    * This is like looking up values in a table and then adding a column; in Excel, this is called a `VLOOKUP`. Importantly, we can only merge data that share a common column or key to  identify observations with particular values. For example, if we want to merge in data from a different year but for the same people (observations) as those we are currently working with, datasets will usually have an identifying number for the person that functions as our key when merging. Unlike with appending, this does not require column names or numbers of observations to be identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666ca06b-6002-4694-be08-88d465045b56",
   "metadata": {},
   "source": [
    "## 7.1: Appending Datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d69f0c-7549-46f6-b6c8-baff425e91e3",
   "metadata": {},
   "source": [
    "### 7.1.1: Append vertically with `rbind`\n",
    "Let's say that our `fake_data` dataset is inexplicably missing 3 observations for worker 1; specifically, the earnings for this worker for the years 2003, 2005, and 2007 are missing. However, let's say these observations exist in another dataset, `missing_data`, which we can append to our `fake_data` dataset since it contains all of the same variables. We can inspect this small dataframe below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18203067-8b2e-40b7-8c34-f1129bfa8d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 3 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>workerid</th><th scope=col>year</th><th scope=col>sex</th><th scope=col>birth_year</th><th scope=col>age</th><th scope=col>start_year</th><th scope=col>region</th><th scope=col>treated</th><th scope=col>earnings</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>2003</td><td>M</td><td>1944</td><td>59</td><td>1997</td><td>1</td><td>0</td><td>30000</td></tr>\n",
       "\t<tr><td>1</td><td>2005</td><td>M</td><td>1944</td><td>61</td><td>1997</td><td>1</td><td>0</td><td>35000</td></tr>\n",
       "\t<tr><td>1</td><td>2007</td><td>M</td><td>1944</td><td>63</td><td>1997</td><td>1</td><td>0</td><td>36000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " workerid & year & sex & birth\\_year & age & start\\_year & region & treated & earnings\\\\\n",
       " <dbl> & <dbl> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 & 2003 & M & 1944 & 59 & 1997 & 1 & 0 & 30000\\\\\n",
       "\t 1 & 2005 & M & 1944 & 61 & 1997 & 1 & 0 & 35000\\\\\n",
       "\t 1 & 2007 & M & 1944 & 63 & 1997 & 1 & 0 & 36000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 9\n",
       "\n",
       "| workerid &lt;dbl&gt; | year &lt;dbl&gt; | sex &lt;chr&gt; | birth_year &lt;dbl&gt; | age &lt;dbl&gt; | start_year &lt;dbl&gt; | region &lt;dbl&gt; | treated &lt;dbl&gt; | earnings &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 2003 | M | 1944 | 59 | 1997 | 1 | 0 | 30000 |\n",
       "| 1 | 2005 | M | 1944 | 61 | 1997 | 1 | 0 | 35000 |\n",
       "| 1 | 2007 | M | 1944 | 63 | 1997 | 1 | 0 | 36000 |\n",
       "\n"
      ],
      "text/plain": [
       "  workerid year sex birth_year age start_year region treated earnings\n",
       "1 1        2003 M   1944       59  1997       1      0       30000   \n",
       "2 1        2005 M   1944       61  1997       1      0       35000   \n",
       "3 1        2007 M   1944       63  1997       1      0       36000   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_data <- data.frame(workerid = c(1, 1, 1), year = c(2003, 2005, 2007), sex = c(\"M\", \"M\", \"M\"), \n",
    "                           birth_year = c(1944, 1944, 1944), age = c(59, 61, 63), start_year = c(1997, 1997, 1997),\n",
    "                           region = c(1, 1, 1), treated = c(0, 0, 0), earnings = c(30000, 35000, 36000))\n",
    "\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9234f3e-7088-4eb1-a408-df9bfd021ceb",
   "metadata": {},
   "source": [
    "To append these four rows to the bottom of our dataset, we can simply use the `rbind` function (row bind). This function allows us to bind together datasets vertically, with the dataset specified second being placed directly underneath the dataset specified first. In this way, we can combine datasets vertically if they share the same column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074b825-025f-44d8-938c-fe75d08a3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data <- rbind(fake_data, missing_data)\n",
    "\n",
    "tail(fake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e215dd2-0b25-4473-874a-fe537f41e955",
   "metadata": {},
   "source": [
    "This is a fast way of concatenating datasets vertically. We can see that it also does not require us to have a designated \"master\" and \"using\" dataset. We can have both datasets stored in our notebook and view them simultaneously, making the process of appending datasets simpler, especially if we want to check for identical column names or missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5982bd19-4741-4236-9449-117d10b565c4",
   "metadata": {},
   "source": [
    "### 7.1.2: Append horizontally with `cbind`\n",
    "We may also want to concatenate datasets horizontally. Suppose that we have a new variable, `religious`, which is a dummy coded as 0 if the person self-identified as religious in that year and 0 if not. This dataframe (which is technically a vector) is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c029f84-dd40-4110-a391-28b92fa0a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "\n",
    "missing_data2 <- data.frame(religious = sample(0:1, 2861772, replace = TRUE))\n",
    "\n",
    "head(missing_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fb1b28-e01f-4cd3-80d8-8e668dd9a2d1",
   "metadata": {},
   "source": [
    "Assuming it is ordered identically to our `fake_data` dataset with respective to participants, we can simply bind this column to our existing dataset using the `cbind` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b4854-fa14-4e1e-9134-126f85cedaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data <- cbind(fake_data, missing_data2)\n",
    "\n",
    "head(fake_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc8bd0e-58d9-4b76-8b0b-dfdc3999fe3e",
   "metadata": {},
   "source": [
    "We can see that this function appended our `religious` variable to the dataset. However, it required us to have an identical number of observations between the two dataframes, and for both dataframes to be ordered identically with respect to people. Often this is not the case, so we must turn to a more commonly used and slightly more challenging concept: merging datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4db390a-9407-4f0c-a6c6-b7d1e2be8c6a",
   "metadata": {},
   "source": [
    "## 7.2: Merging Datasets \n",
    "---\n",
    "Merging datasets means matching existing observations between datasets along specific variables, typically in order to add more information about existing participants to our current dataset. This process, also known in R as joining data, is more complicated than simply appending data. Luckily, we have four functions with descriptive names which help to crystallize this process for us depending on how we want to merge two datasets. Before we start, we should look at the structure of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c35906-b27c-4e91-bd2f-d62704b3d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(fake_data)\n",
    "\n",
    "head(region_year_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af205cc0-2a47-47ae-b266-6e23dfc9fde9",
   "metadata": {},
   "source": [
    "To do a merge of any type, we need to specify a \"key\" or variable on which we will merge our datasets. It is best to choose a variable (or variables) which uniquely identify each observation, otherwise merging will incur challenges. We can guess from our knowledge of the dataset that every combination of `workerid` and `year` returns a unique observation in the `fake_data` dataset. Looking at the `region_year_data` dataset above, we can see that every combination of `year` and `region` identifies unique observations in this dataset. This second dataset, however, does not have the `workerid` variable, while the first dataset has all three of the `workerid`, `year` and `region`. Since the unique identifiers common to both datasets are `year` and `region`, we will use these as our keys within the join functions. Since there are many observations with identical years and regions within the `fake_data` dataset, we will be doing what is similar to a m:1 merge in Stata. However, we can specify how we would like matched and unmatched observations to be treated.\n",
    "\n",
    "> **Tip**: If we do not have any common identifiers between our datasets, but do have variables which express the exact same information, we can simply rename one of the variables so that they are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a95616-1330-4900-9a5a-0263e286e42c",
   "metadata": {},
   "source": [
    "### 7.2.1: Merge with `left_join`\n",
    "The left join merge is a type of merge whereby we merge two datasets along one or more \"keys\", but keep all observations without a match from the dataset specified first in the function and discard all the unmatched observations in the dataset specified second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d0bc6a-7cd6-4b8d-9dfe-7c1105d8c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_join(fake_data, region_year_data, by = c(\"year\", \"region\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79567c25-b2a0-43d4-bf64-94391fd1ebdb",
   "metadata": {},
   "source": [
    "Notice here that this function preserves all rows in the first dataset, in this case the `fake_data` dataset, no matter what. The only rows of the second dataset, `region_year_data`, which are kept are those which can be matched to a corresponding row from the first with identical key values (identical values for `year` and `region`). A direct partner to this function is the `right_join` function, which operates identically but in reverse. That is, it keeps all observations in the second dataset and keeps only those in the first which found a match with the second based on the identifier columns specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085cb3e-6790-4278-9998-49879955a8ca",
   "metadata": {},
   "source": [
    "### 7.2.2: Merge with `inner_join`\n",
    "The inner join merge is a type of merge whereby we keep only observations which have found a match between the two datasets. In this way, this function necessarily discards as many or more observations than the other types of merges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944cd19-0b2d-479e-bde5-ab26586f8709",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join(fake_data, region_year_data, by = c(\"year\", \"region\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ea953-2539-449f-a8ed-0b07868c57b9",
   "metadata": {},
   "source": [
    "We can see that this function matched many identical region and year pairings to different workers. That is because there are many workers who have data reported for the same year and same region (i.e. many different workers in `fake_data` have earnings recorded for 1999 in region 1. In some datasets, however, especially those which are not as large as `fake_data`, we will lose many observations with `inner_join`, since this function only preserves observations which can be matched across the key/s specified in both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f81aa-2557-445e-9ac6-6bdb3724332d",
   "metadata": {},
   "source": [
    "### 7.2.3: Merge with `full_join`\n",
    "This is the function that is closest to appending data horizontally. The process of full join ensures that all observations from both datasets are maintained; if observations from one dataset do not find a match, they simply take on values of NA for the newly merged variables from the other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e453f-5100-4936-96d6-83d660c1a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_join(fake_data, region_year_data, by = c(\"year\", \"region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60585b78-be85-441c-86c3-f2c2fb78fbf4",
   "metadata": {},
   "source": [
    "We can see that this function left many observations from our `fake_data` dataset with missing values for variables from our `region_year_data` dataset such as `avg_log_earnings` and `total_employment`. This is because the `fake_data` dataset has observations for workers in years which are not included in the `region_year_data` dataset (since the former records information from 1982 on the latter records information from 1998 on). In this way, while `full_join` typically retains the highest number of observations, it fills our dataset with many missing observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa41b9-c31f-4403-b58d-b60415785cd1",
   "metadata": {},
   "source": [
    "When choosing which merge method to choose, it is important to consider if any observations will not find a match, which datasets these \"unmatched\" observations are in, and whether we would like for these observations to be recorded as missing or dropped. If we wish to drop unmatched observations in all cases, `inner_join` is most appropriate. If we have two datasets and want to drop unmatched observations solely from the first, `left_join` is most appropriate (and correspondingly `right_join` if we want to drop unmatched observations solely from the second). Finally, if we wanted to keep all observations no matter what and have unmatched observations automatically marked with missing values for variables for which they have no recorded information, we should use `full_join`. In all cases, unmatched observations refer to observations in a dataset which do not share the same recorded value for the specified key/s (common identifier/s) with the dataset they are being merged with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659dde3e-2dad-496c-89f1-35e4538dcb27",
   "metadata": {},
   "source": [
    "## 7.3: Wrap Up\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6f3c1-9e7f-43b4-abba-b8f4df719c70",
   "metadata": {},
   "source": [
    "In this module, we learned how to combine different datasets. The most important lesson we should take away from this module is that we can append datasets vertically when they have identical variables and horizontally when they have identical observations (and when these variables and observations are identically ordered in both datasets). More generally, however, we want to merge different variables (columns) between two datasets using common identifier variables. We have a series of four types of merges we can use to accomplish this, each of which treats unmatched observations differently.\n",
    "\n",
    "As a final note, throughout this module we used the join functions. However, base R has a `merge` function which can accomplish all of the joins we have discussed. We didn't cover this function in detail, however, because it operates much more slowly on large datasets. If you wish to learn more about this function, you can view its documentation by running the code cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9e6fb-cd34-459b-983f-1e4767fb7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "?merge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
