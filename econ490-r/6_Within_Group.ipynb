{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53f8bd0",
   "metadata": {},
   "source": [
    "# ECON 490: Within Group Analysis (6)\n",
    "\n",
    "## Prerequisites\n",
    "---\n",
    "1. Inspect and clean the variables of a data set.\n",
    "2. Generate basic variables for a variety of purposes.\n",
    "\n",
    "## Learning Outcomes\n",
    "---\n",
    "1. Use `arrange`, `group_by`, `group_keys` and `ungroup` to sort and organize data for specific purposes.\n",
    "2. Generate variables with `summarize` to analyze patterns within groups of data. \n",
    "3. Reshape data frames using `pivot_wider` and `pivot_longer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a976d969-7824-4da8-98d6-0a8041c61a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘testthat’ was built under R version 4.1.3”\n"
     ]
    }
   ],
   "source": [
    "source(\"6_tests.r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1e5a0",
   "metadata": {},
   "source": [
    "## 6.1 Key Functions for Group Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c2751",
   "metadata": {},
   "source": [
    "When we are working on a particular project, it is often quite important to know how to visualize data for specific groupings, whether of variables or observations meeting specific conditions. In this notebook, we will go into depth and look at a variety of functions for conducting group-level analysis. We will rely heavily on the `dyplr` package, which we have implicitly imported through the `tidyverse` package. Let's import these packages and load in our \"fake_data\" now. Recall that this data set is simulating information of workers in the years 1995-2012 in a fake country where a training program was introduced in 2003 to boost their earnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1103483-26ac-4329-93d0-c77b7fed529b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:4:18: unexpected INCOMPLETE_STRING\n3: \n4: data <- read_csv(\"../econ490-stata/fake_data.csv\n                    ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:4:18: unexpected INCOMPLETE_STRING\n3: \n4: data <- read_csv(\"../econ490-stata/fake_data.csv\n                    ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "library(haven)\n",
    "library(tidyverse)\n",
    "library(IRdisplay)\n",
    "\n",
    "fake_data <- read_csv(\"../econ490-stata/fake_data.csv\") # change me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229270d8-1c32-4f46-9dff-2e04aea2e54c",
   "metadata": {},
   "source": [
    "Now that we've loaded in our data and already know how to view it, clean it, and generate additional variables for it as needed, we can look at commands with group this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec3ab2-a581-40ca-8196-057b0b584e77",
   "metadata": {},
   "source": [
    "#### 6.1.1 `arrange`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426f9575-4e47-404b-862b-db67504eb616",
   "metadata": {},
   "source": [
    "Before grouping data, we may want to order our data set based on the values of a particular data set. The `arrange` function helps us achieve this. It takes in a data frame and variable and rearranges our data frame in ascending order by default, with the option to arrange in descending order requiring a further `desc` function. If we want this function to rearrange our entire data set in order of one of our variables, say _year_, we can do it as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89e5b33-bd7c-4dfd-8d58-d8dc2760f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange the dataframe by ascending year\n",
    "fake_data %>% arrange(year)\n",
    "\n",
    "# arrange the dataframe by descending year\n",
    "fake_data %>% arrange(desc(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323ed700-8710-40f1-aa15-48c7955146f1",
   "metadata": {},
   "source": [
    "We can pass multiple variable parameters to the `arrange` function to indicate how we should further sort our data within each year grouping. For instance, including the _region_ variable will further sort each year grouping in order of region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786344e-6e2a-412d-b2a3-6aa1cacf909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data %>% arrange(year, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e028e0c-155d-49cf-b3fa-11ad802a6529",
   "metadata": {},
   "source": [
    "#### 6.1.2 `group_by`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9ff06-75d9-4e1c-8df3-87bae32b4cf4",
   "metadata": {},
   "source": [
    "This is one of the most pivotal functions in R. It allows you to group a data frame by the values of a specific variable and perform further operations on those groups. Let's say that we wanted to group our data set by _region_ and count the number of observations in each region. We can simply pass this variable as a parameter to our `group_by` function and further pipe this result into the `tally` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7567715-5026-49e0-b629-f99918876ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data %>% group_by(region) %>% tally()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393ac43-7e16-41ee-9a16-8d4b764d6a05",
   "metadata": {},
   "source": [
    "Notice how the `group_by` function nicely groups the regions in ascending order for us automatically. Unlike with the `arrange` function, it does not preserve the data set in its entirety. It instead collapses our data set into groups, thus it is important not to redefine our \"data\" data frame by this group_by if we want to preserve our original data. We can also pass multiple arguments to `group_by`. If we pass both _region_ and _treated_ to our function as inputs, our region groups will be further grouped by observations which are and are not treated. Let's count the number of treated and untreated observations in each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c69e531-b0ca-4a3a-baf9-b16e89804b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data %>% group_by(region, treated) %>% tally()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13054875-1f49-4dc4-bfd8-1bd4346d93cf",
   "metadata": {},
   "source": [
    "Finally, we can pipe a group_by object into another group_by object. In this case, the second group_by will simply overwrite the first. For example, if we wanted to pass our original _region_ group_by into a _treated_ group_by, we will simply get a data frame counting the total number of observations who are treated and untreated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b86ed4-26db-4df2-a983-285ab5a434f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data %>% group_by(region) %>% group_by(treated) %>% tally()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e17ae4c-eb3c-4e8f-8a90-23754b446bee",
   "metadata": {},
   "source": [
    "#### 6.1.3 `group_keys`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603283af-9f4a-4e91-a2fa-0259ab1ce7d7",
   "metadata": {},
   "source": [
    "This function allows us to see the specific groups for a group_by data frame we have created. For instance, if we wanted to see every year in the data, we could group by _year_ and then apply the `group_keys` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf32c3a-89ea-4f3d-ae11-b78c1ad6b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data %>% group_by(year) %>% group_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2787c2-4e9b-481e-a5c7-e34cc36b1776",
   "metadata": {},
   "source": [
    "This is equivalent to using the `unique` function directly on a column of our data set, as below. The output is just a list in this case instead of another data frame as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed6752-9c59-4026-bf3d-6f952283bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(fake_data$year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d822b1-4e57-4126-91bd-5716918e35d0",
   "metadata": {},
   "source": [
    "#### 6.1.4 `ungroup`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87969b68-07f3-4894-b286-c17cad5b8f6f",
   "metadata": {},
   "source": [
    "We can even selectively remove groups from a grouped dataframe. Say we realized that we didn't need the dataframe grouping by `region` and `treated` and wanted to just count by `region`. If this dataframe had been defined as A, we can simply use `ungroup` to \"work backwards\", removing the grouping by treatment status and having a count for just regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadafe8-eafe-4c52-a486-b040a6001de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A <- fake_data %>% group_by(region, sex) %>% tally()\n",
    "A %>% ungroup(treated) %>% tally()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a46cb-d1a2-40dc-8dd2-3801c46a9952",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Order the following pieces of code to create a data frame which shows, in descending order, the population of each region and treatment pairing. Be sure to include piping. Pass your final code into answer_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491628af-2b3e-4bca-95e7-d7c4a0233909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count()\n",
    "# arrange(desc(n))\n",
    "# fake_data\n",
    "# group_by(region, treated)\n",
    "\n",
    "answer_1 <- # your answer ordering the 4 code pieces above and adjoining them with %>% here\n",
    "\n",
    "test_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fc37e-2823-4dd9-b7e3-4c6ebd89b0c7",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Use the methods we've learned so far to determine how many unique combinations of _region_, *birth_year* and *sex* exist in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975dac3-23c7-4f83-8c4e-911b4702691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "answer_2 <- # your answer here\n",
    "\n",
    "test_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57fe872-637b-4db8-b27c-76284aaa2d95",
   "metadata": {},
   "source": [
    "## 6.2 Generating Variables for Group Analysis\n",
    "\n",
    "We have already seen how to redefine and add new variables to a data frame using the df$ <- format. We have also seen how to use the `mutate` function to add new variables to a data frame. However, we often want to add new variables to grouped data frames to display information about the different groups rather than different observations from the original data frame. That is where `summarise` comes in. The `summarise` function gives us access to a variety of common functions we can use to generate variables corresponding to individual groups. For instance, we may want to find the mean earnings of each region. As such, we will group on _region_ and then add a variable to our grouped data frame which aggregates the mean of the _earnings_ variable for each region group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a3835-eff0-4d3d-adfe-7b6f85e6de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data %>% group_by(region) %>% summarise(meanearnings = mean(earnings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccb70d-ae72-40f5-8a79-e37b9225cf86",
   "metadata": {},
   "source": [
    "We may want more detailed information about each region. We can pass a series of parameters to `summarise`, and it will generate variables for all of these requests. Let's say we want the mean and standard deviation of _earnings_ for each group, as well as the range of _earnings_ of each group (max _earnings_ - min _earnings_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5110b7-40ce-4102-9788-b8d141c99bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data %>% \n",
    "    group_by(region) %>% \n",
    "    summarise(meanearnings = mean(earnings), stdevearnings = sd(earnings), range = max(earnings) - min(earnings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dbba6d-72a3-46dc-b402-a65f2f61707b",
   "metadata": {},
   "source": [
    "We may also want to calculate the number of observations in each region as an additional variable. Before, we could simply group by our _region_ variable and then immediately apply the `tally` function. However, now that we have defined a series of other variables, our data set on which `tally` operates is different. Watch what happens when we try to use `tally` after using `summarise`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b007f-ea2c-4235-9f7d-6d55b2391c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data %>% \n",
    "    group_by(region) %>% \n",
    "    summarise(meanearnings = mean(earnings), stdevearnings = sd(earnings), range = max(earnings) - min(earnings)) %>%\n",
    "    tally()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c98e441-6695-413f-9a49-cb0b10828971",
   "metadata": {},
   "source": [
    "Now watch what happens when we try to use `tally` before using `summarise`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80374e7-bf23-4631-aced-61d0fefd0e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data %>% \n",
    "    group_by(region) %>% \n",
    "    tally() %>%\n",
    "    summarise(meanearnings = mean(earnings), stdevearnings = sd(earnings), range = max(earnings) - min(earnings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd703245-f6aa-4309-9060-349268d5b666",
   "metadata": {},
   "source": [
    "In the first case, tally does not have the necessary information left in the data frame to count the number of observations in each region. In the second case, tally has shrunk the data frame so much that the functions within `summarise` do not have the necessary information to make their calculations. This is where `n` comes in. This is a special function used within the `summarise` variable. It represents the number of observations within each group of a data frame. As such, it is directly paired with `group_by`, although it can be paired with `mutate` when we are working with the number of observations in a data set as a whole (i.e. with one group, meaning `n` represents the position of each observation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa913e7-b697-4cd4-a13b-215c59db4d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data %>% \n",
    "    group_by(region) %>% \n",
    "    summarise(meanearnings = mean(earnings), stdevearnings = sd(earnings), range = max(earnings) - min(earnings), total = n())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e17e16-89b8-4b30-9677-a2c943b65994",
   "metadata": {},
   "source": [
    "The entire process in this section is similar to collapsing a dataset in Stata as part of aggregating a function across a series of observations. Luckily, it can be done more quickly here in R. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5077b6a-f1d4-4a7d-bb08-eef87eceed79",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Create a data frame which has the total number of people born in all birth years in which more than 100,000 people were born. The data frame should have two columns, one for *birth_year* and one for *total_births*, where *total_births* is arranged from most popular birth year to least popular birth year (with the least still having more than 100,000 in its *total_births*). Save your answer to answer_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf8e90-4a58-4225-86a8-365320a30999",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_3 <- # your code here\n",
    "\n",
    "test_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03594dac-6cc2-494e-8245-9638e7d32242",
   "metadata": {},
   "source": [
    "## 6.3 Reshaping Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb793df1-4846-4bbc-81cb-2502b8ae0352",
   "metadata": {},
   "source": [
    "Sometimes in our process of data analysis, we may want to restructure our data frame. To do this, we can take advantage of a series of functions within the `tidyr` package that we have imported implicitly through loading in the `tidyverse` package. Within this package, we can use a series of functions to quickly change the format of our data frame without having to redefine all of its columns and rows manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50845aa0-4cdc-4f19-ad7f-bc5be6d74264",
   "metadata": {},
   "source": [
    "We often want to transform our data from \"wide\" to \"long\" format, or vice versa. Suppose that we wish to make our data set more \"cross-sectional\" in appearance by dropping the age variable and adding variables for each year, with the values in these columns corresponding to the earnings of that person in that year. Effectively, by adding columns, we are making our data set \"wider\", so we will use the `pivot_wider` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0853e8fa-e012-4af8-b130-303fe8f57281",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in UseMethod(\"select\"): no applicable method for 'select' applied to an object of class \"function\"\n",
     "output_type": "error",
     "traceback": [
      "Error in UseMethod(\"select\"): no applicable method for 'select' applied to an object of class \"function\"\nTraceback:\n",
      "1. data %>% select(-age) %>% pivot_wider(names_from = \"year\", values_from = \"earnings\")",
      "2. pivot_wider(., names_from = \"year\", values_from = \"earnings\")",
      "3. select(., -age)"
     ]
    }
   ],
   "source": [
    "wide_data <- fake_data %>% select(-age) %>% pivot_wider(names_from = \"year\", values_from = \"earnings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28227f-e53a-48c3-ad62-945ce78d9dc2",
   "metadata": {},
   "source": [
    "We can see that the function above took the names from _year_ and generated a new variable for each of them 1995-2012, then supplied the corresponding values from _earnings_ to each of these years. In the case where a worker didn't have a recorded observation for a given year (and thus no wage), the _earnings_ variable is marked as missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bbdda6-fc27-416b-a53c-55d7cc60a499",
   "metadata": {},
   "source": [
    "Now suppose we want to work backward and transform this data set back into its original, \"longer\" shape (just now without the `age` variable). To do this, we can invoke the complementary `pivot_longer` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba4582-b9b0-4f96-8015-0b7c5a47f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_data %>% pivot_longer(cols = c(1995:2012), names_to = \"year\", values_to = \"earnings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e78afe0-72e4-472f-824a-bc416949daa3",
   "metadata": {},
   "source": [
    "Here, we supply the names of all variables/columns we want to compress to cols (being all the year variables we now want to squash), we supply the name of the singular variable all of these columns will be compressed into (being our original _year_ variable), and then we finally supply the name of the column for all of these earnings values to now be stored in: our original _earnings_ variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dd7d39-f273-4c60-8020-ebdfe81be4cf",
   "metadata": {},
   "source": [
    "If this doesn't seem intuitive or easy to grasp, don't worry. Even many experienced coders struggle with the reshape functionality in R, Stata, and other tools. With practice, it will become much more digestible!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a337ac3-78fa-4402-863d-607f616485c5",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Study the output of the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ceadf5-3a5e-43e3-897a-53a9e534b389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Person</th><th scope=col>Week</th><th scope=col>Money_Spent</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Jack</td><td>1</td><td> 50</td></tr>\n",
       "\t<tr><td>Jack</td><td>2</td><td> 75</td></tr>\n",
       "\t<tr><td>Jack</td><td>3</td><td> 25</td></tr>\n",
       "\t<tr><td>Jill</td><td>1</td><td> 15</td></tr>\n",
       "\t<tr><td>Jill</td><td>2</td><td>100</td></tr>\n",
       "\t<tr><td>Jill</td><td>3</td><td> 60</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{lll}\n",
       " Person & Week & Money\\_Spent\\\\\n",
       " <chr> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t Jack & 1 &  50\\\\\n",
       "\t Jack & 2 &  75\\\\\n",
       "\t Jack & 3 &  25\\\\\n",
       "\t Jill & 1 &  15\\\\\n",
       "\t Jill & 2 & 100\\\\\n",
       "\t Jill & 3 &  60\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| Person &lt;chr&gt; | Week &lt;dbl&gt; | Money_Spent &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| Jack | 1 |  50 |\n",
       "| Jack | 2 |  75 |\n",
       "| Jack | 3 |  25 |\n",
       "| Jill | 1 |  15 |\n",
       "| Jill | 2 | 100 |\n",
       "| Jill | 3 |  60 |\n",
       "\n"
      ],
      "text/plain": [
       "  Person Week Money_Spent\n",
       "1 Jack   1     50        \n",
       "2 Jack   2     75        \n",
       "3 Jack   3     25        \n",
       "4 Jill   1     15        \n",
       "5 Jill   2    100        \n",
       "6 Jill   3     60        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "people = c(\"Jack\", \"Jack\", \"Jack\", \"Jill\", \"Jill\", \"Jill\")\n",
    "weeks= c(1, 2, 3, 1, 2, 3)\n",
    "moneyspent = c(50, 75, 25, 15, 100, 60)\n",
    "\n",
    "Expenses <- data.frame(Person = people, Week = weeks, Money_Spent = moneyspent)\n",
    "Expenses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c54ebf-a552-4b9a-a718-3c671ac543f1",
   "metadata": {},
   "source": [
    "Run the code cell below to see the exercise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5120a36e-f983-4749-9827-c53a6aba3869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://h5p.open.ubc.ca/wp-admin/admin-ajax.php?action=h5p_embed&id=1207\" width=\"862\" height=\"258\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\" title=\"R 6.4\"></iframe><script src=\"https://h5p.open.ubc.ca/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js\" charset=\"UTF-8\"></script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_html('<iframe src=\"https://h5p.open.ubc.ca/wp-admin/admin-ajax.php?action=h5p_embed&id=1207\" width=\"862\" height=\"258\" frameborder=\"0\" allowfullscreen=\"allowfullscreen\" title=\"R 6.4\"></iframe><script src=\"https://h5p.open.ubc.ca/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js\" charset=\"UTF-8\"></script>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6489078-0759-4daf-9b23-9d3c11856b89",
   "metadata": {},
   "source": [
    "**Extra**: Try to create two data frames representing the two reshaping options described above! Feel free to label the columns of each new data frame as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f720fb-a255-419b-81f3-0986ace4d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b9278",
   "metadata": {},
   "source": [
    "## 6.4 Wrap Up\n",
    "Being able to generate new variables and modify a data set to suit your specific research is pivotal. Now you should hopefully have more confidence in your ability to perform these tasks. Next, we will explore the challenges posed by working with multiple datasets at once."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
